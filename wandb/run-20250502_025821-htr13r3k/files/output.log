02-05-2025 02:58:23 Downloading and reading train artifact
[34m[1mwandb[0m:   1 of 1 files downloaded.
02-05-2025 02:58:25 Spliting data into train/val
02-05-2025 02:58:25 x train: (375, 28)
02-05-2025 02:58:25 y train: (375,)
02-05-2025 02:58:25 x val: (162, 28)
02-05-2025 02:58:25 y val: (162,)
02-05-2025 02:58:25 Outlier Removal
02-05-2025 02:58:26 x_train shape [original]: (375, 28)
02-05-2025 02:58:26 x_train shape [outlier removal]: (357, 28)
02-05-2025 02:58:26 Data after SMOTE: (476, 28)
02-05-2025 02:58:26 [Logistic] Accuracy: 0.7469135802469136
02-05-2025 02:58:27 [Random Forest] Accuracy: 0.7222222222222222
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [02:58:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
02-05-2025 02:58:27 [XGBoost] Accuracy: 0.7222222222222222
                 Model  Accuracy
0  Logistic Regression  0.746914
1        Random Forest  0.722222
2              XGBoost  0.722222
[I 2025-05-02 02:58:30,309] A new study created in memory with name: no-name-3d7f4403-5b72-4b8a-bbd6-2ea0a8ba1e55
[I 2025-05-02 02:58:32,548] Trial 0 finished with value: 0.7816510172143974 and parameters: {'n_estimators': 140, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.7816510172143974.
[I 2025-05-02 02:58:33,430] Trial 1 finished with value: 0.7956964006259781 and parameters: {'n_estimators': 63, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:35,423] Trial 2 finished with value: 0.7816901408450704 and parameters: {'n_estimators': 138, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:36,714] Trial 3 finished with value: 0.7956964006259781 and parameters: {'n_estimators': 89, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:37,655] Trial 4 finished with value: 0.7817292644757433 and parameters: {'n_estimators': 71, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:39,250] Trial 5 finished with value: 0.7843896713615024 and parameters: {'n_estimators': 91, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:40,734] Trial 6 finished with value: 0.7760954616588419 and parameters: {'n_estimators': 88, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:42,301] Trial 7 finished with value: 0.7843896713615022 and parameters: {'n_estimators': 114, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:43,856] Trial 8 finished with value: 0.787206572769953 and parameters: {'n_estimators': 128, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:46,022] Trial 9 finished with value: 0.7789123630672925 and parameters: {'n_estimators': 163, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:46,889] Trial 10 finished with value: 0.7816118935837245 and parameters: {'n_estimators': 59, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:47,747] Trial 11 finished with value: 0.784467918622848 and parameters: {'n_estimators': 50, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:49,114] Trial 12 finished with value: 0.7928403755868544 and parameters: {'n_estimators': 92, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:51,702] Trial 13 finished with value: 0.7844287949921751 and parameters: {'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:52,707] Trial 14 finished with value: 0.7676447574334897 and parameters: {'n_estimators': 74, 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:54,356] Trial 15 finished with value: 0.7928403755868544 and parameters: {'n_estimators': 107, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:55,384] Trial 16 finished with value: 0.7816118935837245 and parameters: {'n_estimators': 70, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:56,804] Trial 17 finished with value: 0.7873239436619718 and parameters: {'n_estimators': 104, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:57,910] Trial 18 finished with value: 0.7844287949921751 and parameters: {'n_estimators': 80, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:58:58,598] Trial 19 finished with value: 0.7844287949921753 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:59:00,629] Trial 20 finished with value: 0.7872848200312988 and parameters: {'n_estimators': 158, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:59:01,953] Trial 21 finished with value: 0.7928403755868544 and parameters: {'n_estimators': 96, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.7956964006259781.
[I 2025-05-02 02:59:02,817] Trial 22 finished with value: 0.8012519561815337 and parameters: {'n_estimators': 65, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:03,661] Trial 23 finished with value: 0.7872456964006259 and parameters: {'n_estimators': 64, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:04,740] Trial 24 finished with value: 0.78716744913928 and parameters: {'n_estimators': 82, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:05,619] Trial 25 finished with value: 0.7843896713615022 and parameters: {'n_estimators': 60, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:07,238] Trial 26 finished with value: 0.7844287949921751 and parameters: {'n_estimators': 117, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:08,260] Trial 27 finished with value: 0.7928403755868544 and parameters: {'n_estimators': 78, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:09,931] Trial 28 finished with value: 0.7843505477308295 and parameters: {'n_estimators': 100, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:10,786] Trial 29 finished with value: 0.7872456964006259 and parameters: {'n_estimators': 56, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:11,703] Trial 30 finished with value: 0.8012519561815337 and parameters: {'n_estimators': 65, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:13,137] Trial 31 finished with value: 0.8012519561815337 and parameters: {'n_estimators': 66, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:14,321] Trial 32 finished with value: 0.8012519561815337 and parameters: {'n_estimators': 65, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:17,566] Trial 33 finished with value: 0.795657276995305 and parameters: {'n_estimators': 65, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:20,687] Trial 34 finished with value: 0.7983959311424099 and parameters: {'n_estimators': 70, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:23,604] Trial 35 finished with value: 0.795657276995305 and parameters: {'n_estimators': 85, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:25,663] Trial 36 finished with value: 0.7928403755868544 and parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:28,542] Trial 37 finished with value: 0.7732003129890455 and parameters: {'n_estimators': 75, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:32,043] Trial 38 finished with value: 0.7843896713615022 and parameters: {'n_estimators': 154, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:34,457] Trial 39 finished with value: 0.7900234741784036 and parameters: {'n_estimators': 184, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:36,309] Trial 40 finished with value: 0.7815727699530516 and parameters: {'n_estimators': 133, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:37,568] Trial 41 finished with value: 0.7900234741784036 and parameters: {'n_estimators': 71, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:38,488] Trial 42 finished with value: 0.7843896713615022 and parameters: {'n_estimators': 65, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:39,273] Trial 43 finished with value: 0.7872456964006259 and parameters: {'n_estimators': 57, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:40,299] Trial 44 finished with value: 0.7928012519561815 and parameters: {'n_estimators': 67, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:41,921] Trial 45 finished with value: 0.795657276995305 and parameters: {'n_estimators': 85, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:43,108] Trial 46 finished with value: 0.7844287949921753 and parameters: {'n_estimators': 92, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:43,928] Trial 47 finished with value: 0.7844287949921751 and parameters: {'n_estimators': 58, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:44,838] Trial 48 finished with value: 0.7732003129890455 and parameters: {'n_estimators': 75, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:46,424] Trial 49 finished with value: 0.7956572769953052 and parameters: {'n_estimators': 113, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:47,337] Trial 50 finished with value: 0.7816118935837245 and parameters: {'n_estimators': 69, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:48,204] Trial 51 finished with value: 0.7928794992175273 and parameters: {'n_estimators': 62, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:48,921] Trial 52 finished with value: 0.795657276995305 and parameters: {'n_estimators': 55, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:49,879] Trial 53 finished with value: 0.7872456964006259 and parameters: {'n_estimators': 77, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:50,871] Trial 54 finished with value: 0.7956181533646323 and parameters: {'n_estimators': 70, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:52,103] Trial 55 finished with value: 0.7872456964006259 and parameters: {'n_estimators': 88, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:53,120] Trial 56 finished with value: 0.787206572769953 and parameters: {'n_estimators': 81, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:55,053] Trial 57 finished with value: 0.7843896713615022 and parameters: {'n_estimators': 142, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:55,895] Trial 58 finished with value: 0.7984741784037558 and parameters: {'n_estimators': 53, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:57,657] Trial 59 finished with value: 0.784467918622848 and parameters: {'n_estimators': 51, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 02:59:59,176] Trial 60 finished with value: 0.7984741784037558 and parameters: {'n_estimators': 61, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:00,821] Trial 61 finished with value: 0.7984741784037558 and parameters: {'n_estimators': 61, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:02,344] Trial 62 finished with value: 0.7985133020344289 and parameters: {'n_estimators': 61, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:03,726] Trial 63 finished with value: 0.7816510172143974 and parameters: {'n_estimators': 56, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:05,030] Trial 64 finished with value: 0.7985133020344289 and parameters: {'n_estimators': 63, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:06,039] Trial 65 finished with value: 0.784467918622848 and parameters: {'n_estimators': 53, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:09,651] Trial 66 finished with value: 0.7844287949921751 and parameters: {'n_estimators': 66, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:14,290] Trial 67 finished with value: 0.7900234741784036 and parameters: {'n_estimators': 73, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:16,569] Trial 68 finished with value: 0.7928794992175273 and parameters: {'n_estimators': 62, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:19,744] Trial 69 finished with value: 0.7928403755868544 and parameters: {'n_estimators': 97, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:22,193] Trial 70 finished with value: 0.7788341158059466 and parameters: {'n_estimators': 80, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:23,849] Trial 71 finished with value: 0.7928794992175273 and parameters: {'n_estimators': 60, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:25,319] Trial 72 finished with value: 0.7928403755868544 and parameters: {'n_estimators': 53, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:28,140] Trial 73 finished with value: 0.8012519561815337 and parameters: {'n_estimators': 65, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:30,098] Trial 74 finished with value: 0.7704616588419405 and parameters: {'n_estimators': 66, 'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:32,569] Trial 75 finished with value: 0.7872456964006259 and parameters: {'n_estimators': 73, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:35,297] Trial 76 finished with value: 0.7844679186228483 and parameters: {'n_estimators': 85, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:37,730] Trial 77 finished with value: 0.7956964006259779 and parameters: {'n_estimators': 55, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:38,941] Trial 78 finished with value: 0.8012128325508607 and parameters: {'n_estimators': 67, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.8012519561815337.
[I 2025-05-02 03:00:40,282] Trial 79 finished with value: 0.8040297339593113 and parameters: {'n_estimators': 69, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 79 with value: 0.8040297339593113.
[I 2025-05-02 03:00:41,549] Trial 80 finished with value: 0.78716744913928 and parameters: {'n_estimators': 76, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 79 with value: 0.8040297339593113.
[I 2025-05-02 03:00:42,303] Trial 81 finished with value: 0.7928012519561815 and parameters: {'n_estimators': 68, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 79 with value: 0.8040297339593113.
[I 2025-05-02 03:00:42,962] Trial 82 finished with value: 0.8039906103286384 and parameters: {'n_estimators': 64, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 79 with value: 0.8040297339593113.
[I 2025-05-02 03:00:43,683] Trial 83 finished with value: 0.7843505477308295 and parameters: {'n_estimators': 72, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 79 with value: 0.8040297339593113.
[I 2025-05-02 03:00:44,309] Trial 84 finished with value: 0.8068857589984351 and parameters: {'n_estimators': 58, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 84 with value: 0.8068857589984351.
[I 2025-05-02 03:00:44,991] Trial 85 finished with value: 0.78716744913928 and parameters: {'n_estimators': 67, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 84 with value: 0.8068857589984351.
[I 2025-05-02 03:00:45,988] Trial 86 finished with value: 0.7956181533646323 and parameters: {'n_estimators': 78, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 84 with value: 0.8068857589984351.
[I 2025-05-02 03:00:46,620] Trial 87 finished with value: 0.8068857589984351 and parameters: {'n_estimators': 58, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 84 with value: 0.8068857589984351.
[I 2025-05-02 03:00:47,282] Trial 88 finished with value: 0.78716744913928 and parameters: {'n_estimators': 64, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 84 with value: 0.8068857589984351.
[I 2025-05-02 03:00:47,860] Trial 89 finished with value: 0.7900625978090767 and parameters: {'n_estimators': 58, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 84 with value: 0.8068857589984351.
[I 2025-05-02 03:00:48,787] Trial 90 finished with value: 0.7901017214397494 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 84 with value: 0.8068857589984351.
[I 2025-05-02 03:00:50,769] Trial 91 finished with value: 0.8068466353677621 and parameters: {'n_estimators': 70, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 84 with value: 0.8068857589984351.
[I 2025-05-02 03:00:55,603] Trial 92 finished with value: 0.7900234741784036 and parameters: {'n_estimators': 182, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 84 with value: 0.8068857589984351.
[I 2025-05-02 03:00:58,058] Trial 93 finished with value: 0.8068466353677621 and parameters: {'n_estimators': 70, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 84 with value: 0.8068857589984351.
[I 2025-05-02 03:01:00,001] Trial 94 finished with value: 0.795618153364632 and parameters: {'n_estimators': 70, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 84 with value: 0.8068857589984351.
[I 2025-05-02 03:01:01,106] Trial 95 finished with value: 0.787206572769953 and parameters: {'n_estimators': 57, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 84 with value: 0.8068857589984351.
[I 2025-05-02 03:01:04,498] Trial 96 finished with value: 0.7731220657276994 and parameters: {'n_estimators': 84, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 84 with value: 0.8068857589984351.
[I 2025-05-02 03:01:05,377] Trial 97 finished with value: 0.8012128325508607 and parameters: {'n_estimators': 75, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 84 with value: 0.8068857589984351.
[I 2025-05-02 03:01:06,721] Trial 98 finished with value: 0.787206572769953 and parameters: {'n_estimators': 122, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 84 with value: 0.8068857589984351.
[I 2025-05-02 03:01:07,346] Trial 99 finished with value: 0.8096635367762129 and parameters: {'n_estimators': 59, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 99 with value: 0.8096635367762129.
✅ Best Random Forest Parameters: {'n_estimators': 59, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 4}
[I 2025-05-02 03:01:07,354] A new study created in memory with name: no-name-89264644-6da0-4589-a3ac-c39d98e31169
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:08,543] Trial 0 finished with value: 0.7815336463223787 and parameters: {'n_estimators': 223, 'max_depth': 7, 'learning_rate': 0.24995475783011437, 'subsample': 0.7539449301081499, 'colsample_bytree': 0.8953926253825502, 'gamma': 0.8056723451142661, 'min_child_weight': 1}. Best is trial 0 with value: 0.7815336463223787.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:09,095] Trial 1 finished with value: 0.7591158059467918 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.15915467617789864, 'subsample': 0.6739691871731998, 'colsample_bytree': 0.8321641779170785, 'gamma': 1.707765162457039, 'min_child_weight': 10}. Best is trial 0 with value: 0.7815336463223787.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:09,753] Trial 2 finished with value: 0.7787949921752737 and parameters: {'n_estimators': 206, 'max_depth': 6, 'learning_rate': 0.03310898230962843, 'subsample': 0.7208237963412836, 'colsample_bytree': 0.8171960604844757, 'gamma': 4.799870376670359, 'min_child_weight': 2}. Best is trial 0 with value: 0.7815336463223787.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:11,484] Trial 3 finished with value: 0.7227308294209702 and parameters: {'n_estimators': 223, 'max_depth': 4, 'learning_rate': 0.23177585506206894, 'subsample': 0.7965001805282865, 'colsample_bytree': 0.6682639631793066, 'gamma': 0.3917041419603612, 'min_child_weight': 8}. Best is trial 0 with value: 0.7815336463223787.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:12,899] Trial 4 finished with value: 0.7788341158059469 and parameters: {'n_estimators': 192, 'max_depth': 10, 'learning_rate': 0.07338360990516653, 'subsample': 0.7975004202989519, 'colsample_bytree': 0.7890396336239095, 'gamma': 4.741114570230489, 'min_child_weight': 10}. Best is trial 0 with value: 0.7815336463223787.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:14,101] Trial 5 finished with value: 0.7535993740219092 and parameters: {'n_estimators': 238, 'max_depth': 9, 'learning_rate': 0.14668455005192224, 'subsample': 0.6574836637934746, 'colsample_bytree': 0.8040485865658881, 'gamma': 2.9701269570670847, 'min_child_weight': 8}. Best is trial 0 with value: 0.7815336463223787.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:15,065] Trial 6 finished with value: 0.7816118935837245 and parameters: {'n_estimators': 174, 'max_depth': 10, 'learning_rate': 0.10370838122444716, 'subsample': 0.6609407933093612, 'colsample_bytree': 0.9001004530139989, 'gamma': 2.0874682021795365, 'min_child_weight': 2}. Best is trial 6 with value: 0.7816118935837245.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:16,645] Trial 7 finished with value: 0.7788732394366196 and parameters: {'n_estimators': 195, 'max_depth': 8, 'learning_rate': 0.2106680785509028, 'subsample': 0.6038062934438969, 'colsample_bytree': 0.8948474894699743, 'gamma': 0.5317135653397115, 'min_child_weight': 1}. Best is trial 6 with value: 0.7816118935837245.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:17,560] Trial 8 finished with value: 0.7956964006259781 and parameters: {'n_estimators': 222, 'max_depth': 5, 'learning_rate': 0.14394614742244505, 'subsample': 0.9862583766662786, 'colsample_bytree': 0.9152144646239311, 'gamma': 3.0324866635122714, 'min_child_weight': 5}. Best is trial 8 with value: 0.7956964006259781.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:19,058] Trial 9 finished with value: 0.7759389671361502 and parameters: {'n_estimators': 174, 'max_depth': 5, 'learning_rate': 0.04210727766927241, 'subsample': 0.6021583555242643, 'colsample_bytree': 0.7559899268033127, 'gamma': 0.8415247136985515, 'min_child_weight': 1}. Best is trial 8 with value: 0.7956964006259781.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:20,435] Trial 10 finished with value: 0.7929186228482002 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.17306014564875916, 'subsample': 0.9975639112220509, 'colsample_bytree': 0.9829665920302387, 'gamma': 3.5898767806145577, 'min_child_weight': 5}. Best is trial 8 with value: 0.7956964006259781.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:21,489] Trial 11 finished with value: 0.7872456964006259 and parameters: {'n_estimators': 298, 'max_depth': 3, 'learning_rate': 0.1659206136062876, 'subsample': 0.9815566903224197, 'colsample_bytree': 0.9949984441456265, 'gamma': 3.410600270348442, 'min_child_weight': 5}. Best is trial 8 with value: 0.7956964006259781.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:22,323] Trial 12 finished with value: 0.7929186228482002 and parameters: {'n_estimators': 114, 'max_depth': 3, 'learning_rate': 0.11526517995506964, 'subsample': 0.9932935865931052, 'colsample_bytree': 0.9939153464826525, 'gamma': 3.7359739270623327, 'min_child_weight': 5}. Best is trial 8 with value: 0.7956964006259781.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:23,384] Trial 13 finished with value: 0.787206572769953 and parameters: {'n_estimators': 296, 'max_depth': 4, 'learning_rate': 0.29387938098432587, 'subsample': 0.9091448136298148, 'colsample_bytree': 0.9410179449752215, 'gamma': 3.8354836804526853, 'min_child_weight': 4}. Best is trial 8 with value: 0.7956964006259781.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:24,369] Trial 14 finished with value: 0.7648278560250391 and parameters: {'n_estimators': 260, 'max_depth': 5, 'learning_rate': 0.1927261397040541, 'subsample': 0.9022789824204301, 'colsample_bytree': 0.9502769140207209, 'gamma': 2.5569518009482772, 'min_child_weight': 7}. Best is trial 8 with value: 0.7956964006259781.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:24,905] Trial 15 finished with value: 0.7816510172143974 and parameters: {'n_estimators': 135, 'max_depth': 3, 'learning_rate': 0.10781660362612928, 'subsample': 0.9103047547961447, 'colsample_bytree': 0.6449149067091458, 'gamma': 4.001445699493084, 'min_child_weight': 4}. Best is trial 8 with value: 0.7956964006259781.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:26,315] Trial 16 finished with value: 0.7731611893583723 and parameters: {'n_estimators': 262, 'max_depth': 6, 'learning_rate': 0.13546586962767276, 'subsample': 0.8624528201170131, 'colsample_bytree': 0.9431461788847949, 'gamma': 2.8258966922489823, 'min_child_weight': 6}. Best is trial 8 with value: 0.7956964006259781.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:27,878] Trial 17 finished with value: 0.8095852895148671 and parameters: {'n_estimators': 271, 'max_depth': 4, 'learning_rate': 0.18902771892604536, 'subsample': 0.955809510892743, 'colsample_bytree': 0.8508121364419876, 'gamma': 1.983660502766151, 'min_child_weight': 3}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:29,316] Trial 18 finished with value: 0.7675665101721438 and parameters: {'n_estimators': 267, 'max_depth': 7, 'learning_rate': 0.2862915511338208, 'subsample': 0.9471688911902818, 'colsample_bytree': 0.7231488200954543, 'gamma': 1.6435780894805676, 'min_child_weight': 3}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:31,451] Trial 19 finished with value: 0.7759780907668231 and parameters: {'n_estimators': 249, 'max_depth': 4, 'learning_rate': 0.07115667366654642, 'subsample': 0.8602847497478993, 'colsample_bytree': 0.8591671600623831, 'gamma': 1.3710151977499194, 'min_child_weight': 3}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:32,748] Trial 20 finished with value: 0.7843896713615022 and parameters: {'n_estimators': 276, 'max_depth': 6, 'learning_rate': 0.25140718105513493, 'subsample': 0.9538689381364986, 'colsample_bytree': 0.8597336953165475, 'gamma': 2.249772773695864, 'min_child_weight': 6}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:33,810] Trial 21 finished with value: 0.7900234741784036 and parameters: {'n_estimators': 281, 'max_depth': 4, 'learning_rate': 0.18266616507195071, 'subsample': 0.9962530730525335, 'colsample_bytree': 0.9235192364394328, 'gamma': 3.2318903412747115, 'min_child_weight': 4}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:34,493] Trial 22 finished with value: 0.795657276995305 and parameters: {'n_estimators': 236, 'max_depth': 5, 'learning_rate': 0.2021959997103557, 'subsample': 0.9474022891133401, 'colsample_bytree': 0.969942126284228, 'gamma': 4.076899780863448, 'min_child_weight': 3}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:35,331] Trial 23 finished with value: 0.7873630672926447 and parameters: {'n_estimators': 231, 'max_depth': 5, 'learning_rate': 0.21210920044618062, 'subsample': 0.9453139869380563, 'colsample_bytree': 0.8656840876181394, 'gamma': 4.291880280684314, 'min_child_weight': 3}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:36,227] Trial 24 finished with value: 0.806924882629108 and parameters: {'n_estimators': 245, 'max_depth': 5, 'learning_rate': 0.21152343163788923, 'subsample': 0.8599238309221192, 'colsample_bytree': 0.9615907872015991, 'gamma': 4.480874335847097, 'min_child_weight': 2}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:37,569] Trial 25 finished with value: 0.7956964006259779 and parameters: {'n_estimators': 247, 'max_depth': 6, 'learning_rate': 0.13337343341595428, 'subsample': 0.862239243730614, 'colsample_bytree': 0.9133427143078683, 'gamma': 4.501827830605695, 'min_child_weight': 2}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:38,373] Trial 26 finished with value: 0.7732394366197182 and parameters: {'n_estimators': 215, 'max_depth': 4, 'learning_rate': 0.2381648671603063, 'subsample': 0.8246156216052688, 'colsample_bytree': 0.8772346151353427, 'gamma': 2.525188780499941, 'min_child_weight': 4}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:39,417] Trial 27 finished with value: 0.7759389671361502 and parameters: {'n_estimators': 280, 'max_depth': 7, 'learning_rate': 0.22192795353153408, 'subsample': 0.8968881715918474, 'colsample_bytree': 0.7721573099488825, 'gamma': 1.2467711396813927, 'min_child_weight': 2}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:40,483] Trial 28 finished with value: 0.7311815336463224 and parameters: {'n_estimators': 252, 'max_depth': 5, 'learning_rate': 0.26243479631068034, 'subsample': 0.8374034845933556, 'colsample_bytree': 0.8289799475170774, 'gamma': 0.012329522661166159, 'min_child_weight': 7}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:41,617] Trial 29 finished with value: 0.7928012519561815 and parameters: {'n_estimators': 219, 'max_depth': 4, 'learning_rate': 0.18957921741338388, 'subsample': 0.9238998402226227, 'colsample_bytree': 0.9512701385424868, 'gamma': 2.0559391761998276, 'min_child_weight': 1}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:42,470] Trial 30 finished with value: 0.7985133020344288 and parameters: {'n_estimators': 177, 'max_depth': 8, 'learning_rate': 0.27267330705727305, 'subsample': 0.7731999083505946, 'colsample_bytree': 0.731424433196461, 'gamma': 4.975694985824371, 'min_child_weight': 3}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:43,565] Trial 31 finished with value: 0.78716744913928 and parameters: {'n_estimators': 179, 'max_depth': 8, 'learning_rate': 0.25321284670127453, 'subsample': 0.7582278125216485, 'colsample_bytree': 0.7271551177348496, 'gamma': 4.9095809358912454, 'min_child_weight': 3}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:44,514] Trial 32 finished with value: 0.7816118935837245 and parameters: {'n_estimators': 154, 'max_depth': 8, 'learning_rate': 0.2803728443760654, 'subsample': 0.7712841173778628, 'colsample_bytree': 0.6990026164321628, 'gamma': 4.422021846106236, 'min_child_weight': 2}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:45,498] Trial 33 finished with value: 0.7928012519561815 and parameters: {'n_estimators': 148, 'max_depth': 9, 'learning_rate': 0.27038822762331144, 'subsample': 0.6995022911834583, 'colsample_bytree': 0.7506190720587589, 'gamma': 4.991718838382993, 'min_child_weight': 4}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:46,747] Trial 34 finished with value: 0.795657276995305 and parameters: {'n_estimators': 209, 'max_depth': 6, 'learning_rate': 0.15539631158969605, 'subsample': 0.7398455796973908, 'colsample_bytree': 0.8478858271729741, 'gamma': 4.648317523885463, 'min_child_weight': 2}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:48,307] Trial 35 finished with value: 0.7929186228482002 and parameters: {'n_estimators': 228, 'max_depth': 7, 'learning_rate': 0.2332226384311378, 'subsample': 0.8201762992248752, 'colsample_bytree': 0.6790977174876254, 'gamma': 3.1078023699046464, 'min_child_weight': 3}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:49,676] Trial 36 finished with value: 0.7901017214397497 and parameters: {'n_estimators': 202, 'max_depth': 5, 'learning_rate': 0.17409157605234638, 'subsample': 0.7799400240612365, 'colsample_bytree': 0.7983326707476585, 'gamma': 4.236008309169636, 'min_child_weight': 1}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:50,715] Trial 37 finished with value: 0.7675665101721438 and parameters: {'n_estimators': 159, 'max_depth': 9, 'learning_rate': 0.14323382287605835, 'subsample': 0.8830105297858063, 'colsample_bytree': 0.6014030204330044, 'gamma': 1.731197140983626, 'min_child_weight': 5}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:51,970] Trial 38 finished with value: 0.7732394366197182 and parameters: {'n_estimators': 187, 'max_depth': 6, 'learning_rate': 0.08804756747866893, 'subsample': 0.9722107139324792, 'colsample_bytree': 0.8897540437638657, 'gamma': 4.6754515978668, 'min_child_weight': 9}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:53,201] Trial 39 finished with value: 0.7311032863849765 and parameters: {'n_estimators': 242, 'max_depth': 8, 'learning_rate': 0.12430387925416547, 'subsample': 0.7360852260450975, 'colsample_bytree': 0.9200789197413115, 'gamma': 2.7224840454237014, 'min_child_weight': 6}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:55,110] Trial 40 finished with value: 0.795618153364632 and parameters: {'n_estimators': 212, 'max_depth': 5, 'learning_rate': 0.22032057466707128, 'subsample': 0.7055194485986127, 'colsample_bytree': 0.8136643621795104, 'gamma': 2.2241823409715673, 'min_child_weight': 2}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:56,783] Trial 41 finished with value: 0.7957355242566508 and parameters: {'n_estimators': 248, 'max_depth': 6, 'learning_rate': 0.13203417379069346, 'subsample': 0.8657835316054953, 'colsample_bytree': 0.9167737515412272, 'gamma': 4.437959476527747, 'min_child_weight': 2}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:58,403] Trial 42 finished with value: 0.8040688575899845 and parameters: {'n_estimators': 255, 'max_depth': 6, 'learning_rate': 0.1569932529251833, 'subsample': 0.8007183022366735, 'colsample_bytree': 0.9639250212792264, 'gamma': 3.483672008662351, 'min_child_weight': 1}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:01:59,187] Trial 43 finished with value: 0.7956964006259781 and parameters: {'n_estimators': 270, 'max_depth': 6, 'learning_rate': 0.1989256898338056, 'subsample': 0.8101984902957058, 'colsample_bytree': 0.9671988599943451, 'gamma': 4.128422146987685, 'min_child_weight': 1}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:01:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:00,746] Trial 44 finished with value: 0.7900234741784036 and parameters: {'n_estimators': 256, 'max_depth': 7, 'learning_rate': 0.1575827579855042, 'subsample': 0.7875735479967491, 'colsample_bytree': 0.965048670915135, 'gamma': 3.4775448696078666, 'min_child_weight': 1}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:01,762] Trial 45 finished with value: 0.8039906103286386 and parameters: {'n_estimators': 287, 'max_depth': 10, 'learning_rate': 0.1753323648384162, 'subsample': 0.8026979428352128, 'colsample_bytree': 0.8378927056348567, 'gamma': 4.528745837691842, 'min_child_weight': 2}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:02,561] Trial 46 finished with value: 0.8013302034428793 and parameters: {'n_estimators': 291, 'max_depth': 10, 'learning_rate': 0.17674296389100566, 'subsample': 0.8412838054868235, 'colsample_bytree': 0.7787537103846088, 'gamma': 3.8449924634179995, 'min_child_weight': 1}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:03,334] Trial 47 finished with value: 0.806924882629108 and parameters: {'n_estimators': 290, 'max_depth': 10, 'learning_rate': 0.1769571056004663, 'subsample': 0.8373062226643572, 'colsample_bytree': 0.7800472609206686, 'gamma': 3.7995269148018096, 'min_child_weight': 1}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:04,801] Trial 48 finished with value: 0.8039514866979657 and parameters: {'n_estimators': 285, 'max_depth': 10, 'learning_rate': 0.159473524690005, 'subsample': 0.8085493670113874, 'colsample_bytree': 0.8258162515829814, 'gamma': 3.646409917023964, 'min_child_weight': 1}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:05,575] Trial 49 finished with value: 0.7900625978090767 and parameters: {'n_estimators': 270, 'max_depth': 9, 'learning_rate': 0.20451883729353398, 'subsample': 0.8359943804243766, 'colsample_bytree': 0.8458702929941347, 'gamma': 3.9424708243076294, 'min_child_weight': 2}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:06,374] Trial 50 finished with value: 0.8095852895148671 and parameters: {'n_estimators': 288, 'max_depth': 10, 'learning_rate': 0.16696636898754177, 'subsample': 0.8801081774241029, 'colsample_bytree': 0.796144553936201, 'gamma': 3.2547745684427154, 'min_child_weight': 1}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:07,251] Trial 51 finished with value: 0.7984741784037558 and parameters: {'n_estimators': 293, 'max_depth': 10, 'learning_rate': 0.18756457930360398, 'subsample': 0.8738255055064224, 'colsample_bytree': 0.7937756499447011, 'gamma': 3.2926454517242028, 'min_child_weight': 1}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:08,540] Trial 52 finished with value: 0.7956964006259781 and parameters: {'n_estimators': 288, 'max_depth': 9, 'learning_rate': 0.17478940610085678, 'subsample': 0.8511200648567451, 'colsample_bytree': 0.75886279569361, 'gamma': 2.8761554598453305, 'min_child_weight': 1}. Best is trial 17 with value: 0.8095852895148671.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:09,704] Trial 53 finished with value: 0.80962441314554 and parameters: {'n_estimators': 277, 'max_depth': 10, 'learning_rate': 0.16399514238747873, 'subsample': 0.8001382285880991, 'colsample_bytree': 0.8131609367650394, 'gamma': 3.5093413601539787, 'min_child_weight': 2}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:11,226] Trial 54 finished with value: 0.787206572769953 and parameters: {'n_estimators': 272, 'max_depth': 10, 'learning_rate': 0.013422074035665588, 'subsample': 0.8199066469655903, 'colsample_bytree': 0.8137123616413053, 'gamma': 3.5587599783042925, 'min_child_weight': 2}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:12,544] Trial 55 finished with value: 0.80962441314554 and parameters: {'n_estimators': 261, 'max_depth': 9, 'learning_rate': 0.14563089524502226, 'subsample': 0.8885785130962306, 'colsample_bytree': 0.7737989228368122, 'gamma': 3.0900394459858993, 'min_child_weight': 1}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:13,375] Trial 56 finished with value: 0.8040297339593115 and parameters: {'n_estimators': 263, 'max_depth': 9, 'learning_rate': 0.12042951578542238, 'subsample': 0.9277709825808358, 'colsample_bytree': 0.7799728570403482, 'gamma': 3.155001990718725, 'min_child_weight': 1}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:14,526] Trial 57 finished with value: 0.8012128325508607 and parameters: {'n_estimators': 299, 'max_depth': 10, 'learning_rate': 0.1419083875181131, 'subsample': 0.9211483900969948, 'colsample_bytree': 0.7411501678594168, 'gamma': 2.65363156407863, 'min_child_weight': 2}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:15,855] Trial 58 finished with value: 0.8068857589984351 and parameters: {'n_estimators': 276, 'max_depth': 10, 'learning_rate': 0.16447629522923363, 'subsample': 0.8846435655005447, 'colsample_bytree': 0.708659238465978, 'gamma': 3.319162283133302, 'min_child_weight': 3}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:17,195] Trial 59 finished with value: 0.7985133020344287 and parameters: {'n_estimators': 279, 'max_depth': 10, 'learning_rate': 0.19596922315609971, 'subsample': 0.8882036715883302, 'colsample_bytree': 0.7673573392996145, 'gamma': 3.768137950362712, 'min_child_weight': 2}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:17,977] Trial 60 finished with value: 0.795618153364632 and parameters: {'n_estimators': 262, 'max_depth': 9, 'learning_rate': 0.21788422331429874, 'subsample': 0.968488740605357, 'colsample_bytree': 0.8179644024787193, 'gamma': 2.9749085813108627, 'min_child_weight': 1}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:20,261] Trial 61 finished with value: 0.7900234741784036 and parameters: {'n_estimators': 276, 'max_depth': 10, 'learning_rate': 0.16687547872170233, 'subsample': 0.8819079259986672, 'colsample_bytree': 0.7897816190788046, 'gamma': 3.3469930895567725, 'min_child_weight': 3}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:21,507] Trial 62 finished with value: 0.7955790297339593 and parameters: {'n_estimators': 282, 'max_depth': 10, 'learning_rate': 0.16468317151988224, 'subsample': 0.8505591160379542, 'colsample_bytree': 0.7083221867171854, 'gamma': 2.433523425726616, 'min_child_weight': 4}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:22,725] Trial 63 finished with value: 0.7732394366197182 and parameters: {'n_estimators': 265, 'max_depth': 10, 'learning_rate': 0.1486247124989468, 'subsample': 0.9020736707449726, 'colsample_bytree': 0.6495504341012397, 'gamma': 1.8274916198598063, 'min_child_weight': 3}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:23,660] Trial 64 finished with value: 0.8040688575899843 and parameters: {'n_estimators': 292, 'max_depth': 4, 'learning_rate': 0.18171280376984067, 'subsample': 0.9317553909081777, 'colsample_bytree': 0.7026573738278822, 'gamma': 3.0285701604042696, 'min_child_weight': 2}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:24,824] Trial 65 finished with value: 0.8040688575899843 and parameters: {'n_estimators': 274, 'max_depth': 9, 'learning_rate': 0.10251352515248091, 'subsample': 0.8731707842925013, 'colsample_bytree': 0.8030688547460113, 'gamma': 3.684524235639236, 'min_child_weight': 2}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:25,722] Trial 66 finished with value: 0.7675665101721438 and parameters: {'n_estimators': 240, 'max_depth': 3, 'learning_rate': 0.20713013011956583, 'subsample': 0.6227821756215272, 'colsample_bytree': 0.7507502205867969, 'gamma': 2.7753849650075115, 'min_child_weight': 3}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:26,784] Trial 67 finished with value: 0.8040297339593115 and parameters: {'n_estimators': 258, 'max_depth': 9, 'learning_rate': 0.18644360146008201, 'subsample': 0.9145342976269348, 'colsample_bytree': 0.8810036260732526, 'gamma': 3.376539136557245, 'min_child_weight': 1}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:28,160] Trial 68 finished with value: 0.7816118935837245 and parameters: {'n_estimators': 299, 'max_depth': 10, 'learning_rate': 0.14793316468875314, 'subsample': 0.8943845320610812, 'colsample_bytree': 0.7631839093431885, 'gamma': 1.4143992473649991, 'min_child_weight': 3}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:29,157] Trial 69 finished with value: 0.798474178403756 and parameters: {'n_estimators': 268, 'max_depth': 10, 'learning_rate': 0.16298673708091935, 'subsample': 0.8493860152965804, 'colsample_bytree': 0.7825294579761345, 'gamma': 2.3688025873770986, 'min_child_weight': 2}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:29,839] Trial 70 finished with value: 0.7874021909233176 and parameters: {'n_estimators': 114, 'max_depth': 9, 'learning_rate': 0.23829374549908516, 'subsample': 0.8297435224365881, 'colsample_bytree': 0.7367626291113031, 'gamma': 3.9636991633198964, 'min_child_weight': 4}. Best is trial 53 with value: 0.80962441314554.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:30,669] Trial 71 finished with value: 0.8152582159624412 and parameters: {'n_estimators': 282, 'max_depth': 4, 'learning_rate': 0.15214518842241645, 'subsample': 0.7892267728875495, 'colsample_bytree': 0.9879046080667583, 'gamma': 3.5123474987395036, 'min_child_weight': 1}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:31,868] Trial 72 finished with value: 0.7984741784037558 and parameters: {'n_estimators': 284, 'max_depth': 4, 'learning_rate': 0.13654267200942594, 'subsample': 0.7861029945647653, 'colsample_bytree': 0.7185596042007034, 'gamma': 4.261179025229687, 'min_child_weight': 1}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:33,090] Trial 73 finished with value: 0.8040297339593115 and parameters: {'n_estimators': 280, 'max_depth': 4, 'learning_rate': 0.16762980460145482, 'subsample': 0.8716405047539418, 'colsample_bytree': 0.9889126418742912, 'gamma': 3.1760686684910535, 'min_child_weight': 1}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:33,885] Trial 74 finished with value: 0.7620500782472612 and parameters: {'n_estimators': 294, 'max_depth': 3, 'learning_rate': 0.1941801835383788, 'subsample': 0.8563135769159607, 'colsample_bytree': 0.9809088406665957, 'gamma': 2.903255361829788, 'min_child_weight': 10}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:34,366] Trial 75 finished with value: 0.7787949921752737 and parameters: {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.150959420991855, 'subsample': 0.7589416023192308, 'colsample_bytree': 0.934651472629615, 'gamma': 3.561929632029512, 'min_child_weight': 1}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:35,177] Trial 76 finished with value: 0.7899452269170579 and parameters: {'n_estimators': 275, 'max_depth': 10, 'learning_rate': 0.12994260838991356, 'subsample': 0.8411905228973495, 'colsample_bytree': 0.6773002742478968, 'gamma': 2.070552209218465, 'min_child_weight': 2}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:37,127] Trial 77 finished with value: 0.7899452269170579 and parameters: {'n_estimators': 288, 'max_depth': 5, 'learning_rate': 0.2129185186555817, 'subsample': 0.8151728234335068, 'colsample_bytree': 0.8090651151252474, 'gamma': 3.2579644100991203, 'min_child_weight': 2}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:37,830] Trial 78 finished with value: 0.7929186228482002 and parameters: {'n_estimators': 246, 'max_depth': 3, 'learning_rate': 0.14037890932032246, 'subsample': 0.9367745582598753, 'colsample_bytree': 0.866052157704603, 'gamma': 3.8439436724710188, 'min_child_weight': 1}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:38,574] Trial 79 finished with value: 0.7984350547730829 and parameters: {'n_estimators': 252, 'max_depth': 4, 'learning_rate': 0.18159152912496418, 'subsample': 0.9129318444904019, 'colsample_bytree': 0.9025910113681539, 'gamma': 3.4074513479832484, 'min_child_weight': 3}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:39,967] Trial 80 finished with value: 0.7788341158059466 and parameters: {'n_estimators': 267, 'max_depth': 8, 'learning_rate': 0.10596837683637135, 'subsample': 0.7958984211956215, 'colsample_bytree': 0.6126805303418983, 'gamma': 0.8947089464735822, 'min_child_weight': 1}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:41,411] Trial 81 finished with value: 0.8040688575899843 and parameters: {'n_estimators': 256, 'max_depth': 10, 'learning_rate': 0.15549411230094665, 'subsample': 0.8009430042288307, 'colsample_bytree': 0.9532126068871656, 'gamma': 3.080137394001265, 'min_child_weight': 1}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:44,107] Trial 82 finished with value: 0.7955790297339593 and parameters: {'n_estimators': 278, 'max_depth': 5, 'learning_rate': 0.16778141585737297, 'subsample': 0.7675855879094479, 'colsample_bytree': 0.9345582940559725, 'gamma': 3.5293078096540293, 'min_child_weight': 1}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:46,829] Trial 83 finished with value: 0.7788341158059466 and parameters: {'n_estimators': 253, 'max_depth': 5, 'learning_rate': 0.22677076312411162, 'subsample': 0.8275700668111945, 'colsample_bytree': 0.9944021512607005, 'gamma': 4.086103763080624, 'min_child_weight': 2}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:48,385] Trial 84 finished with value: 0.7901017214397494 and parameters: {'n_estimators': 236, 'max_depth': 10, 'learning_rate': 0.15181865299674416, 'subsample': 0.8852787545527915, 'colsample_bytree': 0.9764327380214695, 'gamma': 3.6882099221179496, 'min_child_weight': 1}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:49,761] Trial 85 finished with value: 0.7985133020344287 and parameters: {'n_estimators': 271, 'max_depth': 6, 'learning_rate': 0.11635328046224293, 'subsample': 0.7945187141731892, 'colsample_bytree': 0.9574821858616176, 'gamma': 3.4573051673008823, 'min_child_weight': 1}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:51,506] Trial 86 finished with value: 0.7676056338028168 and parameters: {'n_estimators': 230, 'max_depth': 5, 'learning_rate': 0.17239618790723532, 'subsample': 0.9570410689430886, 'colsample_bytree': 0.8334701060786592, 'gamma': 2.640159612114689, 'min_child_weight': 9}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:52,640] Trial 87 finished with value: 0.7956181533646323 and parameters: {'n_estimators': 259, 'max_depth': 4, 'learning_rate': 0.12638255064630605, 'subsample': 0.7394460306813063, 'colsample_bytree': 0.7735481885560408, 'gamma': 3.253636442505829, 'min_child_weight': 2}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:55,050] Trial 88 finished with value: 0.7816510172143974 and parameters: {'n_estimators': 285, 'max_depth': 7, 'learning_rate': 0.1601349564265204, 'subsample': 0.8306216250018337, 'colsample_bytree': 0.7970795584259903, 'gamma': 3.86528645265428, 'min_child_weight': 1}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:56,117] Trial 89 finished with value: 0.7900234741784038 and parameters: {'n_estimators': 295, 'max_depth': 9, 'learning_rate': 0.19101460330038425, 'subsample': 0.7821873146659212, 'colsample_bytree': 0.8438351147451439, 'gamma': 4.133668385811077, 'min_child_weight': 2}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:57,509] Trial 90 finished with value: 0.7676056338028168 and parameters: {'n_estimators': 265, 'max_depth': 6, 'learning_rate': 0.1825188207429001, 'subsample': 0.7482801933261699, 'colsample_bytree': 0.9757424199041155, 'gamma': 3.7137971853181764, 'min_child_weight': 7}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:02:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:02:59,946] Trial 91 finished with value: 0.8039906103286386 and parameters: {'n_estimators': 293, 'max_depth': 4, 'learning_rate': 0.1791966430025705, 'subsample': 0.932766143050173, 'colsample_bytree': 0.6968370907146288, 'gamma': 3.050333544166872, 'min_child_weight': 2}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:03:01,398] Trial 92 finished with value: 0.8012910798122066 and parameters: {'n_estimators': 290, 'max_depth': 4, 'learning_rate': 0.1696614505111968, 'subsample': 0.9848482195070712, 'colsample_bytree': 0.7016049188182178, 'gamma': 3.3084380572049197, 'min_child_weight': 2}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:03:02,421] Trial 93 finished with value: 0.8039906103286384 and parameters: {'n_estimators': 283, 'max_depth': 4, 'learning_rate': 0.19724578851088953, 'subsample': 0.9664080896294163, 'colsample_bytree': 0.6639512535523728, 'gamma': 2.9370461153480703, 'min_child_weight': 3}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:03:03,426] Trial 94 finished with value: 0.8012519561815337 and parameters: {'n_estimators': 275, 'max_depth': 10, 'learning_rate': 0.18675960290132843, 'subsample': 0.9046823988813936, 'colsample_bytree': 0.7154340786938912, 'gamma': 1.8841981604863713, 'min_child_weight': 1}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:03:04,449] Trial 95 finished with value: 0.7957355242566511 and parameters: {'n_estimators': 289, 'max_depth': 3, 'learning_rate': 0.1459757642463958, 'subsample': 0.8957199600511444, 'colsample_bytree': 0.6826819720450467, 'gamma': 4.782774459884158, 'min_child_weight': 2}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:03:05,462] Trial 96 finished with value: 0.8011737089201878 and parameters: {'n_estimators': 271, 'max_depth': 5, 'learning_rate': 0.2027741709509094, 'subsample': 0.9404202364546612, 'colsample_bytree': 0.8187331198667444, 'gamma': 3.0354975973977836, 'min_child_weight': 4}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:03:06,610] Trial 97 finished with value: 0.8124413145539906 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.1575806399938394, 'subsample': 0.8632806011121044, 'colsample_bytree': 0.999029159101251, 'gamma': 3.5931181397547562, 'min_child_weight': 3}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:03:07,553] Trial 98 finished with value: 0.8041471048513303 and parameters: {'n_estimators': 244, 'max_depth': 10, 'learning_rate': 0.1560938255210913, 'subsample': 0.8660390816920929, 'colsample_bytree': 0.9973304451588559, 'gamma': 3.581066736257469, 'min_child_weight': 3}. Best is trial 71 with value: 0.8152582159624412.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:03:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:03:08,611] Trial 99 finished with value: 0.8069640062597807 and parameters: {'n_estimators': 297, 'max_depth': 10, 'learning_rate': 0.14025945841355447, 'subsample': 0.8663628790554184, 'colsample_bytree': 0.9978687581489785, 'gamma': 3.7659803538863983, 'min_child_weight': 3}. Best is trial 71 with value: 0.8152582159624412.
✅ Best XGBoost Parameters: {'n_estimators': 282, 'max_depth': 4, 'learning_rate': 0.15214518842241645, 'subsample': 0.7892267728875495, 'colsample_bytree': 0.9879046080667583, 'gamma': 3.5123474987395036, 'min_child_weight': 1}
✅ Best model selected based on F1: XGBoost
02-05-2025 03:03:09 Retraining best model on original full dataset...
02-05-2025 03:03:10 ✅ Exported and logged final model to W&B as artifact: final_model_xgboost.pkl
Requirement already satisfied: wandb in c:\users\x-hp\anaconda3\lib\site-packages (0.19.8)
Requirement already satisfied: click!=8.0.0,>=7.1 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (8.1.7)
Requirement already satisfied: docker-pycreds>=0.4.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (0.4.0)
Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (3.1.43)
Requirement already satisfied: platformdirs in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (3.10.0)
Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (4.25.3)
Requirement already satisfied: psutil>=5.0.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (5.9.0)
Requirement already satisfied: pydantic<3,>=2.6 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (2.8.2)
Requirement already satisfied: pyyaml in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (6.0.1)
Requirement already satisfied: requests<3,>=2.0.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (2.32.3)
Requirement already satisfied: sentry-sdk>=2.0.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (2.18.0)
Requirement already satisfied: setproctitle in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (1.3.5)
Requirement already satisfied: setuptools in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (75.1.0)
Requirement already satisfied: colorama in c:\users\x-hp\anaconda3\lib\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)
Requirement already satisfied: six>=1.4.0 in c:\users\x-hp\anaconda3\lib\site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)
Requirement already satisfied: gitdb<5,>=4.0.1 in c:\users\x-hp\anaconda3\lib\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.7)
Requirement already satisfied: annotated-types>=0.4.0 in c:\users\x-hp\anaconda3\lib\site-packages (from pydantic<3,>=2.6->wandb) (0.6.0)
Requirement already satisfied: pydantic-core==2.20.1 in c:\users\x-hp\anaconda3\lib\site-packages (from pydantic<3,>=2.6->wandb) (2.20.1)
Requirement already satisfied: typing-extensions>=4.6.1 in c:\users\x-hp\anaconda3\lib\site-packages (from pydantic<3,>=2.6->wandb) (4.11.0)
Requirement already satisfied: charset-normalizer<4,>=2 in c:\users\x-hp\anaconda3\lib\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in c:\users\x-hp\anaconda3\lib\site-packages (from requests<3,>=2.0.0->wandb) (3.7)
Requirement already satisfied: urllib3<3,>=1.21.1 in c:\users\x-hp\anaconda3\lib\site-packages (from requests<3,>=2.0.0->wandb) (2.2.3)
Requirement already satisfied: certifi>=2017.4.17 in c:\users\x-hp\anaconda3\lib\site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)
Requirement already satisfied: smmap<5,>=3.0.1 in c:\users\x-hp\anaconda3\lib\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (4.0.0)
[34m[1mwandb[0m: [33mWARNING[0m Calling wandb.login() after wandb.init() has no effect.
02-05-2025 03:53:19 Downloading and reading train artifact
[34m[1mwandb[0m:   1 of 1 files downloaded.
02-05-2025 03:53:24 Spliting data into train/val
02-05-2025 03:53:24 x train: (375, 8)
02-05-2025 03:53:24 y train: (375,)
02-05-2025 03:53:24 x val: (162, 8)
02-05-2025 03:53:24 y val: (162,)
02-05-2025 03:53:24 Outlier Removal
02-05-2025 03:53:24 x_train shape [original]: (375, 8)
02-05-2025 03:53:24 x_train shape [outlier removal]: (357, 8)
02-05-2025 03:53:24 Data after SMOTE: (476, 8)
02-05-2025 03:53:25 [Logistic] Accuracy: 0.7037037037037037
02-05-2025 03:53:25 [Random Forest] Accuracy: 0.691358024691358
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:53:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
02-05-2025 03:53:25 [XGBoost] Accuracy: 0.7098765432098766
                 Model  Accuracy
0  Logistic Regression  0.703704
1        Random Forest  0.691358
2              XGBoost  0.709877
[I 2025-05-02 03:53:30,696] A new study created in memory with name: no-name-2d637f35-3954-4623-b0f5-4fffa29569b1
[I 2025-05-02 03:53:32,828] Trial 0 finished with value: 0.7703834115805946 and parameters: {'n_estimators': 122, 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.7703834115805946.
[I 2025-05-02 03:53:35,304] Trial 1 finished with value: 0.7929577464788732 and parameters: {'n_estimators': 156, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.7929577464788732.
[I 2025-05-02 03:53:37,891] Trial 2 finished with value: 0.7845070422535212 and parameters: {'n_estimators': 185, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.7929577464788732.
[I 2025-05-02 03:53:39,485] Trial 3 finished with value: 0.776017214397496 and parameters: {'n_estimators': 119, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.7929577464788732.
[I 2025-05-02 03:53:41,814] Trial 4 finished with value: 0.7872456964006259 and parameters: {'n_estimators': 172, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.7929577464788732.
[I 2025-05-02 03:53:43,067] Trial 5 finished with value: 0.7817292644757433 and parameters: {'n_estimators': 96, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.7929577464788732.
[I 2025-05-02 03:53:45,144] Trial 6 finished with value: 0.7787949921752737 and parameters: {'n_estimators': 159, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.7929577464788732.
[I 2025-05-02 03:53:48,552] Trial 7 finished with value: 0.7676838810641626 and parameters: {'n_estimators': 186, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.7929577464788732.
[I 2025-05-02 03:53:52,284] Trial 8 finished with value: 0.784467918622848 and parameters: {'n_estimators': 199, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.7929577464788732.
[I 2025-05-02 03:53:53,633] Trial 9 finished with value: 0.7732394366197182 and parameters: {'n_estimators': 87, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.7929577464788732.
[I 2025-05-02 03:53:56,066] Trial 10 finished with value: 0.7872456964006259 and parameters: {'n_estimators': 153, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.7929577464788732.
[I 2025-05-02 03:53:58,573] Trial 11 finished with value: 0.7928794992175273 and parameters: {'n_estimators': 157, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.7929577464788732.
[I 2025-05-02 03:54:00,108] Trial 12 finished with value: 0.7873239436619718 and parameters: {'n_estimators': 51, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.7929577464788732.
[I 2025-05-02 03:54:02,471] Trial 13 finished with value: 0.7985133020344287 and parameters: {'n_estimators': 143, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.7985133020344287.
[I 2025-05-02 03:54:04,349] Trial 14 finished with value: 0.7929577464788732 and parameters: {'n_estimators': 136, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.7985133020344287.
[I 2025-05-02 03:54:06,859] Trial 15 finished with value: 0.8013302034428793 and parameters: {'n_estimators': 138, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 15 with value: 0.8013302034428793.
[I 2025-05-02 03:54:08,346] Trial 16 finished with value: 0.7985524256651017 and parameters: {'n_estimators': 105, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 15 with value: 0.8013302034428793.
[I 2025-05-02 03:54:09,749] Trial 17 finished with value: 0.7985133020344287 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 15 with value: 0.8013302034428793.
[I 2025-05-02 03:54:10,943] Trial 18 finished with value: 0.7956964006259779 and parameters: {'n_estimators': 72, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 15 with value: 0.8013302034428793.
[I 2025-05-02 03:54:12,696] Trial 19 finished with value: 0.8012519561815337 and parameters: {'n_estimators': 111, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 15 with value: 0.8013302034428793.
[I 2025-05-02 03:54:14,226] Trial 20 finished with value: 0.7816901408450704 and parameters: {'n_estimators': 112, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 15 with value: 0.8013302034428793.
[I 2025-05-02 03:54:16,068] Trial 21 finished with value: 0.8040688575899843 and parameters: {'n_estimators': 133, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8040688575899843.
[I 2025-05-02 03:54:18,192] Trial 22 finished with value: 0.8040688575899843 and parameters: {'n_estimators': 137, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8040688575899843.
[I 2025-05-02 03:54:20,100] Trial 23 finished with value: 0.7928403755868544 and parameters: {'n_estimators': 138, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8040688575899843.
[I 2025-05-02 03:54:22,633] Trial 24 finished with value: 0.8012519561815334 and parameters: {'n_estimators': 131, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8040688575899843.
[I 2025-05-02 03:54:24,551] Trial 25 finished with value: 0.7845461658841939 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8040688575899843.
[I 2025-05-02 03:54:26,333] Trial 26 finished with value: 0.7984350547730829 and parameters: {'n_estimators': 127, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.8040688575899843.
[I 2025-05-02 03:54:28,665] Trial 27 finished with value: 0.7816901408450704 and parameters: {'n_estimators': 172, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.8040688575899843.
[I 2025-05-02 03:54:30,956] Trial 28 finished with value: 0.7928794992175273 and parameters: {'n_estimators': 172, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.8040688575899843.
[I 2025-05-02 03:54:33,071] Trial 29 finished with value: 0.8040688575899845 and parameters: {'n_estimators': 148, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 29 with value: 0.8040688575899845.
[I 2025-05-02 03:54:34,946] Trial 30 finished with value: 0.7732003129890452 and parameters: {'n_estimators': 121, 'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 29 with value: 0.8040688575899845.
[I 2025-05-02 03:54:37,189] Trial 31 finished with value: 0.8040688575899845 and parameters: {'n_estimators': 152, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 29 with value: 0.8040688575899845.
[I 2025-05-02 03:54:39,197] Trial 32 finished with value: 0.8040688575899845 and parameters: {'n_estimators': 149, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 29 with value: 0.8040688575899845.
[I 2025-05-02 03:54:41,557] Trial 33 finished with value: 0.8040688575899845 and parameters: {'n_estimators': 149, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 29 with value: 0.8040688575899845.
[I 2025-05-02 03:54:43,707] Trial 34 finished with value: 0.8040688575899845 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 29 with value: 0.8040688575899845.
[I 2025-05-02 03:54:46,254] Trial 35 finished with value: 0.7984741784037558 and parameters: {'n_estimators': 164, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 29 with value: 0.8040688575899845.
[I 2025-05-02 03:54:49,054] Trial 36 finished with value: 0.8012519561815337 and parameters: {'n_estimators': 165, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 29 with value: 0.8040688575899845.
[I 2025-05-02 03:54:51,602] Trial 37 finished with value: 0.8097809076682315 and parameters: {'n_estimators': 183, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:54:54,191] Trial 38 finished with value: 0.7957355242566508 and parameters: {'n_estimators': 185, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:54:57,378] Trial 39 finished with value: 0.7956964006259781 and parameters: {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:54:59,888] Trial 40 finished with value: 0.7732394366197182 and parameters: {'n_estimators': 191, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:55:02,535] Trial 41 finished with value: 0.8040688575899845 and parameters: {'n_estimators': 176, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:55:04,591] Trial 42 finished with value: 0.8040688575899845 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:55:06,889] Trial 43 finished with value: 0.8069640062597807 and parameters: {'n_estimators': 162, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:55:09,392] Trial 44 finished with value: 0.8013302034428795 and parameters: {'n_estimators': 178, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:55:11,757] Trial 45 finished with value: 0.7985915492957746 and parameters: {'n_estimators': 161, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:55:14,058] Trial 46 finished with value: 0.8012910798122066 and parameters: {'n_estimators': 167, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:55:16,445] Trial 47 finished with value: 0.7957355242566508 and parameters: {'n_estimators': 182, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:55:18,683] Trial 48 finished with value: 0.8041079812206572 and parameters: {'n_estimators': 156, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:55:22,273] Trial 49 finished with value: 0.7872848200312988 and parameters: {'n_estimators': 193, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:55:24,390] Trial 50 finished with value: 0.8041079812206572 and parameters: {'n_estimators': 155, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:55:26,938] Trial 51 finished with value: 0.8012910798122066 and parameters: {'n_estimators': 160, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:55:29,780] Trial 52 finished with value: 0.8012910798122064 and parameters: {'n_estimators': 157, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:55:32,527] Trial 53 finished with value: 0.8012910798122066 and parameters: {'n_estimators': 168, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:55:34,464] Trial 54 finished with value: 0.784507042253521 and parameters: {'n_estimators': 146, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:55:36,647] Trial 55 finished with value: 0.8013302034428795 and parameters: {'n_estimators': 154, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.8097809076682315.
[I 2025-05-02 03:55:38,980] Trial 56 finished with value: 0.8125195618153365 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:55:40,979] Trial 57 finished with value: 0.8125195618153365 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:55:43,085] Trial 58 finished with value: 0.8012910798122064 and parameters: {'n_estimators': 127, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:55:45,078] Trial 59 finished with value: 0.7957355242566508 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:55:47,694] Trial 60 finished with value: 0.776056338028169 and parameters: {'n_estimators': 177, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:55:49,853] Trial 61 finished with value: 0.8097026604068857 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:55:51,824] Trial 62 finished with value: 0.8012128325508607 and parameters: {'n_estimators': 116, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:55:53,744] Trial 63 finished with value: 0.7957355242566508 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:55:55,710] Trial 64 finished with value: 0.8125195618153365 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:55:57,709] Trial 65 finished with value: 0.8125195618153365 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:55:59,446] Trial 66 finished with value: 0.7985133020344287 and parameters: {'n_estimators': 124, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:01,466] Trial 67 finished with value: 0.8097026604068857 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:03,501] Trial 68 finished with value: 0.7957746478873238 and parameters: {'n_estimators': 140, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:05,367] Trial 69 finished with value: 0.8012519561815334 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:06,670] Trial 70 finished with value: 0.7984350547730829 and parameters: {'n_estimators': 89, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:08,769] Trial 71 finished with value: 0.8068857589984348 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:10,524] Trial 72 finished with value: 0.8068857589984348 and parameters: {'n_estimators': 128, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:12,622] Trial 73 finished with value: 0.8125195618153365 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:14,632] Trial 74 finished with value: 0.7956964006259781 and parameters: {'n_estimators': 120, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:15,647] Trial 75 finished with value: 0.784467918622848 and parameters: {'n_estimators': 73, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:17,431] Trial 76 finished with value: 0.7929577464788732 and parameters: {'n_estimators': 131, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:19,721] Trial 77 finished with value: 0.7956572769953052 and parameters: {'n_estimators': 137, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:21,724] Trial 78 finished with value: 0.7732003129890452 and parameters: {'n_estimators': 142, 'max_depth': 2, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:23,363] Trial 79 finished with value: 0.8012519561815337 and parameters: {'n_estimators': 108, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:25,341] Trial 80 finished with value: 0.7928794992175273 and parameters: {'n_estimators': 145, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:27,180] Trial 81 finished with value: 0.7957355242566508 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:29,180] Trial 82 finished with value: 0.8068857589984348 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:32,304] Trial 83 finished with value: 0.8096635367762129 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:34,547] Trial 84 finished with value: 0.8040688575899843 and parameters: {'n_estimators': 130, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:36,578] Trial 85 finished with value: 0.7956572769953052 and parameters: {'n_estimators': 146, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:38,656] Trial 86 finished with value: 0.8068857589984348 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:40,216] Trial 87 finished with value: 0.7732394366197182 and parameters: {'n_estimators': 116, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:42,152] Trial 88 finished with value: 0.7901017214397494 and parameters: {'n_estimators': 124, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:44,165] Trial 89 finished with value: 0.7985133020344287 and parameters: {'n_estimators': 149, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:46,112] Trial 90 finished with value: 0.776017214397496 and parameters: {'n_estimators': 153, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:48,125] Trial 91 finished with value: 0.8069640062597807 and parameters: {'n_estimators': 159, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:50,171] Trial 92 finished with value: 0.7901799687010953 and parameters: {'n_estimators': 163, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:51,934] Trial 93 finished with value: 0.8070031298904536 and parameters: {'n_estimators': 133, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:54,109] Trial 94 finished with value: 0.8068857589984348 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:55,792] Trial 95 finished with value: 0.7956572769953052 and parameters: {'n_estimators': 135, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:57,708] Trial 96 finished with value: 0.7957355242566511 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:56:59,935] Trial 97 finished with value: 0.8040688575899843 and parameters: {'n_estimators': 134, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:57:01,808] Trial 98 finished with value: 0.7985133020344287 and parameters: {'n_estimators': 128, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 56 with value: 0.8125195618153365.
[I 2025-05-02 03:57:03,624] Trial 99 finished with value: 0.7928794992175273 and parameters: {'n_estimators': 139, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 56 with value: 0.8125195618153365.
✅ Best Random Forest Parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}
[I 2025-05-02 03:57:03,632] A new study created in memory with name: no-name-a3e52ae1-7b4b-46ee-9038-738e160bc205
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:04,316] Trial 0 finished with value: 0.7761345852895148 and parameters: {'n_estimators': 116, 'max_depth': 3, 'learning_rate': 0.04621013699432877, 'subsample': 0.8975125813626366, 'colsample_bytree': 0.6974345110633817, 'gamma': 0.9482539551124786, 'min_child_weight': 4}. Best is trial 0 with value: 0.7761345852895148.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:04,819] Trial 1 finished with value: 0.8125978090766823 and parameters: {'n_estimators': 116, 'max_depth': 3, 'learning_rate': 0.15161327469013983, 'subsample': 0.6727574848100859, 'colsample_bytree': 0.9401475829469241, 'gamma': 3.9844615188642662, 'min_child_weight': 1}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:05,332] Trial 2 finished with value: 0.7759389671361502 and parameters: {'n_estimators': 122, 'max_depth': 5, 'learning_rate': 0.2723386792425811, 'subsample': 0.679233177367577, 'colsample_bytree': 0.6933816762060139, 'gamma': 2.2575495213469217, 'min_child_weight': 7}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:06,212] Trial 3 finished with value: 0.7536384976525822 and parameters: {'n_estimators': 193, 'max_depth': 10, 'learning_rate': 0.03953262023206453, 'subsample': 0.7325607520732949, 'colsample_bytree': 0.7053959952534786, 'gamma': 0.3344287891898118, 'min_child_weight': 7}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:06,963] Trial 4 finished with value: 0.7620109546165883 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.22786357922723094, 'subsample': 0.9773791930513407, 'colsample_bytree': 0.808532491604079, 'gamma': 0.2848576707646011, 'min_child_weight': 5}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:07,565] Trial 5 finished with value: 0.7731220657276994 and parameters: {'n_estimators': 111, 'max_depth': 9, 'learning_rate': 0.23181921146890347, 'subsample': 0.667775778002773, 'colsample_bytree': 0.7835660785487795, 'gamma': 1.2366690164821192, 'min_child_weight': 4}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:08,809] Trial 6 finished with value: 0.7900234741784036 and parameters: {'n_estimators': 209, 'max_depth': 8, 'learning_rate': 0.2736412234721002, 'subsample': 0.6169334639957126, 'colsample_bytree': 0.9040473794435054, 'gamma': 0.3555408702410445, 'min_child_weight': 1}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:09,815] Trial 7 finished with value: 0.7787949921752739 and parameters: {'n_estimators': 291, 'max_depth': 9, 'learning_rate': 0.21202058990309983, 'subsample': 0.6662030712246614, 'colsample_bytree': 0.6675216057543693, 'gamma': 0.7408440949054179, 'min_child_weight': 2}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:10,422] Trial 8 finished with value: 0.7985524256651017 and parameters: {'n_estimators': 168, 'max_depth': 9, 'learning_rate': 0.08782120575808934, 'subsample': 0.9717468637903791, 'colsample_bytree': 0.8768077097646192, 'gamma': 1.8166832392858638, 'min_child_weight': 4}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:11,164] Trial 9 finished with value: 0.7817292644757433 and parameters: {'n_estimators': 203, 'max_depth': 4, 'learning_rate': 0.24045580234116495, 'subsample': 0.9535580728376629, 'colsample_bytree': 0.6774412648860532, 'gamma': 2.924205266679491, 'min_child_weight': 3}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:11,979] Trial 10 finished with value: 0.776017214397496 and parameters: {'n_estimators': 256, 'max_depth': 7, 'learning_rate': 0.14045293790732927, 'subsample': 0.8108476792102851, 'colsample_bytree': 0.9979518317941901, 'gamma': 4.468173759046358, 'min_child_weight': 10}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:12,706] Trial 11 finished with value: 0.784507042253521 and parameters: {'n_estimators': 155, 'max_depth': 6, 'learning_rate': 0.11014676116111884, 'subsample': 0.8183858706397732, 'colsample_bytree': 0.9340402183271262, 'gamma': 4.596391074183907, 'min_child_weight': 1}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:13,351] Trial 12 finished with value: 0.7732394366197184 and parameters: {'n_estimators': 155, 'max_depth': 3, 'learning_rate': 0.08418453336461142, 'subsample': 0.9036394289767913, 'colsample_bytree': 0.8697695921409189, 'gamma': 3.6991329554765757, 'min_child_weight': 7}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:14,065] Trial 13 finished with value: 0.7816510172143974 and parameters: {'n_estimators': 159, 'max_depth': 7, 'learning_rate': 0.1753520851156764, 'subsample': 0.7548727912269393, 'colsample_bytree': 0.9992028959344422, 'gamma': 1.8221222474519672, 'min_child_weight': 3}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:14,634] Trial 14 finished with value: 0.7732394366197184 and parameters: {'n_estimators': 141, 'max_depth': 10, 'learning_rate': 0.15978176926855897, 'subsample': 0.851118727415086, 'colsample_bytree': 0.836265942915695, 'gamma': 3.2438433240206774, 'min_child_weight': 10}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:15,289] Trial 15 finished with value: 0.7788732394366196 and parameters: {'n_estimators': 176, 'max_depth': 8, 'learning_rate': 0.08449778974675864, 'subsample': 0.7539470585543919, 'colsample_bytree': 0.6001944260251336, 'gamma': 3.811211995222055, 'min_child_weight': 6}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:16,153] Trial 16 finished with value: 0.8125978090766821 and parameters: {'n_estimators': 238, 'max_depth': 6, 'learning_rate': 0.13006067294381965, 'subsample': 0.9207526318890558, 'colsample_bytree': 0.93279043690246, 'gamma': 1.814750605992815, 'min_child_weight': 2}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:16,901] Trial 17 finished with value: 0.7928794992175273 and parameters: {'n_estimators': 236, 'max_depth': 5, 'learning_rate': 0.13232937633245323, 'subsample': 0.6066059474480974, 'colsample_bytree': 0.9444621384916703, 'gamma': 4.993533763169314, 'min_child_weight': 2}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:18,089] Trial 18 finished with value: 0.795774647887324 and parameters: {'n_estimators': 239, 'max_depth': 4, 'learning_rate': 0.1877376639137917, 'subsample': 0.8874311375962323, 'colsample_bytree': 0.9519086034577561, 'gamma': 2.4283669696307406, 'min_child_weight': 1}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:19,003] Trial 19 finished with value: 0.7928012519561815 and parameters: {'n_estimators': 288, 'max_depth': 6, 'learning_rate': 0.19031512499156233, 'subsample': 0.7239669757170625, 'colsample_bytree': 0.7768161580808398, 'gamma': 3.156290241733248, 'min_child_weight': 2}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:20,588] Trial 20 finished with value: 0.7956964006259779 and parameters: {'n_estimators': 266, 'max_depth': 4, 'learning_rate': 0.010111839059477962, 'subsample': 0.9389447328605732, 'colsample_bytree': 0.9032356181708477, 'gamma': 1.6601818617509698, 'min_child_weight': 3}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:21,415] Trial 21 finished with value: 0.7985133020344287 and parameters: {'n_estimators': 233, 'max_depth': 8, 'learning_rate': 0.09922778011389205, 'subsample': 0.983407023035722, 'colsample_bytree': 0.8712358683372731, 'gamma': 1.8135355146029462, 'min_child_weight': 4}. Best is trial 1 with value: 0.8125978090766823.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:22,095] Trial 22 finished with value: 0.8236697965571205 and parameters: {'n_estimators': 129, 'max_depth': 9, 'learning_rate': 0.12294224485738789, 'subsample': 0.9966399160220876, 'colsample_bytree': 0.9654418189273486, 'gamma': 1.3688324667610288, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:22,823] Trial 23 finished with value: 0.8152973395931141 and parameters: {'n_estimators': 137, 'max_depth': 6, 'learning_rate': 0.12622969331942985, 'subsample': 0.9266278298642674, 'colsample_bytree': 0.9701621897970981, 'gamma': 1.196541199847851, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:23,542] Trial 24 finished with value: 0.8124021909233177 and parameters: {'n_estimators': 132, 'max_depth': 7, 'learning_rate': 0.15489003617308664, 'subsample': 0.8522000171038744, 'colsample_bytree': 0.9710469409968666, 'gamma': 1.2324240190259157, 'min_child_weight': 1}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:24,233] Trial 25 finished with value: 0.7899843505477309 and parameters: {'n_estimators': 104, 'max_depth': 3, 'learning_rate': 0.06824454912991668, 'subsample': 0.8605016740002588, 'colsample_bytree': 0.975763799377057, 'gamma': 0.7972803959748503, 'min_child_weight': 3}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:24,883] Trial 26 finished with value: 0.8153755868544602 and parameters: {'n_estimators': 141, 'max_depth': 5, 'learning_rate': 0.11886996294183308, 'subsample': 0.9322110502947021, 'colsample_bytree': 0.9034156489663658, 'gamma': 2.765855733416434, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:25,475] Trial 27 finished with value: 0.7929186228482002 and parameters: {'n_estimators': 137, 'max_depth': 5, 'learning_rate': 0.12561153599385302, 'subsample': 0.9982220438070815, 'colsample_bytree': 0.9050275361555626, 'gamma': 2.8068859215525808, 'min_child_weight': 5}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:26,174] Trial 28 finished with value: 0.7732394366197184 and parameters: {'n_estimators': 182, 'max_depth': 6, 'learning_rate': 0.11349921904779595, 'subsample': 0.93175638408324, 'colsample_bytree': 0.836636429889168, 'gamma': 2.2175079675881006, 'min_child_weight': 9}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:26,971] Trial 29 finished with value: 0.806924882629108 and parameters: {'n_estimators': 101, 'max_depth': 7, 'learning_rate': 0.06236569236261076, 'subsample': 0.8915477596757978, 'colsample_bytree': 0.9744001656867644, 'gamma': 1.2511180941697138, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:27,564] Trial 30 finished with value: 0.7928794992175273 and parameters: {'n_estimators': 125, 'max_depth': 4, 'learning_rate': 0.045441718820032104, 'subsample': 0.9595678782629791, 'colsample_bytree': 0.9125394745564411, 'gamma': 2.621308908129053, 'min_child_weight': 4}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:28,232] Trial 31 finished with value: 0.7928794992175273 and parameters: {'n_estimators': 146, 'max_depth': 5, 'learning_rate': 0.15988559295701485, 'subsample': 0.9143618250833978, 'colsample_bytree': 0.96162986021795, 'gamma': 3.6815589408639626, 'min_child_weight': 1}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:28,779] Trial 32 finished with value: 0.8152973395931141 and parameters: {'n_estimators': 121, 'max_depth': 3, 'learning_rate': 0.14935899860192647, 'subsample': 0.9455329025533247, 'colsample_bytree': 0.939091091512889, 'gamma': 4.112127350975939, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:29,637] Trial 33 finished with value: 0.795657276995305 and parameters: {'n_estimators': 120, 'max_depth': 3, 'learning_rate': 0.17451236398682926, 'subsample': 0.9979675418798252, 'colsample_bytree': 0.989227588920687, 'gamma': 4.2347648340441975, 'min_child_weight': 3}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:30,323] Trial 34 finished with value: 0.804186228482003 and parameters: {'n_estimators': 129, 'max_depth': 4, 'learning_rate': 0.1169373679965435, 'subsample': 0.951151816501629, 'colsample_bytree': 0.9263778492881583, 'gamma': 1.3985206660739293, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:30,912] Trial 35 finished with value: 0.7872456964006259 and parameters: {'n_estimators': 112, 'max_depth': 6, 'learning_rate': 0.13659865141241137, 'subsample': 0.8729192462390508, 'colsample_bytree': 0.8852896679984357, 'gamma': 3.3989512960514765, 'min_child_weight': 5}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:31,590] Trial 36 finished with value: 0.8013302034428793 and parameters: {'n_estimators': 148, 'max_depth': 5, 'learning_rate': 0.1058546569192827, 'subsample': 0.9331876831576571, 'colsample_bytree': 0.835917721789307, 'gamma': 2.131633209125369, 'min_child_weight': 3}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:32,293] Trial 37 finished with value: 0.7899843505477309 and parameters: {'n_estimators': 167, 'max_depth': 10, 'learning_rate': 0.2960166877126704, 'subsample': 0.9653014711189463, 'colsample_bytree': 0.9544725201991243, 'gamma': 0.5305356507285479, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:33,370] Trial 38 finished with value: 0.7983959311424099 and parameters: {'n_estimators': 118, 'max_depth': 8, 'learning_rate': 0.1439606551378281, 'subsample': 0.8385009991752608, 'colsample_bytree': 0.7307002061290004, 'gamma': 0.04228748818411976, 'min_child_weight': 1}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:34,081] Trial 39 finished with value: 0.7984350547730829 and parameters: {'n_estimators': 190, 'max_depth': 9, 'learning_rate': 0.20915227689351473, 'subsample': 0.9818943951874641, 'colsample_bytree': 0.9237766685146928, 'gamma': 1.4584831041963184, 'min_child_weight': 4}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:34,820] Trial 40 finished with value: 0.7676447574334899 and parameters: {'n_estimators': 136, 'max_depth': 5, 'learning_rate': 0.06657598875437791, 'subsample': 0.7817326400615883, 'colsample_bytree': 0.8535609361786796, 'gamma': 0.9108576093384708, 'min_child_weight': 6}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:35,344] Trial 41 finished with value: 0.8069640062597807 and parameters: {'n_estimators': 109, 'max_depth': 3, 'learning_rate': 0.14899894342297315, 'subsample': 0.645936078797665, 'colsample_bytree': 0.9495492365187258, 'gamma': 4.032343592419481, 'min_child_weight': 1}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:35,899] Trial 42 finished with value: 0.7929577464788732 and parameters: {'n_estimators': 121, 'max_depth': 3, 'learning_rate': 0.17107592680380643, 'subsample': 0.632820411791201, 'colsample_bytree': 0.8859704183148314, 'gamma': 4.411477463388013, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:36,474] Trial 43 finished with value: 0.7901408450704226 and parameters: {'n_estimators': 127, 'max_depth': 4, 'learning_rate': 0.09246836193216197, 'subsample': 0.7020153263158033, 'colsample_bytree': 0.9747140335181173, 'gamma': 4.957386505896412, 'min_child_weight': 1}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:37,043] Trial 44 finished with value: 0.7956964006259779 and parameters: {'n_estimators': 147, 'max_depth': 3, 'learning_rate': 0.197256875926145, 'subsample': 0.9076824091190585, 'colsample_bytree': 0.9113279603526258, 'gamma': 3.3917409255348487, 'min_child_weight': 3}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:37,694] Trial 45 finished with value: 0.8068857589984351 and parameters: {'n_estimators': 164, 'max_depth': 4, 'learning_rate': 0.1238546435172797, 'subsample': 0.9467279612336892, 'colsample_bytree': 0.987347648915301, 'gamma': 3.949551544288708, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:38,249] Trial 46 finished with value: 0.7845070422535212 and parameters: {'n_estimators': 114, 'max_depth': 7, 'learning_rate': 0.16461072907972507, 'subsample': 0.9693343140193043, 'colsample_bytree': 0.9380730057283114, 'gamma': 2.1295982770980886, 'min_child_weight': 8}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:39,128] Trial 47 finished with value: 0.7789123630672925 and parameters: {'n_estimators': 102, 'max_depth': 5, 'learning_rate': 0.14846123905228933, 'subsample': 0.7909583498136757, 'colsample_bytree': 0.8945473329169242, 'gamma': 4.601427505188543, 'min_child_weight': 1}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:39,927] Trial 48 finished with value: 0.7758998435054772 and parameters: {'n_estimators': 155, 'max_depth': 9, 'learning_rate': 0.24320622243995516, 'subsample': 0.6857646236137462, 'colsample_bytree': 0.7878682366426178, 'gamma': 1.0506904808095765, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:41,293] Trial 49 finished with value: 0.7732003129890452 and parameters: {'n_estimators': 214, 'max_depth': 6, 'learning_rate': 0.10667293732391925, 'subsample': 0.8826124023423576, 'colsample_bytree': 0.9608828074030673, 'gamma': 0.631433718271715, 'min_child_weight': 3}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:41,937] Trial 50 finished with value: 0.8096635367762129 and parameters: {'n_estimators': 141, 'max_depth': 3, 'learning_rate': 0.1212482355837034, 'subsample': 0.9208844357486796, 'colsample_bytree': 0.9227553952567502, 'gamma': 3.5160648644662995, 'min_child_weight': 1}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:42,702] Trial 51 finished with value: 0.8153364632237873 and parameters: {'n_estimators': 218, 'max_depth': 6, 'learning_rate': 0.1333028106027866, 'subsample': 0.9277638721606031, 'colsample_bytree': 0.9326613767264988, 'gamma': 1.6367539196413177, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:43,761] Trial 52 finished with value: 0.7983568075117372 and parameters: {'n_estimators': 215, 'max_depth': 6, 'learning_rate': 0.13639364550626576, 'subsample': 0.830079568370004, 'colsample_bytree': 0.9404914620108018, 'gamma': 1.613546415105363, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:44,695] Trial 53 finished with value: 0.7872848200312988 and parameters: {'n_estimators': 201, 'max_depth': 6, 'learning_rate': 0.0958284343099457, 'subsample': 0.9797309588278384, 'colsample_bytree': 0.9817270795089881, 'gamma': 1.0656927559466047, 'min_child_weight': 3}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:45,476] Trial 54 finished with value: 0.8152973395931141 and parameters: {'n_estimators': 222, 'max_depth': 8, 'learning_rate': 0.08267676629403387, 'subsample': 0.9390797086802873, 'colsample_bytree': 0.9977854480021022, 'gamma': 3.0030917632073253, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:46,376] Trial 55 finished with value: 0.8040688575899845 and parameters: {'n_estimators': 220, 'max_depth': 9, 'learning_rate': 0.03195993713688253, 'subsample': 0.9264837672165505, 'colsample_bytree': 0.9990398129318449, 'gamma': 2.8588585866866416, 'min_child_weight': 3}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:47,259] Trial 56 finished with value: 0.8097026604068857 and parameters: {'n_estimators': 251, 'max_depth': 7, 'learning_rate': 0.08131650388349167, 'subsample': 0.8981304137407926, 'colsample_bytree': 0.9616742369006318, 'gamma': 2.584241407734848, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:47,989] Trial 57 finished with value: 0.8097417840375588 and parameters: {'n_estimators': 229, 'max_depth': 8, 'learning_rate': 0.10308089508276072, 'subsample': 0.9453340198807241, 'colsample_bytree': 0.6162434659992827, 'gamma': 2.3946445589935434, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:48,894] Trial 58 finished with value: 0.8069248826291078 and parameters: {'n_estimators': 222, 'max_depth': 10, 'learning_rate': 0.07623477227287229, 'subsample': 0.9613070582017333, 'colsample_bytree': 0.8550217626241225, 'gamma': 1.9506975437126501, 'min_child_weight': 4}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:49,730] Trial 59 finished with value: 0.8069248826291078 and parameters: {'n_estimators': 206, 'max_depth': 8, 'learning_rate': 0.05396610912652712, 'subsample': 0.9926958950184342, 'colsample_bytree': 0.7497410793861797, 'gamma': 2.9399933131029328, 'min_child_weight': 1}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:50,439] Trial 60 finished with value: 0.8069640062597809 and parameters: {'n_estimators': 190, 'max_depth': 7, 'learning_rate': 0.11421661504745932, 'subsample': 0.8729836066748604, 'colsample_bytree': 0.965417191279105, 'gamma': 3.139022432357574, 'min_child_weight': 3}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:51,285] Trial 61 finished with value: 0.8012519561815337 and parameters: {'n_estimators': 252, 'max_depth': 9, 'learning_rate': 0.13090306692380732, 'subsample': 0.9085995395325097, 'colsample_bytree': 0.9462321141567135, 'gamma': 4.782476411265358, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:51,850] Trial 62 finished with value: 0.8041471048513301 and parameters: {'n_estimators': 133, 'max_depth': 4, 'learning_rate': 0.1528728600359491, 'subsample': 0.9400197843605413, 'colsample_bytree': 0.9297536962203318, 'gamma': 4.132255328541502, 'min_child_weight': 1}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:52,699] Trial 63 finished with value: 0.8041079812206572 and parameters: {'n_estimators': 178, 'max_depth': 5, 'learning_rate': 0.14367318319450414, 'subsample': 0.9545964065952379, 'colsample_bytree': 0.9880956576144464, 'gamma': 1.5626671941049821, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:53,977] Trial 64 finished with value: 0.7901017214397497 and parameters: {'n_estimators': 244, 'max_depth': 6, 'learning_rate': 0.18257508917126308, 'subsample': 0.7500221219345313, 'colsample_bytree': 0.9108055114835552, 'gamma': 3.862131632655321, 'min_child_weight': 1}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:54,634] Trial 65 finished with value: 0.8013693270735525 and parameters: {'n_estimators': 125, 'max_depth': 8, 'learning_rate': 0.16247762704436924, 'subsample': 0.9222854847798835, 'colsample_bytree': 0.9990359081435309, 'gamma': 4.306983464962333, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:55,339] Trial 66 finished with value: 0.8068857589984351 and parameters: {'n_estimators': 141, 'max_depth': 10, 'learning_rate': 0.12303640728498834, 'subsample': 0.977682690370224, 'colsample_bytree': 0.9471414381575628, 'gamma': 1.9421763477224885, 'min_child_weight': 2}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:56,007] Trial 67 finished with value: 0.8096635367762129 and parameters: {'n_estimators': 108, 'max_depth': 7, 'learning_rate': 0.13499479077689172, 'subsample': 0.9340972305112021, 'colsample_bytree': 0.973019139018573, 'gamma': 1.2946558200949865, 'min_child_weight': 3}. Best is trial 22 with value: 0.8236697965571205.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:56,826] Trial 68 finished with value: 0.8237089201877934 and parameters: {'n_estimators': 227, 'max_depth': 3, 'learning_rate': 0.09668632746569038, 'subsample': 0.8791794300176844, 'colsample_bytree': 0.9224914880553556, 'gamma': 3.720754367606462, 'min_child_weight': 1}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:57,631] Trial 69 finished with value: 0.81537558685446 and parameters: {'n_estimators': 226, 'max_depth': 6, 'learning_rate': 0.09109401713792895, 'subsample': 0.8834314311443385, 'colsample_bytree': 0.8965954236654828, 'gamma': 2.9984343779790703, 'min_child_weight': 1}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:58,482] Trial 70 finished with value: 0.8013302034428795 and parameters: {'n_estimators': 267, 'max_depth': 6, 'learning_rate': 0.09821508695760622, 'subsample': 0.8672663753165379, 'colsample_bytree': 0.8948126047457612, 'gamma': 3.628889707084414, 'min_child_weight': 1}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:57:59,324] Trial 71 finished with value: 0.8097026604068857 and parameters: {'n_estimators': 224, 'max_depth': 6, 'learning_rate': 0.07658485653230683, 'subsample': 0.897391042908165, 'colsample_bytree': 0.9178074978232377, 'gamma': 3.280697511578752, 'min_child_weight': 1}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:57:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:00,215] Trial 72 finished with value: 0.8125586854460094 and parameters: {'n_estimators': 210, 'max_depth': 5, 'learning_rate': 0.11134591570876896, 'subsample': 0.8874833363491796, 'colsample_bytree': 0.8624652070562249, 'gamma': 3.0666940143292845, 'min_child_weight': 1}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:01,040] Trial 73 finished with value: 0.8181533646322379 and parameters: {'n_estimators': 230, 'max_depth': 7, 'learning_rate': 0.08948131140360659, 'subsample': 0.9159899019266446, 'colsample_bytree': 0.9338290798287767, 'gamma': 2.700828320484751, 'min_child_weight': 2}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:01,810] Trial 74 finished with value: 0.8180751173708922 and parameters: {'n_estimators': 230, 'max_depth': 6, 'learning_rate': 0.1143034731600508, 'subsample': 0.9102280616813038, 'colsample_bytree': 0.896775533533685, 'gamma': 2.3992255365437307, 'min_child_weight': 2}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:02,591] Trial 75 finished with value: 0.818075117370892 and parameters: {'n_estimators': 230, 'max_depth': 7, 'learning_rate': 0.11609051241764654, 'subsample': 0.9170416579702988, 'colsample_bytree': 0.8786397668137877, 'gamma': 2.7102323923940075, 'min_child_weight': 2}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:04,039] Trial 76 finished with value: 0.8153755868544602 and parameters: {'n_estimators': 231, 'max_depth': 7, 'learning_rate': 0.09043600583444478, 'subsample': 0.8546123585628599, 'colsample_bytree': 0.8793402797747565, 'gamma': 2.7603440027507866, 'min_child_weight': 1}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:05,011] Trial 77 finished with value: 0.8181533646322379 and parameters: {'n_estimators': 230, 'max_depth': 7, 'learning_rate': 0.09158793543220127, 'subsample': 0.8535838844294877, 'colsample_bytree': 0.8288837662556076, 'gamma': 2.5770849002100427, 'min_child_weight': 1}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:05,915] Trial 78 finished with value: 0.8181533646322379 and parameters: {'n_estimators': 244, 'max_depth': 7, 'learning_rate': 0.07248748435991227, 'subsample': 0.8635608255287484, 'colsample_bytree': 0.8112583925620755, 'gamma': 2.779059123590292, 'min_child_weight': 1}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:06,799] Trial 79 finished with value: 0.8097026604068857 and parameters: {'n_estimators': 242, 'max_depth': 7, 'learning_rate': 0.05880473980096382, 'subsample': 0.8402337657804355, 'colsample_bytree': 0.8183760581909441, 'gamma': 2.667317908452869, 'min_child_weight': 1}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:08,130] Trial 80 finished with value: 0.806924882629108 and parameters: {'n_estimators': 264, 'max_depth': 7, 'learning_rate': 0.037385817169849844, 'subsample': 0.8267399394945981, 'colsample_bytree': 0.8287542994598395, 'gamma': 2.391349976073638, 'min_child_weight': 1}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:09,026] Trial 81 finished with value: 0.8153364632237871 and parameters: {'n_estimators': 232, 'max_depth': 7, 'learning_rate': 0.07322525893982346, 'subsample': 0.8578331612150879, 'colsample_bytree': 0.7991659127560213, 'gamma': 2.731665236065266, 'min_child_weight': 1}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:10,109] Trial 82 finished with value: 0.8125195618153365 and parameters: {'n_estimators': 238, 'max_depth': 7, 'learning_rate': 0.08780763173231762, 'subsample': 0.8454970527809376, 'colsample_bytree': 0.8782862190967641, 'gamma': 2.473647120017174, 'min_child_weight': 1}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:11,097] Trial 83 finished with value: 0.8153364632237873 and parameters: {'n_estimators': 248, 'max_depth': 7, 'learning_rate': 0.10261644609055222, 'subsample': 0.8602228869152955, 'colsample_bytree': 0.8469504938021108, 'gamma': 2.2695634138859035, 'min_child_weight': 1}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:12,263] Trial 84 finished with value: 0.8097417840375586 and parameters: {'n_estimators': 260, 'max_depth': 7, 'learning_rate': 0.11667246085932825, 'subsample': 0.8046182369938553, 'colsample_bytree': 0.8122525824215685, 'gamma': 2.795530930219881, 'min_child_weight': 2}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:13,163] Trial 85 finished with value: 0.8153755868544602 and parameters: {'n_estimators': 275, 'max_depth': 7, 'learning_rate': 0.08987935019673356, 'subsample': 0.9120018294683155, 'colsample_bytree': 0.8690117330931894, 'gamma': 2.606030568576523, 'min_child_weight': 2}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:14,233] Trial 86 finished with value: 0.7816901408450704 and parameters: {'n_estimators': 245, 'max_depth': 8, 'learning_rate': 0.06832163297236635, 'subsample': 0.8744535457111353, 'colsample_bytree': 0.882798704806415, 'gamma': 2.267702063220508, 'min_child_weight': 7}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:15,136] Trial 87 finished with value: 0.8069640062597809 and parameters: {'n_estimators': 235, 'max_depth': 8, 'learning_rate': 0.10823480487240959, 'subsample': 0.8211065871848306, 'colsample_bytree': 0.9012690084191742, 'gamma': 3.2652036066902443, 'min_child_weight': 1}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:16,513] Trial 88 finished with value: 0.8012910798122066 and parameters: {'n_estimators': 231, 'max_depth': 7, 'learning_rate': 0.05514719236036242, 'subsample': 0.894985625667569, 'colsample_bytree': 0.7784865718935624, 'gamma': 2.560352779249745, 'min_child_weight': 3}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:17,448] Trial 89 finished with value: 0.8068857589984351 and parameters: {'n_estimators': 256, 'max_depth': 7, 'learning_rate': 0.09894611611660167, 'subsample': 0.9030327585193442, 'colsample_bytree': 0.8444475486069164, 'gamma': 1.974627453077104, 'min_child_weight': 2}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:18,443] Trial 90 finished with value: 0.8152973395931143 and parameters: {'n_estimators': 239, 'max_depth': 8, 'learning_rate': 0.08038228133543768, 'subsample': 0.8473195651473286, 'colsample_bytree': 0.7533589959234501, 'gamma': 2.873279074665912, 'min_child_weight': 2}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:19,370] Trial 91 finished with value: 0.8181142410015649 and parameters: {'n_estimators': 276, 'max_depth': 7, 'learning_rate': 0.09181997782574441, 'subsample': 0.9155261135047182, 'colsample_bytree': 0.8685710891224143, 'gamma': 2.717091130590046, 'min_child_weight': 2}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:20,338] Trial 92 finished with value: 0.8069248826291078 and parameters: {'n_estimators': 276, 'max_depth': 7, 'learning_rate': 0.09202321053171361, 'subsample': 0.9146537340708428, 'colsample_bytree': 0.8646046043198465, 'gamma': 2.729066127652886, 'min_child_weight': 2}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:21,478] Trial 93 finished with value: 0.8097809076682317 and parameters: {'n_estimators': 292, 'max_depth': 7, 'learning_rate': 0.07137430531427116, 'subsample': 0.8806680111339801, 'colsample_bytree': 0.8882600287654484, 'gamma': 2.443635916338778, 'min_child_weight': 1}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:22,336] Trial 94 finished with value: 0.8040297339593113 and parameters: {'n_estimators': 212, 'max_depth': 7, 'learning_rate': 0.11887785623977765, 'subsample': 0.863962332980052, 'colsample_bytree': 0.8223082041487978, 'gamma': 3.1163173385220224, 'min_child_weight': 3}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:23,151] Trial 95 finished with value: 0.8209311424100155 and parameters: {'n_estimators': 227, 'max_depth': 8, 'learning_rate': 0.08564779942393987, 'subsample': 0.9039567289487349, 'colsample_bytree': 0.7936748460297481, 'gamma': 2.3089485299776658, 'min_child_weight': 2}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:24,015] Trial 96 finished with value: 0.773317683881064 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.10952541117026124, 'subsample': 0.9170482836977774, 'colsample_bytree': 0.7965725486955122, 'gamma': 2.089739724751348, 'min_child_weight': 8}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:24,902] Trial 97 finished with value: 0.80962441314554 and parameters: {'n_estimators': 197, 'max_depth': 9, 'learning_rate': 0.0841654006821464, 'subsample': 0.8913925800341927, 'colsample_bytree': 0.766250038085699, 'gamma': 2.2524169314566276, 'min_child_weight': 3}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:25,758] Trial 98 finished with value: 0.7816118935837245 and parameters: {'n_estimators': 227, 'max_depth': 8, 'learning_rate': 0.10177432757503922, 'subsample': 0.9059293860441573, 'colsample_bytree': 0.7871195600862452, 'gamma': 2.3523614319844537, 'min_child_weight': 5}. Best is trial 68 with value: 0.8237089201877934.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [03:58:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 03:58:26,794] Trial 99 finished with value: 0.8209311424100157 and parameters: {'n_estimators': 235, 'max_depth': 6, 'learning_rate': 0.06116769795774714, 'subsample': 0.8785063691642399, 'colsample_bytree': 0.9146678439104559, 'gamma': 2.9031635042594353, 'min_child_weight': 2}. Best is trial 68 with value: 0.8237089201877934.
✅ Best XGBoost Parameters: {'n_estimators': 227, 'max_depth': 3, 'learning_rate': 0.09668632746569038, 'subsample': 0.8791794300176844, 'colsample_bytree': 0.9224914880553556, 'gamma': 3.720754367606462, 'min_child_weight': 1}
✅ Best model selected based on F1: XGBoost
02-05-2025 03:58:28 Retraining best model on original full dataset...
02-05-2025 03:58:28 ✅ Exported and logged final model to W&B as artifact: final_model_xgboost.pkl
Requirement already satisfied: wandb in c:\users\x-hp\anaconda3\lib\site-packages (0.19.8)
Requirement already satisfied: click!=8.0.0,>=7.1 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (8.1.7)
Requirement already satisfied: docker-pycreds>=0.4.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (0.4.0)
Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (3.1.43)
Requirement already satisfied: platformdirs in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (3.10.0)
Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (4.25.3)
Requirement already satisfied: psutil>=5.0.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (5.9.0)
Requirement already satisfied: pydantic<3,>=2.6 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (2.8.2)
Requirement already satisfied: pyyaml in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (6.0.1)
Requirement already satisfied: requests<3,>=2.0.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (2.32.3)
Requirement already satisfied: sentry-sdk>=2.0.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (2.18.0)
Requirement already satisfied: setproctitle in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (1.3.5)
Requirement already satisfied: setuptools in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (75.1.0)
Requirement already satisfied: colorama in c:\users\x-hp\anaconda3\lib\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)
Requirement already satisfied: six>=1.4.0 in c:\users\x-hp\anaconda3\lib\site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)
Requirement already satisfied: gitdb<5,>=4.0.1 in c:\users\x-hp\anaconda3\lib\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.7)
Requirement already satisfied: annotated-types>=0.4.0 in c:\users\x-hp\anaconda3\lib\site-packages (from pydantic<3,>=2.6->wandb) (0.6.0)
Requirement already satisfied: pydantic-core==2.20.1 in c:\users\x-hp\anaconda3\lib\site-packages (from pydantic<3,>=2.6->wandb) (2.20.1)
Requirement already satisfied: typing-extensions>=4.6.1 in c:\users\x-hp\anaconda3\lib\site-packages (from pydantic<3,>=2.6->wandb) (4.11.0)
Requirement already satisfied: charset-normalizer<4,>=2 in c:\users\x-hp\anaconda3\lib\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in c:\users\x-hp\anaconda3\lib\site-packages (from requests<3,>=2.0.0->wandb) (3.7)
Requirement already satisfied: urllib3<3,>=1.21.1 in c:\users\x-hp\anaconda3\lib\site-packages (from requests<3,>=2.0.0->wandb) (2.2.3)
Requirement already satisfied: certifi>=2017.4.17 in c:\users\x-hp\anaconda3\lib\site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)
Requirement already satisfied: smmap<5,>=3.0.1 in c:\users\x-hp\anaconda3\lib\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (4.0.0)
[34m[1mwandb[0m: [33mWARNING[0m Calling wandb.login() after wandb.init() has no effect.
02-05-2025 04:06:06 Downloading and reading train artifact
[34m[1mwandb[0m:   1 of 1 files downloaded.
02-05-2025 04:06:08 Spliting data into train/val
02-05-2025 04:06:08 x train: (375, 8)
02-05-2025 04:06:08 y train: (375,)
02-05-2025 04:06:08 x val: (162, 8)
02-05-2025 04:06:08 y val: (162,)
02-05-2025 04:06:08 Outlier Removal
02-05-2025 04:06:08 x_train shape [original]: (375, 8)
02-05-2025 04:06:08 x_train shape [outlier removal]: (357, 8)
02-05-2025 04:06:09 Data after SMOTE: (476, 8)
02-05-2025 04:06:09 [Logistic] Accuracy: 0.7037037037037037
02-05-2025 04:06:09 [Random Forest] Accuracy: 0.691358024691358
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:06:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
02-05-2025 04:06:09 [XGBoost] Accuracy: 0.7098765432098766
                 Model  Accuracy
0  Logistic Regression  0.703704
1        Random Forest  0.691358
2              XGBoost  0.709877
[I 2025-05-02 04:06:12,442] A new study created in memory with name: no-name-f8928361-41dd-45b4-9fe0-16a4492506a1
[I 2025-05-02 04:06:16,143] Trial 0 finished with value: 0.6329007045701269 and parameters: {'n_estimators': 117, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.6329007045701269.
[I 2025-05-02 04:06:18,364] Trial 1 finished with value: 0.6332628611698379 and parameters: {'n_estimators': 116, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.6332628611698379.
[I 2025-05-02 04:06:21,724] Trial 2 finished with value: 0.6731595457682414 and parameters: {'n_estimators': 146, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.6731595457682414.
[I 2025-05-02 04:06:25,603] Trial 3 finished with value: 0.6865348422510642 and parameters: {'n_estimators': 149, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:06:29,587] Trial 4 finished with value: 0.5934798534798535 and parameters: {'n_estimators': 125, 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:06:36,278] Trial 5 finished with value: 0.6259033402908714 and parameters: {'n_estimators': 188, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:06:41,172] Trial 6 finished with value: 0.6026063858622 and parameters: {'n_estimators': 133, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:06:44,828] Trial 7 finished with value: 0.6514641430920501 and parameters: {'n_estimators': 151, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:06:48,635] Trial 8 finished with value: 0.6419220641144733 and parameters: {'n_estimators': 159, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:06:51,052] Trial 9 finished with value: 0.6721917280562376 and parameters: {'n_estimators': 177, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:06:52,525] Trial 10 finished with value: 0.6482539682539683 and parameters: {'n_estimators': 70, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:06:53,918] Trial 11 finished with value: 0.6575934418947994 and parameters: {'n_estimators': 82, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:06:57,436] Trial 12 finished with value: 0.6525832442526666 and parameters: {'n_estimators': 157, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:06:59,653] Trial 13 finished with value: 0.6695636422370927 and parameters: {'n_estimators': 94, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:07:02,866] Trial 14 finished with value: 0.6510207666729405 and parameters: {'n_estimators': 142, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:07:04,285] Trial 15 finished with value: 0.6581000216473347 and parameters: {'n_estimators': 50, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:07:08,421] Trial 16 finished with value: 0.6503085566915354 and parameters: {'n_estimators': 173, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:07:12,490] Trial 17 finished with value: 0.6770651244932164 and parameters: {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:07:17,479] Trial 18 finished with value: 0.6454945867962218 and parameters: {'n_estimators': 199, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:07:21,840] Trial 19 finished with value: 0.676041778714799 and parameters: {'n_estimators': 171, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:07:26,450] Trial 20 finished with value: 0.6675421354906276 and parameters: {'n_estimators': 200, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:07:30,015] Trial 21 finished with value: 0.676041778714799 and parameters: {'n_estimators': 172, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:07:33,212] Trial 22 finished with value: 0.6734978379192393 and parameters: {'n_estimators': 184, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:07:37,287] Trial 23 finished with value: 0.6756470479874734 and parameters: {'n_estimators': 164, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:07:41,527] Trial 24 finished with value: 0.6750289200983003 and parameters: {'n_estimators': 189, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:07:44,785] Trial 25 finished with value: 0.6756470479874734 and parameters: {'n_estimators': 166, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:07:49,281] Trial 26 finished with value: 0.6649330626203891 and parameters: {'n_estimators': 182, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:07:51,993] Trial 27 finished with value: 0.6577267693546763 and parameters: {'n_estimators': 138, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:07:55,360] Trial 28 finished with value: 0.6768098253363835 and parameters: {'n_estimators': 192, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:07:57,549] Trial 29 finished with value: 0.6492287692702845 and parameters: {'n_estimators': 107, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:08:01,210] Trial 30 finished with value: 0.6850681791402894 and parameters: {'n_estimators': 195, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:08:05,730] Trial 31 finished with value: 0.6850681791402894 and parameters: {'n_estimators': 191, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:08:09,445] Trial 32 finished with value: 0.6797490302041191 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:08:13,879] Trial 33 finished with value: 0.6850681791402894 and parameters: {'n_estimators': 192, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:08:18,783] Trial 34 finished with value: 0.6850681791402894 and parameters: {'n_estimators': 180, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:08:20,913] Trial 35 finished with value: 0.6587135367244225 and parameters: {'n_estimators': 116, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:08:22,869] Trial 36 finished with value: 0.6695107239206618 and parameters: {'n_estimators': 126, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.6865348422510642.
[I 2025-05-02 04:08:25,075] Trial 37 finished with value: 0.6868674245607973 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:08:28,946] Trial 38 finished with value: 0.5934798534798535 and parameters: {'n_estimators': 151, 'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:08:30,738] Trial 39 finished with value: 0.6560872740981598 and parameters: {'n_estimators': 106, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:08:33,100] Trial 40 finished with value: 0.6227210112632688 and parameters: {'n_estimators': 149, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:08:37,178] Trial 41 finished with value: 0.6850681791402894 and parameters: {'n_estimators': 189, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:08:39,851] Trial 42 finished with value: 0.6797490302041191 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:08:43,593] Trial 43 finished with value: 0.673486403941493 and parameters: {'n_estimators': 159, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:08:46,134] Trial 44 finished with value: 0.6614979021174834 and parameters: {'n_estimators': 128, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:08:50,835] Trial 45 finished with value: 0.6698923236032266 and parameters: {'n_estimators': 190, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:08:53,496] Trial 46 finished with value: 0.6702802545168571 and parameters: {'n_estimators': 177, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:08:56,178] Trial 47 finished with value: 0.6595592598066621 and parameters: {'n_estimators': 166, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:09:00,234] Trial 48 finished with value: 0.6752114725393967 and parameters: {'n_estimators': 193, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:09:03,642] Trial 49 finished with value: 0.645297157622739 and parameters: {'n_estimators': 157, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:09:07,553] Trial 50 finished with value: 0.6321659665534977 and parameters: {'n_estimators': 180, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:09:11,619] Trial 51 finished with value: 0.6850681791402894 and parameters: {'n_estimators': 183, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:09:16,631] Trial 52 finished with value: 0.6797490302041191 and parameters: {'n_estimators': 195, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:09:20,550] Trial 53 finished with value: 0.6514190404107147 and parameters: {'n_estimators': 176, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:09:24,727] Trial 54 finished with value: 0.6817653837444707 and parameters: {'n_estimators': 184, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:09:28,183] Trial 55 finished with value: 0.6463969518360502 and parameters: {'n_estimators': 171, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:09:30,824] Trial 56 finished with value: 0.6574731133376229 and parameters: {'n_estimators': 146, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:09:34,699] Trial 57 finished with value: 0.6764462348083006 and parameters: {'n_estimators': 163, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:09:38,483] Trial 58 finished with value: 0.6517311314204802 and parameters: {'n_estimators': 186, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.6868674245607973.
[I 2025-05-02 04:09:41,126] Trial 59 finished with value: 0.68722882318627 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.68722882318627.
[I 2025-05-02 04:09:43,993] Trial 60 finished with value: 0.675879917184265 and parameters: {'n_estimators': 120, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 59 with value: 0.68722882318627.
[I 2025-05-02 04:09:47,029] Trial 61 finished with value: 0.68722882318627 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.68722882318627.
[I 2025-05-02 04:09:50,225] Trial 62 finished with value: 0.68722882318627 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.68722882318627.
[I 2025-05-02 04:09:53,476] Trial 63 finished with value: 0.6856794547520189 and parameters: {'n_estimators': 141, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.68722882318627.
[I 2025-05-02 04:09:56,405] Trial 64 finished with value: 0.6856794547520189 and parameters: {'n_estimators': 140, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.68722882318627.
[I 2025-05-02 04:09:59,107] Trial 65 finished with value: 0.667929373835829 and parameters: {'n_estimators': 142, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.68722882318627.
[I 2025-05-02 04:10:01,243] Trial 66 finished with value: 0.6821289742725536 and parameters: {'n_estimators': 133, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 59 with value: 0.68722882318627.
[I 2025-05-02 04:10:04,713] Trial 67 finished with value: 0.6640638746210623 and parameters: {'n_estimators': 142, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.68722882318627.
[I 2025-05-02 04:10:08,126] Trial 68 finished with value: 0.6630629274107535 and parameters: {'n_estimators': 155, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.68722882318627.
[I 2025-05-02 04:10:11,314] Trial 69 finished with value: 0.685008265523938 and parameters: {'n_estimators': 139, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 59 with value: 0.68722882318627.
[I 2025-05-02 04:10:15,069] Trial 70 finished with value: 0.6415176151761518 and parameters: {'n_estimators': 152, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.68722882318627.
[I 2025-05-02 04:10:17,826] Trial 71 finished with value: 0.6748686225992695 and parameters: {'n_estimators': 131, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.68722882318627.
[I 2025-05-02 04:10:21,024] Trial 72 finished with value: 0.6678090014184264 and parameters: {'n_estimators': 121, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 59 with value: 0.68722882318627.
[I 2025-05-02 04:10:23,287] Trial 73 finished with value: 0.6880387728213815 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:10:26,349] Trial 74 finished with value: 0.6856794547520189 and parameters: {'n_estimators': 146, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:10:29,905] Trial 75 finished with value: 0.685008265523938 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:10:32,839] Trial 76 finished with value: 0.6788904181363737 and parameters: {'n_estimators': 148, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:10:36,608] Trial 77 finished with value: 0.6128994261552402 and parameters: {'n_estimators': 143, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:10:39,451] Trial 78 finished with value: 0.6478643578643578 and parameters: {'n_estimators': 153, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:10:43,437] Trial 79 finished with value: 0.6748686225992695 and parameters: {'n_estimators': 131, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:10:47,263] Trial 80 finished with value: 0.6723226049313006 and parameters: {'n_estimators': 160, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:10:51,203] Trial 81 finished with value: 0.6856794547520189 and parameters: {'n_estimators': 144, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:10:54,206] Trial 82 finished with value: 0.6856794547520189 and parameters: {'n_estimators': 138, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:10:56,704] Trial 83 finished with value: 0.6757059399425426 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:10:59,136] Trial 84 finished with value: 0.6655862518534841 and parameters: {'n_estimators': 111, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:11:02,271] Trial 85 finished with value: 0.6786068788542812 and parameters: {'n_estimators': 136, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:11:05,538] Trial 86 finished with value: 0.6734264903251415 and parameters: {'n_estimators': 129, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:11:08,995] Trial 87 finished with value: 0.6584631927531482 and parameters: {'n_estimators': 150, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:11:11,978] Trial 88 finished with value: 0.6819096742500997 and parameters: {'n_estimators': 156, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:11:14,141] Trial 89 finished with value: 0.6689695868647261 and parameters: {'n_estimators': 124, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:11:16,236] Trial 90 finished with value: 0.6690931367823996 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:11:18,289] Trial 91 finished with value: 0.6856794547520189 and parameters: {'n_estimators': 145, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:11:22,352] Trial 92 finished with value: 0.6856794547520189 and parameters: {'n_estimators': 145, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:11:24,892] Trial 93 finished with value: 0.6786068788542812 and parameters: {'n_estimators': 152, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:11:26,823] Trial 94 finished with value: 0.6782719124461215 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:11:27,691] Trial 95 finished with value: 0.6670034559951303 and parameters: {'n_estimators': 56, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:11:31,234] Trial 96 finished with value: 0.6856794547520189 and parameters: {'n_estimators': 162, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:11:33,683] Trial 97 finished with value: 0.6868674245607973 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:11:37,264] Trial 98 finished with value: 0.6391346076684802 and parameters: {'n_estimators': 168, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 73 with value: 0.6880387728213815.
[I 2025-05-02 04:11:40,920] Trial 99 finished with value: 0.6868674245607973 and parameters: {'n_estimators': 149, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 73 with value: 0.6880387728213815.
✅ Best Random Forest Parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1}
[I 2025-05-02 04:11:40,927] A new study created in memory with name: no-name-a43a95f6-d79d-4e83-a10e-ab85bb48b8ee
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:41,328] Trial 0 finished with value: 0.6175197894214217 and parameters: {'n_estimators': 109, 'max_depth': 9, 'learning_rate': 0.29333404573066313, 'subsample': 0.7138427698239164, 'colsample_bytree': 0.9674966362357883, 'gamma': 2.609676587162984, 'min_child_weight': 6}. Best is trial 0 with value: 0.6175197894214217.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:41,901] Trial 1 finished with value: 0.6364158981115503 and parameters: {'n_estimators': 182, 'max_depth': 4, 'learning_rate': 0.16940676301796997, 'subsample': 0.6268919478629675, 'colsample_bytree': 0.9269152144747037, 'gamma': 2.3613698502542912, 'min_child_weight': 5}. Best is trial 1 with value: 0.6364158981115503.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:42,452] Trial 2 finished with value: 0.6687617886276536 and parameters: {'n_estimators': 236, 'max_depth': 8, 'learning_rate': 0.22224185420475692, 'subsample': 0.8269952706257023, 'colsample_bytree': 0.7030268651007597, 'gamma': 4.31183365031383, 'min_child_weight': 4}. Best is trial 2 with value: 0.6687617886276536.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:43,010] Trial 3 finished with value: 0.6301336344814605 and parameters: {'n_estimators': 219, 'max_depth': 6, 'learning_rate': 0.10517684287234866, 'subsample': 0.8557974801485848, 'colsample_bytree': 0.6731308458668289, 'gamma': 4.111103460631858, 'min_child_weight': 7}. Best is trial 2 with value: 0.6687617886276536.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:43,747] Trial 4 finished with value: 0.6153765619723066 and parameters: {'n_estimators': 258, 'max_depth': 10, 'learning_rate': 0.19285239626538653, 'subsample': 0.8416669999622786, 'colsample_bytree': 0.7572425750481062, 'gamma': 0.41249344293137036, 'min_child_weight': 10}. Best is trial 2 with value: 0.6687617886276536.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:44,225] Trial 5 finished with value: 0.6791509636302356 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.1671878513060319, 'subsample': 0.9373839274048523, 'colsample_bytree': 0.7217293516309425, 'gamma': 2.457053100322024, 'min_child_weight': 1}. Best is trial 5 with value: 0.6791509636302356.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:44,892] Trial 6 finished with value: 0.6239108409321175 and parameters: {'n_estimators': 235, 'max_depth': 5, 'learning_rate': 0.26361206808048754, 'subsample': 0.6089125198432412, 'colsample_bytree': 0.9365751641431103, 'gamma': 4.08787736146347, 'min_child_weight': 8}. Best is trial 5 with value: 0.6791509636302356.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:45,403] Trial 7 finished with value: 0.6548089591567853 and parameters: {'n_estimators': 101, 'max_depth': 8, 'learning_rate': 0.055137588951268156, 'subsample': 0.7482687717639682, 'colsample_bytree': 0.9086410351179952, 'gamma': 2.139793287348204, 'min_child_weight': 6}. Best is trial 5 with value: 0.6791509636302356.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:46,171] Trial 8 finished with value: 0.6103126126694445 and parameters: {'n_estimators': 259, 'max_depth': 4, 'learning_rate': 0.29192045422190377, 'subsample': 0.7578198233137002, 'colsample_bytree': 0.9772127514845235, 'gamma': 0.30696288850335596, 'min_child_weight': 9}. Best is trial 5 with value: 0.6791509636302356.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:46,728] Trial 9 finished with value: 0.6138811369509044 and parameters: {'n_estimators': 206, 'max_depth': 4, 'learning_rate': 0.20424517438063233, 'subsample': 0.7111438963454962, 'colsample_bytree': 0.9423948167901194, 'gamma': 1.8228243269927613, 'min_child_weight': 9}. Best is trial 5 with value: 0.6791509636302356.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:47,543] Trial 10 finished with value: 0.6647132545909672 and parameters: {'n_estimators': 163, 'max_depth': 6, 'learning_rate': 0.10678643779433586, 'subsample': 0.9981500427689706, 'colsample_bytree': 0.6004554324427365, 'gamma': 3.226227101689021, 'min_child_weight': 1}. Best is trial 5 with value: 0.6791509636302356.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:48,288] Trial 11 finished with value: 0.6843456750289049 and parameters: {'n_estimators': 298, 'max_depth': 8, 'learning_rate': 0.2306696639688079, 'subsample': 0.9479599613802333, 'colsample_bytree': 0.7800303115193866, 'gamma': 4.595047213738819, 'min_child_weight': 2}. Best is trial 11 with value: 0.6843456750289049.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:49,119] Trial 12 finished with value: 0.7119030732860521 and parameters: {'n_estimators': 297, 'max_depth': 7, 'learning_rate': 0.12243826068347863, 'subsample': 0.9505196173524697, 'colsample_bytree': 0.8284529190052956, 'gamma': 1.3538624493439229, 'min_child_weight': 1}. Best is trial 12 with value: 0.7119030732860521.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:50,001] Trial 13 finished with value: 0.6896486605182257 and parameters: {'n_estimators': 299, 'max_depth': 8, 'learning_rate': 0.11337176005690967, 'subsample': 0.9279238867617965, 'colsample_bytree': 0.8383943900674781, 'gamma': 1.229838085775853, 'min_child_weight': 3}. Best is trial 12 with value: 0.7119030732860521.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:50,977] Trial 14 finished with value: 0.6937694334650856 and parameters: {'n_estimators': 298, 'max_depth': 7, 'learning_rate': 0.10266713587268081, 'subsample': 0.8981161509301202, 'colsample_bytree': 0.849112065511881, 'gamma': 1.202350388704711, 'min_child_weight': 3}. Best is trial 12 with value: 0.7119030732860521.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:51,945] Trial 15 finished with value: 0.6646480331262941 and parameters: {'n_estimators': 261, 'max_depth': 7, 'learning_rate': 0.03331908027331293, 'subsample': 0.8965485388170916, 'colsample_bytree': 0.8548707220718611, 'gamma': 1.1407748071157402, 'min_child_weight': 3}. Best is trial 12 with value: 0.7119030732860521.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:52,753] Trial 16 finished with value: 0.6814348728593669 and parameters: {'n_estimators': 269, 'max_depth': 7, 'learning_rate': 0.07279947807247841, 'subsample': 0.9942319570236132, 'colsample_bytree': 0.851201011494766, 'gamma': 1.1721930443844224, 'min_child_weight': 3}. Best is trial 12 with value: 0.7119030732860521.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:53,631] Trial 17 finished with value: 0.6878921326076199 and parameters: {'n_estimators': 282, 'max_depth': 10, 'learning_rate': 0.13329231935354682, 'subsample': 0.88696449213633, 'colsample_bytree': 0.8843694160188241, 'gamma': 0.7709010865550442, 'min_child_weight': 2}. Best is trial 12 with value: 0.7119030732860521.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:54,416] Trial 18 finished with value: 0.611896012936729 and parameters: {'n_estimators': 150, 'max_depth': 6, 'learning_rate': 0.012483450864038459, 'subsample': 0.8936483976689681, 'colsample_bytree': 0.8188024979852307, 'gamma': 1.598057281042927, 'min_child_weight': 4}. Best is trial 12 with value: 0.7119030732860521.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:55,183] Trial 19 finished with value: 0.7029808286951145 and parameters: {'n_estimators': 277, 'max_depth': 3, 'learning_rate': 0.07021248840956794, 'subsample': 0.9607442762554366, 'colsample_bytree': 0.7899843360141635, 'gamma': 3.169753886852604, 'min_child_weight': 1}. Best is trial 12 with value: 0.7119030732860521.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:55,934] Trial 20 finished with value: 0.6946070460704608 and parameters: {'n_estimators': 238, 'max_depth': 3, 'learning_rate': 0.06356134043309532, 'subsample': 0.9756632863221774, 'colsample_bytree': 0.7666599411710568, 'gamma': 3.371231520545035, 'min_child_weight': 1}. Best is trial 12 with value: 0.7119030732860521.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:57,022] Trial 21 finished with value: 0.69743961352657 and parameters: {'n_estimators': 240, 'max_depth': 3, 'learning_rate': 0.07202595866702757, 'subsample': 0.9745145121855906, 'colsample_bytree': 0.7812171565387337, 'gamma': 3.4281919495325215, 'min_child_weight': 1}. Best is trial 12 with value: 0.7119030732860521.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:57,801] Trial 22 finished with value: 0.7159380457762662 and parameters: {'n_estimators': 283, 'max_depth': 3, 'learning_rate': 0.0790277452604645, 'subsample': 0.962639689726688, 'colsample_bytree': 0.8034415539997891, 'gamma': 3.199408555017131, 'min_child_weight': 2}. Best is trial 22 with value: 0.7159380457762662.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:58,528] Trial 23 finished with value: 0.7022727272727273 and parameters: {'n_estimators': 274, 'max_depth': 3, 'learning_rate': 0.13721430164754503, 'subsample': 0.9416921292533612, 'colsample_bytree': 0.7985975437883444, 'gamma': 2.881595347098404, 'min_child_weight': 2}. Best is trial 22 with value: 0.7159380457762662.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:11:59,306] Trial 24 finished with value: 0.7016479345361333 and parameters: {'n_estimators': 281, 'max_depth': 5, 'learning_rate': 0.08571910636322294, 'subsample': 0.799989964770538, 'colsample_bytree': 0.7278253891327587, 'gamma': 3.617902024219592, 'min_child_weight': 2}. Best is trial 22 with value: 0.7159380457762662.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:11:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:01,424] Trial 25 finished with value: 0.6716014217862205 and parameters: {'n_estimators': 283, 'max_depth': 4, 'learning_rate': 0.030772127814663257, 'subsample': 0.9620926879377523, 'colsample_bytree': 0.8764372226106941, 'gamma': 3.014305327581022, 'min_child_weight': 4}. Best is trial 22 with value: 0.7159380457762662.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:02,887] Trial 26 finished with value: 0.7019675010979359 and parameters: {'n_estimators': 253, 'max_depth': 3, 'learning_rate': 0.14191533702509523, 'subsample': 0.9182978177872771, 'colsample_bytree': 0.8217604055991773, 'gamma': 3.684639058869389, 'min_child_weight': 1}. Best is trial 22 with value: 0.7159380457762662.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:03,775] Trial 27 finished with value: 0.7038501291989665 and parameters: {'n_estimators': 222, 'max_depth': 5, 'learning_rate': 0.08615161931619342, 'subsample': 0.8643548261929273, 'colsample_bytree': 0.6745357576530797, 'gamma': 1.9902015272229492, 'min_child_weight': 2}. Best is trial 22 with value: 0.7159380457762662.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:06,096] Trial 28 finished with value: 0.6614540408712472 and parameters: {'n_estimators': 217, 'max_depth': 5, 'learning_rate': 0.03988245017352321, 'subsample': 0.8708818203396269, 'colsample_bytree': 0.6615602042357164, 'gamma': 2.0189173494297483, 'min_child_weight': 5}. Best is trial 22 with value: 0.7159380457762662.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:07,782] Trial 29 finished with value: 0.6926919518963922 and parameters: {'n_estimators': 178, 'max_depth': 6, 'learning_rate': 0.12263603913160159, 'subsample': 0.8034704402710394, 'colsample_bytree': 0.6248544761961403, 'gamma': 2.767279481363129, 'min_child_weight': 2}. Best is trial 22 with value: 0.7159380457762662.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:08,443] Trial 30 finished with value: 0.6425846942631572 and parameters: {'n_estimators': 124, 'max_depth': 9, 'learning_rate': 0.08992227176018602, 'subsample': 0.9134887134425008, 'colsample_bytree': 0.7273631068623116, 'gamma': 1.5663490815386252, 'min_child_weight': 4}. Best is trial 22 with value: 0.7159380457762662.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:09,845] Trial 31 finished with value: 0.7183343640486498 and parameters: {'n_estimators': 290, 'max_depth': 4, 'learning_rate': 0.09011681563194203, 'subsample': 0.9657354135387831, 'colsample_bytree': 0.8143060605623438, 'gamma': 2.5950360988392127, 'min_child_weight': 2}. Best is trial 31 with value: 0.7183343640486498.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:11,078] Trial 32 finished with value: 0.6940392388839595 and parameters: {'n_estimators': 286, 'max_depth': 4, 'learning_rate': 0.16038420224847785, 'subsample': 0.9979396255741678, 'colsample_bytree': 0.7528237171619514, 'gamma': 2.5367411401223636, 'min_child_weight': 2}. Best is trial 31 with value: 0.7183343640486498.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:12,145] Trial 33 finished with value: 0.6616091348265261 and parameters: {'n_estimators': 250, 'max_depth': 5, 'learning_rate': 0.0943507104819644, 'subsample': 0.6608536029307803, 'colsample_bytree': 0.8127485024813079, 'gamma': 2.2007290641749737, 'min_child_weight': 3}. Best is trial 31 with value: 0.7183343640486498.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:13,067] Trial 34 finished with value: 0.6358715818343147 and parameters: {'n_estimators': 196, 'max_depth': 4, 'learning_rate': 0.11653076014077948, 'subsample': 0.8608627476305301, 'colsample_bytree': 0.6862369519969282, 'gamma': 1.796291983772323, 'min_child_weight': 5}. Best is trial 31 with value: 0.7183343640486498.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:14,062] Trial 35 finished with value: 0.6839222007307114 and parameters: {'n_estimators': 226, 'max_depth': 4, 'learning_rate': 0.04551494313479271, 'subsample': 0.8272186146471213, 'colsample_bytree': 0.8787199752530312, 'gamma': 4.99842816095026, 'min_child_weight': 2}. Best is trial 31 with value: 0.7183343640486498.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:15,822] Trial 36 finished with value: 0.6664361001317523 and parameters: {'n_estimators': 289, 'max_depth': 5, 'learning_rate': 0.15106587529328502, 'subsample': 0.9184591722539764, 'colsample_bytree': 0.7523694110016805, 'gamma': 0.6865152807872414, 'min_child_weight': 3}. Best is trial 31 with value: 0.7183343640486498.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:17,145] Trial 37 finished with value: 0.7089637993613641 and parameters: {'n_estimators': 263, 'max_depth': 9, 'learning_rate': 0.180489392849036, 'subsample': 0.9748962095754886, 'colsample_bytree': 0.9042382828830927, 'gamma': 2.5659808546736045, 'min_child_weight': 4}. Best is trial 31 with value: 0.7183343640486498.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:18,295] Trial 38 finished with value: 0.6642618733923081 and parameters: {'n_estimators': 270, 'max_depth': 9, 'learning_rate': 0.18916569412548642, 'subsample': 0.9775970257381364, 'colsample_bytree': 0.8945978344676007, 'gamma': 2.6356476740849577, 'min_child_weight': 7}. Best is trial 31 with value: 0.7183343640486498.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:20,224] Trial 39 finished with value: 0.6753094321221378 and parameters: {'n_estimators': 266, 'max_depth': 10, 'learning_rate': 0.1764142350284362, 'subsample': 0.953301853975448, 'colsample_bytree': 0.9912192727605462, 'gamma': 2.3574400557158923, 'min_child_weight': 4}. Best is trial 31 with value: 0.7183343640486498.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:21,612] Trial 40 finished with value: 0.6091416055697929 and parameters: {'n_estimators': 291, 'max_depth': 9, 'learning_rate': 0.2246350111627871, 'subsample': 0.9357583758753673, 'colsample_bytree': 0.9187158369988571, 'gamma': 0.014557032151603533, 'min_child_weight': 6}. Best is trial 31 with value: 0.7183343640486498.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:22,480] Trial 41 finished with value: 0.700627262701508 and parameters: {'n_estimators': 250, 'max_depth': 4, 'learning_rate': 0.08713978443565966, 'subsample': 0.9747040029483849, 'colsample_bytree': 0.8308403810257631, 'gamma': 2.3913883924550587, 'min_child_weight': 1}. Best is trial 31 with value: 0.7183343640486498.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:23,235] Trial 42 finished with value: 0.7194949494949495 and parameters: {'n_estimators': 201, 'max_depth': 6, 'learning_rate': 0.13192781499017509, 'subsample': 0.9485071042277902, 'colsample_bytree': 0.8646495943775862, 'gamma': 1.9844970570929337, 'min_child_weight': 2}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:24,124] Trial 43 finished with value: 0.6617193860598977 and parameters: {'n_estimators': 140, 'max_depth': 7, 'learning_rate': 0.12272802311084269, 'subsample': 0.956929424025488, 'colsample_bytree': 0.8651633409181864, 'gamma': 3.8764963377215462, 'min_child_weight': 5}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:25,137] Trial 44 finished with value: 0.6990091974894407 and parameters: {'n_estimators': 190, 'max_depth': 8, 'learning_rate': 0.17870457719943034, 'subsample': 0.9351638540526158, 'colsample_bytree': 0.9066429735189397, 'gamma': 2.8600134713659777, 'min_child_weight': 1}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:26,003] Trial 45 finished with value: 0.6987416310397677 and parameters: {'n_estimators': 172, 'max_depth': 8, 'learning_rate': 0.20195853521946167, 'subsample': 0.9106765823798857, 'colsample_bytree': 0.949032710645578, 'gamma': 1.5265821815530012, 'min_child_weight': 3}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:27,381] Trial 46 finished with value: 0.6841438703140831 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.2454088850552899, 'subsample': 0.9866318350207203, 'colsample_bytree': 0.8067048825549935, 'gamma': 2.158852633435182, 'min_child_weight': 2}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:28,332] Trial 47 finished with value: 0.6875833759063572 and parameters: {'n_estimators': 204, 'max_depth': 7, 'learning_rate': 0.1516280454746416, 'subsample': 0.9632812003238247, 'colsample_bytree': 0.8376474452772739, 'gamma': 2.6319793124592104, 'min_child_weight': 4}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:29,942] Trial 48 finished with value: 0.6550491969837581 and parameters: {'n_estimators': 291, 'max_depth': 9, 'learning_rate': 0.10363335644564625, 'subsample': 0.8819183670084714, 'colsample_bytree': 0.9511319284817882, 'gamma': 0.9296704708802659, 'min_child_weight': 3}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:31,758] Trial 49 finished with value: 0.7012923351158645 and parameters: {'n_estimators': 263, 'max_depth': 10, 'learning_rate': 0.1336252077898673, 'subsample': 0.7001372722403172, 'colsample_bytree': 0.9015242217172023, 'gamma': 1.8018471092470145, 'min_child_weight': 1}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:33,382] Trial 50 finished with value: 0.6206609574000879 and parameters: {'n_estimators': 275, 'max_depth': 3, 'learning_rate': 0.1661969627637289, 'subsample': 0.8423011571252211, 'colsample_bytree': 0.922278653658883, 'gamma': 1.4858403621429626, 'min_child_weight': 7}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:36,085] Trial 51 finished with value: 0.7187384044526902 and parameters: {'n_estimators': 225, 'max_depth': 5, 'learning_rate': 0.055299468666211424, 'subsample': 0.9485347327538725, 'colsample_bytree': 0.8588432957391278, 'gamma': 2.05397485966063, 'min_child_weight': 2}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:38,369] Trial 52 finished with value: 0.7007586064728921 and parameters: {'n_estimators': 209, 'max_depth': 6, 'learning_rate': 0.02186429600974687, 'subsample': 0.9457280356181199, 'colsample_bytree': 0.8515339996796157, 'gamma': 2.2991353031067048, 'min_child_weight': 2}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:40,254] Trial 53 finished with value: 0.7072379471333312 and parameters: {'n_estimators': 231, 'max_depth': 6, 'learning_rate': 0.05949285826446847, 'subsample': 0.9273945339643261, 'colsample_bytree': 0.8661628298236232, 'gamma': 3.1973501196940415, 'min_child_weight': 1}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:41,258] Trial 54 finished with value: 0.6403134674846914 and parameters: {'n_estimators': 214, 'max_depth': 5, 'learning_rate': 0.049763037062343744, 'subsample': 0.9999628451045441, 'colsample_bytree': 0.834884832575295, 'gamma': 1.896575113142696, 'min_child_weight': 10}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:42,221] Trial 55 finished with value: 0.6622343308539469 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.07439754148197751, 'subsample': 0.98095829270349, 'colsample_bytree': 0.8013402300955733, 'gamma': 1.3218532924889452, 'min_child_weight': 3}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:43,219] Trial 56 finished with value: 0.6916730750271123 and parameters: {'n_estimators': 293, 'max_depth': 4, 'learning_rate': 0.2992793037335218, 'subsample': 0.9008700360866042, 'colsample_bytree': 0.8862319077874977, 'gamma': 2.9288754555241607, 'min_child_weight': 2}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:44,078] Trial 57 finished with value: 0.7157693815645572 and parameters: {'n_estimators': 241, 'max_depth': 6, 'learning_rate': 0.09720848119127556, 'subsample': 0.9609889129259265, 'colsample_bytree': 0.7765140229854842, 'gamma': 2.7042081141756404, 'min_child_weight': 1}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:45,046] Trial 58 finished with value: 0.7085800328036352 and parameters: {'n_estimators': 242, 'max_depth': 7, 'learning_rate': 0.11381340718492519, 'subsample': 0.9471137876144109, 'colsample_bytree': 0.7428947893702681, 'gamma': 3.093117099923811, 'min_child_weight': 1}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:45,902] Trial 59 finished with value: 0.6847787909490037 and parameters: {'n_estimators': 196, 'max_depth': 6, 'learning_rate': 0.09990167710928408, 'subsample': 0.9245994296795326, 'colsample_bytree': 0.7864853033982524, 'gamma': 3.495226990450628, 'min_child_weight': 1}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:46,864] Trial 60 finished with value: 0.7119575524544468 and parameters: {'n_estimators': 230, 'max_depth': 6, 'learning_rate': 0.06442588171127274, 'subsample': 0.7649383614801502, 'colsample_bytree': 0.7666412714447024, 'gamma': 2.7461794807314197, 'min_child_weight': 2}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:47,854] Trial 61 finished with value: 0.699168591050723 and parameters: {'n_estimators': 230, 'max_depth': 6, 'learning_rate': 0.07935906674635301, 'subsample': 0.7617104910598171, 'colsample_bytree': 0.8225201686732171, 'gamma': 2.7624591585726717, 'min_child_weight': 2}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:49,249] Trial 62 finished with value: 0.685058087947009 and parameters: {'n_estimators': 246, 'max_depth': 7, 'learning_rate': 0.06148184552035042, 'subsample': 0.7343315662219251, 'colsample_bytree': 0.775578311518867, 'gamma': 2.0618739160301867, 'min_child_weight': 2}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:50,378] Trial 63 finished with value: 0.7035922669463042 and parameters: {'n_estimators': 257, 'max_depth': 6, 'learning_rate': 0.12244971776760681, 'subsample': 0.7775753311774456, 'colsample_bytree': 0.7677424084802454, 'gamma': 1.6961977697179265, 'min_child_weight': 1}. Best is trial 42 with value: 0.7194949494949495.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:51,283] Trial 64 finished with value: 0.7210308945712672 and parameters: {'n_estimators': 213, 'max_depth': 5, 'learning_rate': 0.0962704324433075, 'subsample': 0.9610906908396217, 'colsample_bytree': 0.7062662904448227, 'gamma': 3.3014792525980017, 'min_child_weight': 1}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:52,055] Trial 65 finished with value: 0.6891150169596052 and parameters: {'n_estimators': 212, 'max_depth': 5, 'learning_rate': 0.08047492273595971, 'subsample': 0.7959816554602923, 'colsample_bytree': 0.7104243196850011, 'gamma': 3.286456210230592, 'min_child_weight': 2}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:52,946] Trial 66 finished with value: 0.6921519543258674 and parameters: {'n_estimators': 222, 'max_depth': 5, 'learning_rate': 0.06725165933159191, 'subsample': 0.9570144189925288, 'colsample_bytree': 0.7988752038791885, 'gamma': 3.8668922842011746, 'min_child_weight': 3}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:53,725] Trial 67 finished with value: 0.7052996692748246 and parameters: {'n_estimators': 232, 'max_depth': 6, 'learning_rate': 0.05474172825928124, 'subsample': 0.9879370866260522, 'colsample_bytree': 0.7355960973770818, 'gamma': 3.076445509129786, 'min_child_weight': 2}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:54,418] Trial 68 finished with value: 0.6299265951439864 and parameters: {'n_estimators': 204, 'max_depth': 4, 'learning_rate': 0.09636378636286824, 'subsample': 0.7354242430770187, 'colsample_bytree': 0.7081913082952931, 'gamma': 2.7843457713301323, 'min_child_weight': 9}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:55,262] Trial 69 finished with value: 0.7056949261918206 and parameters: {'n_estimators': 219, 'max_depth': 3, 'learning_rate': 0.0372932743593067, 'subsample': 0.9661510665360994, 'colsample_bytree': 0.7631678647683686, 'gamma': 2.26137612012489, 'min_child_weight': 1}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:56,079] Trial 70 finished with value: 0.7175693101225016 and parameters: {'n_estimators': 226, 'max_depth': 5, 'learning_rate': 0.10649088066355551, 'subsample': 0.9036691890607741, 'colsample_bytree': 0.7889676267866512, 'gamma': 2.4749301249188265, 'min_child_weight': 3}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:57,086] Trial 71 finished with value: 0.715275559499162 and parameters: {'n_estimators': 239, 'max_depth': 5, 'learning_rate': 0.10514980944888057, 'subsample': 0.9384998212868401, 'colsample_bytree': 0.7931941375920069, 'gamma': 2.4378794579666674, 'min_child_weight': 2}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:57,946] Trial 72 finished with value: 0.698727308835459 and parameters: {'n_estimators': 239, 'max_depth': 5, 'learning_rate': 0.1064075622404409, 'subsample': 0.9051421114710236, 'colsample_bytree': 0.8116819846651876, 'gamma': 2.473674783032842, 'min_child_weight': 3}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:58,670] Trial 73 finished with value: 0.6945662481066208 and parameters: {'n_estimators': 225, 'max_depth': 4, 'learning_rate': 0.11193305754503019, 'subsample': 0.9363079609517111, 'colsample_bytree': 0.6405523533937754, 'gamma': 2.997929965842531, 'min_child_weight': 2}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:12:59,358] Trial 74 finished with value: 0.7080610900486677 and parameters: {'n_estimators': 195, 'max_depth': 5, 'learning_rate': 0.1282537368085454, 'subsample': 0.9681794669789773, 'colsample_bytree': 0.8451560449014159, 'gamma': 1.9540306074961014, 'min_child_weight': 1}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:12:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:00,159] Trial 75 finished with value: 0.6945195074077061 and parameters: {'n_estimators': 213, 'max_depth': 5, 'learning_rate': 0.09393732511529852, 'subsample': 0.8837413469868952, 'colsample_bytree': 0.7911750076969959, 'gamma': 2.4639424050931824, 'min_child_weight': 1}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:01,485] Trial 76 finished with value: 0.7165451370976432 and parameters: {'n_estimators': 235, 'max_depth': 4, 'learning_rate': 0.08105749380776636, 'subsample': 0.9467321622143311, 'colsample_bytree': 0.8620833578897544, 'gamma': 3.5572446638260904, 'min_child_weight': 2}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:02,288] Trial 77 finished with value: 0.6777823994659642 and parameters: {'n_estimators': 247, 'max_depth': 3, 'learning_rate': 0.14588139275429898, 'subsample': 0.9517182206324007, 'colsample_bytree': 0.8654602672120456, 'gamma': 4.16997705782587, 'min_child_weight': 3}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:03,027] Trial 78 finished with value: 0.682889874353289 and parameters: {'n_estimators': 208, 'max_depth': 4, 'learning_rate': 0.07744482860720339, 'subsample': 0.9884596947476969, 'colsample_bytree': 0.8563948681787228, 'gamma': 3.4631974180903278, 'min_child_weight': 1}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:03,794] Trial 79 finished with value: 0.6898457109441771 and parameters: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.08234345609456255, 'subsample': 0.9277560630725213, 'colsample_bytree': 0.8182196122040933, 'gamma': 3.6449803802384855, 'min_child_weight': 2}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:04,835] Trial 80 finished with value: 0.7072332015810276 and parameters: {'n_estimators': 255, 'max_depth': 4, 'learning_rate': 0.08933292619745231, 'subsample': 0.9667836951209594, 'colsample_bytree': 0.685836638716425, 'gamma': 3.2982308003337986, 'min_child_weight': 2}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:05,719] Trial 81 finished with value: 0.708169673666568 and parameters: {'n_estimators': 236, 'max_depth': 5, 'learning_rate': 0.11215747495610273, 'subsample': 0.940676990427954, 'colsample_bytree': 0.782066365396682, 'gamma': 2.164621605023553, 'min_child_weight': 3}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:06,728] Trial 82 finished with value: 0.7115535120504065 and parameters: {'n_estimators': 226, 'max_depth': 5, 'learning_rate': 0.10143565108022749, 'subsample': 0.9173065230607823, 'colsample_bytree': 0.8427262593792295, 'gamma': 2.697706123086015, 'min_child_weight': 2}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:07,661] Trial 83 finished with value: 0.6958984853156917 and parameters: {'n_estimators': 279, 'max_depth': 3, 'learning_rate': 0.12731907230436237, 'subsample': 0.9465201355681524, 'colsample_bytree': 0.8304918679454083, 'gamma': 3.793127357537522, 'min_child_weight': 2}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:08,609] Trial 84 finished with value: 0.6996431036182589 and parameters: {'n_estimators': 244, 'max_depth': 5, 'learning_rate': 0.0948346738732804, 'subsample': 0.9313732625482447, 'colsample_bytree': 0.7935087938260237, 'gamma': 2.31788563069196, 'min_child_weight': 3}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:09,340] Trial 85 finished with value: 0.7145836108135689 and parameters: {'n_estimators': 217, 'max_depth': 4, 'learning_rate': 0.10607642453660637, 'subsample': 0.9557469873021398, 'colsample_bytree': 0.7497524630185466, 'gamma': 2.5519923494498626, 'min_child_weight': 2}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:10,089] Trial 86 finished with value: 0.6903493985156015 and parameters: {'n_estimators': 235, 'max_depth': 6, 'learning_rate': 0.07020816260843199, 'subsample': 0.9790262629493631, 'colsample_bytree': 0.873078363879049, 'gamma': 3.5490405120715853, 'min_child_weight': 1}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:10,963] Trial 87 finished with value: 0.6791577156215841 and parameters: {'n_estimators': 268, 'max_depth': 5, 'learning_rate': 0.2783932586194341, 'subsample': 0.9696074489759731, 'colsample_bytree': 0.8875719788381844, 'gamma': 2.9361307226208977, 'min_child_weight': 1}. Best is trial 64 with value: 0.7210308945712672.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:11,923] Trial 88 finished with value: 0.7263881179977387 and parameters: {'n_estimators': 173, 'max_depth': 3, 'learning_rate': 0.1190189196479002, 'subsample': 0.8938506136081646, 'colsample_bytree': 0.8080499753799478, 'gamma': 3.198138137857171, 'min_child_weight': 2}. Best is trial 88 with value: 0.7263881179977387.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:12,896] Trial 89 finished with value: 0.6866974088713219 and parameters: {'n_estimators': 151, 'max_depth': 3, 'learning_rate': 0.048367591249887654, 'subsample': 0.8758447004195677, 'colsample_bytree': 0.808857649437739, 'gamma': 3.361803998696738, 'min_child_weight': 3}. Best is trial 88 with value: 0.7263881179977387.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:13,525] Trial 90 finished with value: 0.6962121212121212 and parameters: {'n_estimators': 178, 'max_depth': 3, 'learning_rate': 0.13964956607760037, 'subsample': 0.8964747358567747, 'colsample_bytree': 0.8564669885977106, 'gamma': 4.002420788891546, 'min_child_weight': 1}. Best is trial 88 with value: 0.7263881179977387.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:14,424] Trial 91 finished with value: 0.7017878481478077 and parameters: {'n_estimators': 225, 'max_depth': 3, 'learning_rate': 0.08644830023664934, 'subsample': 0.9110718167264934, 'colsample_bytree': 0.8252938898580896, 'gamma': 3.183318151987767, 'min_child_weight': 2}. Best is trial 88 with value: 0.7263881179977387.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:15,181] Trial 92 finished with value: 0.7175899432767535 and parameters: {'n_estimators': 202, 'max_depth': 4, 'learning_rate': 0.11471390757631277, 'subsample': 0.9222425205273092, 'colsample_bytree': 0.8032498523537037, 'gamma': 2.8644450913319783, 'min_child_weight': 2}. Best is trial 88 with value: 0.7263881179977387.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:16,315] Trial 93 finished with value: 0.6905044231131188 and parameters: {'n_estimators': 173, 'max_depth': 4, 'learning_rate': 0.1174119706251816, 'subsample': 0.8490858892855804, 'colsample_bytree': 0.8027928048291803, 'gamma': 3.122119565801467, 'min_child_weight': 2}. Best is trial 88 with value: 0.7263881179977387.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:17,225] Trial 94 finished with value: 0.6889744637824581 and parameters: {'n_estimators': 190, 'max_depth': 4, 'learning_rate': 0.11952231066858947, 'subsample': 0.9221478973869396, 'colsample_bytree': 0.7730879206113161, 'gamma': 2.9020719660512695, 'min_child_weight': 3}. Best is trial 88 with value: 0.7263881179977387.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:17,912] Trial 95 finished with value: 0.7074352217830479 and parameters: {'n_estimators': 163, 'max_depth': 3, 'learning_rate': 0.13094666368886282, 'subsample': 0.9599985225635291, 'colsample_bytree': 0.8382707482490742, 'gamma': 2.6304484724283106, 'min_child_weight': 2}. Best is trial 88 with value: 0.7263881179977387.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:18,747] Trial 96 finished with value: 0.6860142417658069 and parameters: {'n_estimators': 201, 'max_depth': 4, 'learning_rate': 0.144325214639492, 'subsample': 0.9475023984390464, 'colsample_bytree': 0.8131221687118582, 'gamma': 3.036297532737639, 'min_child_weight': 1}. Best is trial 88 with value: 0.7263881179977387.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:19,549] Trial 97 finished with value: 0.7033526756931012 and parameters: {'n_estimators': 285, 'max_depth': 3, 'learning_rate': 0.09135662395922652, 'subsample': 0.8886215683001192, 'colsample_bytree': 0.7831435553930712, 'gamma': 3.2810045866879802, 'min_child_weight': 1}. Best is trial 88 with value: 0.7263881179977387.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:20,193] Trial 98 finished with value: 0.6805787757314121 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.0996363967223772, 'subsample': 0.9059817138899426, 'colsample_bytree': 0.7596859320674274, 'gamma': 3.7500330639636754, 'min_child_weight': 2}. Best is trial 88 with value: 0.7263881179977387.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:13:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:13:20,877] Trial 99 finished with value: 0.6627828007936865 and parameters: {'n_estimators': 211, 'max_depth': 4, 'learning_rate': 0.1584871711586715, 'subsample': 0.9836861477279791, 'colsample_bytree': 0.8748850522761085, 'gamma': 3.543766389070598, 'min_child_weight': 3}. Best is trial 88 with value: 0.7263881179977387.
✅ Best XGBoost Parameters: {'n_estimators': 173, 'max_depth': 3, 'learning_rate': 0.1190189196479002, 'subsample': 0.8938506136081646, 'colsample_bytree': 0.8080499753799478, 'gamma': 3.198138137857171, 'min_child_weight': 2}
✅ Best model selected based on F1: XGBoost
02-05-2025 04:13:22 Retraining best model on original full dataset...
02-05-2025 04:13:23 ✅ Exported and logged final model to W&B as artifact: final_model_xgboost.pkl
Requirement already satisfied: wandb in c:\users\x-hp\anaconda3\lib\site-packages (0.19.8)
Requirement already satisfied: click!=8.0.0,>=7.1 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (8.1.7)
Requirement already satisfied: docker-pycreds>=0.4.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (0.4.0)
Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (3.1.43)
Requirement already satisfied: platformdirs in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (3.10.0)
Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (4.25.3)
Requirement already satisfied: psutil>=5.0.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (5.9.0)
Requirement already satisfied: pydantic<3,>=2.6 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (2.8.2)
Requirement already satisfied: pyyaml in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (6.0.1)
Requirement already satisfied: requests<3,>=2.0.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (2.32.3)
Requirement already satisfied: sentry-sdk>=2.0.0 in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (2.18.0)
Requirement already satisfied: setproctitle in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (1.3.5)
Requirement already satisfied: setuptools in c:\users\x-hp\anaconda3\lib\site-packages (from wandb) (75.1.0)
Requirement already satisfied: colorama in c:\users\x-hp\anaconda3\lib\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)
Requirement already satisfied: six>=1.4.0 in c:\users\x-hp\anaconda3\lib\site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)
Requirement already satisfied: gitdb<5,>=4.0.1 in c:\users\x-hp\anaconda3\lib\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.7)
Requirement already satisfied: annotated-types>=0.4.0 in c:\users\x-hp\anaconda3\lib\site-packages (from pydantic<3,>=2.6->wandb) (0.6.0)
Requirement already satisfied: pydantic-core==2.20.1 in c:\users\x-hp\anaconda3\lib\site-packages (from pydantic<3,>=2.6->wandb) (2.20.1)
Requirement already satisfied: typing-extensions>=4.6.1 in c:\users\x-hp\anaconda3\lib\site-packages (from pydantic<3,>=2.6->wandb) (4.11.0)
Requirement already satisfied: charset-normalizer<4,>=2 in c:\users\x-hp\anaconda3\lib\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in c:\users\x-hp\anaconda3\lib\site-packages (from requests<3,>=2.0.0->wandb) (3.7)
Requirement already satisfied: urllib3<3,>=1.21.1 in c:\users\x-hp\anaconda3\lib\site-packages (from requests<3,>=2.0.0->wandb) (2.2.3)
Requirement already satisfied: certifi>=2017.4.17 in c:\users\x-hp\anaconda3\lib\site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)
Requirement already satisfied: smmap<5,>=3.0.1 in c:\users\x-hp\anaconda3\lib\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (4.0.0)
[34m[1mwandb[0m: [33mWARNING[0m Calling wandb.login() after wandb.init() has no effect.
02-05-2025 04:19:00 Downloading and reading train artifact
[34m[1mwandb[0m:   1 of 1 files downloaded.
02-05-2025 04:19:04 Spliting data into train/val
02-05-2025 04:19:04 x train: (375, 8)
02-05-2025 04:19:04 y train: (375,)
02-05-2025 04:19:04 x val: (162, 8)
02-05-2025 04:19:04 y val: (162,)
02-05-2025 04:19:04 Outlier Removal
02-05-2025 04:19:04 x_train shape [original]: (375, 8)
02-05-2025 04:19:04 x_train shape [outlier removal]: (357, 8)
02-05-2025 04:19:04 Data after SMOTE: (476, 8)
02-05-2025 04:19:05 [Logistic] Accuracy: 0.7037037037037037
02-05-2025 04:19:07 [Random Forest] Accuracy: 0.691358024691358
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:19:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
02-05-2025 04:19:07 [XGBoost] Accuracy: 0.7098765432098766
                 Model  Accuracy
0  Logistic Regression  0.703704
1        Random Forest  0.691358
2              XGBoost  0.709877
[I 2025-05-02 04:19:11,509] A new study created in memory with name: no-name-820db407-32d3-411f-91ad-c530169083ed
[I 2025-05-02 04:19:17,689] Trial 0 finished with value: 0.6192376728962095 and parameters: {'n_estimators': 164, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.6192376728962095.
[I 2025-05-02 04:19:20,120] Trial 1 finished with value: 0.6556337898703924 and parameters: {'n_estimators': 71, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.6556337898703924.
[I 2025-05-02 04:19:21,967] Trial 2 finished with value: 0.6100422832980973 and parameters: {'n_estimators': 67, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.6556337898703924.
[I 2025-05-02 04:19:25,133] Trial 3 finished with value: 0.6022922813620488 and parameters: {'n_estimators': 128, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.6556337898703924.
[I 2025-05-02 04:19:28,223] Trial 4 finished with value: 0.6292749224683428 and parameters: {'n_estimators': 113, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.6556337898703924.
[I 2025-05-02 04:19:29,895] Trial 5 finished with value: 0.5824060150375939 and parameters: {'n_estimators': 65, 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.6556337898703924.
[I 2025-05-02 04:19:33,270] Trial 6 finished with value: 0.6391015747537486 and parameters: {'n_estimators': 126, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.6556337898703924.
[I 2025-05-02 04:19:38,110] Trial 7 finished with value: 0.6256092902688379 and parameters: {'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.6556337898703924.
[I 2025-05-02 04:19:41,896] Trial 8 finished with value: 0.6388995545517284 and parameters: {'n_estimators': 158, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.6556337898703924.
[I 2025-05-02 04:19:44,371] Trial 9 finished with value: 0.6602136441819767 and parameters: {'n_estimators': 118, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.6602136441819767.
[I 2025-05-02 04:19:47,590] Trial 10 finished with value: 0.6586728617972298 and parameters: {'n_estimators': 97, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.6602136441819767.
[I 2025-05-02 04:19:51,651] Trial 11 finished with value: 0.6493362193362193 and parameters: {'n_estimators': 101, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.6602136441819767.
[I 2025-05-02 04:19:55,450] Trial 12 finished with value: 0.6695636422370927 and parameters: {'n_estimators': 94, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 12 with value: 0.6695636422370927.
[I 2025-05-02 04:19:58,111] Trial 13 finished with value: 0.6540000612801421 and parameters: {'n_estimators': 87, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.6695636422370927.
[I 2025-05-02 04:20:02,012] Trial 14 finished with value: 0.6398585415903575 and parameters: {'n_estimators': 143, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.6695636422370927.
[I 2025-05-02 04:20:03,216] Trial 15 finished with value: 0.6617372023522606 and parameters: {'n_estimators': 53, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.6695636422370927.
[I 2025-05-02 04:20:06,903] Trial 16 finished with value: 0.6808170337933908 and parameters: {'n_estimators': 59, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:09,700] Trial 17 finished with value: 0.6408799171842651 and parameters: {'n_estimators': 82, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:11,442] Trial 18 finished with value: 0.6271539313399779 and parameters: {'n_estimators': 51, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:14,120] Trial 19 finished with value: 0.6443101825710521 and parameters: {'n_estimators': 83, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:18,064] Trial 20 finished with value: 0.6321021255988826 and parameters: {'n_estimators': 102, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:19,730] Trial 21 finished with value: 0.6605844756538558 and parameters: {'n_estimators': 56, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:22,110] Trial 22 finished with value: 0.6599446131821409 and parameters: {'n_estimators': 73, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:23,740] Trial 23 finished with value: 0.6617372023522606 and parameters: {'n_estimators': 52, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:25,260] Trial 24 finished with value: 0.6520902656494163 and parameters: {'n_estimators': 62, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:26,935] Trial 25 finished with value: 0.6386885465955234 and parameters: {'n_estimators': 90, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:28,848] Trial 26 finished with value: 0.6397647413743621 and parameters: {'n_estimators': 78, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:33,866] Trial 27 finished with value: 0.6692662398352651 and parameters: {'n_estimators': 109, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:39,005] Trial 28 finished with value: 0.6516396523373267 and parameters: {'n_estimators': 141, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:41,988] Trial 29 finished with value: 0.6514641430920501 and parameters: {'n_estimators': 113, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:46,565] Trial 30 finished with value: 0.6538490495012234 and parameters: {'n_estimators': 186, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:49,145] Trial 31 finished with value: 0.6484406119815971 and parameters: {'n_estimators': 96, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:51,880] Trial 32 finished with value: 0.6546640316205534 and parameters: {'n_estimators': 59, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:54,184] Trial 33 finished with value: 0.6764638293960842 and parameters: {'n_estimators': 107, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.6808170337933908.
[I 2025-05-02 04:20:56,350] Trial 34 finished with value: 0.6823842734293867 and parameters: {'n_estimators': 108, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.6823842734293867.
[I 2025-05-02 04:20:58,991] Trial 35 finished with value: 0.6770651244932164 and parameters: {'n_estimators': 133, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.6823842734293867.
[I 2025-05-02 04:21:01,134] Trial 36 finished with value: 0.6770292666452501 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 34 with value: 0.6823842734293867.
[I 2025-05-02 04:21:02,841] Trial 37 finished with value: 0.6654474914464535 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 34 with value: 0.6823842734293867.
[I 2025-05-02 04:21:04,363] Trial 38 finished with value: 0.6885543417915876 and parameters: {'n_estimators': 166, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 38 with value: 0.6885543417915876.
[I 2025-05-02 04:21:05,890] Trial 39 finished with value: 0.6853120815793139 and parameters: {'n_estimators': 165, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 38 with value: 0.6885543417915876.
[I 2025-05-02 04:21:07,468] Trial 40 finished with value: 0.6885543417915876 and parameters: {'n_estimators': 170, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 38 with value: 0.6885543417915876.
[I 2025-05-02 04:21:09,029] Trial 41 finished with value: 0.6885543417915876 and parameters: {'n_estimators': 170, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 38 with value: 0.6885543417915876.
[I 2025-05-02 04:21:10,584] Trial 42 finished with value: 0.6885543417915876 and parameters: {'n_estimators': 173, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 38 with value: 0.6885543417915876.
[I 2025-05-02 04:21:12,384] Trial 43 finished with value: 0.6885543417915876 and parameters: {'n_estimators': 171, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 38 with value: 0.6885543417915876.
[I 2025-05-02 04:21:14,105] Trial 44 finished with value: 0.6885543417915876 and parameters: {'n_estimators': 173, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 38 with value: 0.6885543417915876.
[I 2025-05-02 04:21:16,029] Trial 45 finished with value: 0.6934523009752611 and parameters: {'n_estimators': 183, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:17,589] Trial 46 finished with value: 0.6904924701084536 and parameters: {'n_estimators': 153, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:18,930] Trial 47 finished with value: 0.590915750915751 and parameters: {'n_estimators': 152, 'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:20,824] Trial 48 finished with value: 0.6885543417915876 and parameters: {'n_estimators': 185, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:22,715] Trial 49 finished with value: 0.6885543417915876 and parameters: {'n_estimators': 185, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:24,537] Trial 50 finished with value: 0.6725200673441913 and parameters: {'n_estimators': 197, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:26,218] Trial 51 finished with value: 0.6904924701084536 and parameters: {'n_estimators': 155, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:27,854] Trial 52 finished with value: 0.6602671029173138 and parameters: {'n_estimators': 152, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:29,291] Trial 53 finished with value: 0.6155572334642102 and parameters: {'n_estimators': 161, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:30,967] Trial 54 finished with value: 0.6834192993767463 and parameters: {'n_estimators': 151, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:32,779] Trial 55 finished with value: 0.660979312898719 and parameters: {'n_estimators': 178, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:34,330] Trial 56 finished with value: 0.6853120815793139 and parameters: {'n_estimators': 166, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:36,025] Trial 57 finished with value: 0.6766746567161721 and parameters: {'n_estimators': 159, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:38,082] Trial 58 finished with value: 0.6699929326431435 and parameters: {'n_estimators': 193, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:39,581] Trial 59 finished with value: 0.6863791302435539 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:41,790] Trial 60 finished with value: 0.6770651244932164 and parameters: {'n_estimators': 178, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:43,513] Trial 61 finished with value: 0.6885543417915876 and parameters: {'n_estimators': 170, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:45,543] Trial 62 finished with value: 0.6885543417915876 and parameters: {'n_estimators': 179, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:47,246] Trial 63 finished with value: 0.6804141223956404 and parameters: {'n_estimators': 156, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:49,016] Trial 64 finished with value: 0.6858490277819259 and parameters: {'n_estimators': 192, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:52,572] Trial 65 finished with value: 0.678133152039091 and parameters: {'n_estimators': 174, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:54,920] Trial 66 finished with value: 0.6296107981446707 and parameters: {'n_estimators': 166, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:21:57,651] Trial 67 finished with value: 0.6732660822577566 and parameters: {'n_estimators': 162, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:22:00,043] Trial 68 finished with value: 0.6916865990107821 and parameters: {'n_estimators': 156, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:22:02,804] Trial 69 finished with value: 0.6916865990107821 and parameters: {'n_estimators': 155, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:22:04,998] Trial 70 finished with value: 0.6734978379192393 and parameters: {'n_estimators': 146, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:22:07,123] Trial 71 finished with value: 0.6916865990107821 and parameters: {'n_estimators': 154, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:22:08,513] Trial 72 finished with value: 0.688588007736944 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:22:09,821] Trial 73 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 131, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:22:11,122] Trial 74 finished with value: 0.6915478386037516 and parameters: {'n_estimators': 121, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:22:12,453] Trial 75 finished with value: 0.6607664686734455 and parameters: {'n_estimators': 121, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:22:13,693] Trial 76 finished with value: 0.6770651244932164 and parameters: {'n_estimators': 132, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:22:15,174] Trial 77 finished with value: 0.6916865990107821 and parameters: {'n_estimators': 156, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:22:16,587] Trial 78 finished with value: 0.6770651244932164 and parameters: {'n_estimators': 131, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 45 with value: 0.6934523009752611.
[I 2025-05-02 04:22:18,147] Trial 79 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 79 with value: 0.6998268184067294.
[I 2025-05-02 04:22:19,667] Trial 80 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 79 with value: 0.6998268184067294.
[I 2025-05-02 04:22:21,429] Trial 81 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 79 with value: 0.6998268184067294.
[I 2025-05-02 04:22:22,970] Trial 82 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 79 with value: 0.6998268184067294.
[I 2025-05-02 04:22:24,293] Trial 83 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 79 with value: 0.6998268184067294.
[I 2025-05-02 04:22:25,666] Trial 84 finished with value: 0.6734978379192393 and parameters: {'n_estimators': 140, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 79 with value: 0.6998268184067294.
[I 2025-05-02 04:22:27,301] Trial 85 finished with value: 0.6839260277904513 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 79 with value: 0.6998268184067294.
[I 2025-05-02 04:22:28,682] Trial 86 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 136, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 79 with value: 0.6998268184067294.
[I 2025-05-02 04:22:30,954] Trial 87 finished with value: 0.6692314448836187 and parameters: {'n_estimators': 135, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 79 with value: 0.6998268184067294.
[I 2025-05-02 04:22:33,755] Trial 88 finished with value: 0.6786068788542812 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 79 with value: 0.6998268184067294.
[I 2025-05-02 04:22:35,832] Trial 89 finished with value: 0.673601921030013 and parameters: {'n_estimators': 149, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 79 with value: 0.6998268184067294.
[I 2025-05-02 04:22:38,564] Trial 90 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 79 with value: 0.6998268184067294.
[I 2025-05-02 04:22:40,187] Trial 91 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:22:42,024] Trial 92 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:22:43,336] Trial 93 finished with value: 0.6945076694705592 and parameters: {'n_estimators': 128, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:22:44,757] Trial 94 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:22:46,164] Trial 95 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:22:47,825] Trial 96 finished with value: 0.6707226297786287 and parameters: {'n_estimators': 144, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:22:49,161] Trial 97 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:22:50,463] Trial 98 finished with value: 0.6859974223225305 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:22:52,094] Trial 99 finished with value: 0.6757059399425426 and parameters: {'n_estimators': 126, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:22:53,649] Trial 100 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:22:55,181] Trial 101 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:22:56,869] Trial 102 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 148, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:22:58,532] Trial 103 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 149, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:00,286] Trial 104 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 149, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:02,443] Trial 105 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 149, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:03,831] Trial 106 finished with value: 0.6102731635289775 and parameters: {'n_estimators': 149, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:05,371] Trial 107 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 148, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:08,198] Trial 108 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 149, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:09,646] Trial 109 finished with value: 0.6789210699661832 and parameters: {'n_estimators': 150, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:11,225] Trial 110 finished with value: 0.6863674500746119 and parameters: {'n_estimators': 160, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:12,969] Trial 111 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 149, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:14,412] Trial 112 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 148, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:15,828] Trial 113 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 148, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:17,424] Trial 114 finished with value: 0.6974216380182001 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:18,928] Trial 115 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 148, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:20,379] Trial 116 finished with value: 0.673601921030013 and parameters: {'n_estimators': 152, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:22,448] Trial 117 finished with value: 0.6834076192078042 and parameters: {'n_estimators': 162, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:24,686] Trial 118 finished with value: 0.6863674500746119 and parameters: {'n_estimators': 159, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:26,370] Trial 119 finished with value: 0.6946464298775897 and parameters: {'n_estimators': 151, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:28,139] Trial 120 finished with value: 0.673601921030013 and parameters: {'n_estimators': 157, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:29,579] Trial 121 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 148, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:31,044] Trial 122 finished with value: 0.6974216380182001 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:32,710] Trial 123 finished with value: 0.6916865990107821 and parameters: {'n_estimators': 153, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:34,220] Trial 124 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:35,488] Trial 125 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:37,084] Trial 126 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:38,849] Trial 127 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:40,166] Trial 128 finished with value: 0.6915478386037516 and parameters: {'n_estimators': 129, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:41,852] Trial 129 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:43,431] Trial 130 finished with value: 0.6420614056205564 and parameters: {'n_estimators': 139, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:44,900] Trial 131 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:46,240] Trial 132 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 134, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:47,974] Trial 133 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:49,404] Trial 134 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:50,618] Trial 135 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:51,989] Trial 136 finished with value: 0.6823842734293867 and parameters: {'n_estimators': 122, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:53,730] Trial 137 finished with value: 0.6916865990107821 and parameters: {'n_estimators': 154, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:54,977] Trial 138 finished with value: 0.6148269301757674 and parameters: {'n_estimators': 135, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:56,413] Trial 139 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:57,938] Trial 140 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:23:59,423] Trial 141 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:01,087] Trial 142 finished with value: 0.6915478386037516 and parameters: {'n_estimators': 129, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:02,985] Trial 143 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:04,453] Trial 144 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:05,686] Trial 145 finished with value: 0.6789210699661832 and parameters: {'n_estimators': 133, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:06,970] Trial 146 finished with value: 0.5961789088104877 and parameters: {'n_estimators': 140, 'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:08,607] Trial 147 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:09,986] Trial 148 finished with value: 0.6734978379192393 and parameters: {'n_estimators': 137, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:11,194] Trial 149 finished with value: 0.6857597249086611 and parameters: {'n_estimators': 115, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:12,786] Trial 150 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:14,326] Trial 151 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:15,568] Trial 152 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 134, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:17,229] Trial 153 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:18,993] Trial 154 finished with value: 0.6915478386037516 and parameters: {'n_estimators': 129, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:20,409] Trial 155 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:21,734] Trial 156 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 136, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:23,292] Trial 157 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:24,823] Trial 158 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:26,452] Trial 159 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 131, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:27,741] Trial 160 finished with value: 0.6480175548049825 and parameters: {'n_estimators': 125, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:29,385] Trial 161 finished with value: 0.6820484346571303 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:30,844] Trial 162 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:32,566] Trial 163 finished with value: 0.6916865990107821 and parameters: {'n_estimators': 152, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:34,140] Trial 164 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:35,490] Trial 165 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:36,840] Trial 166 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 136, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:38,437] Trial 167 finished with value: 0.6739010028926773 and parameters: {'n_estimators': 141, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:40,467] Trial 168 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 133, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:42,659] Trial 169 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:44,663] Trial 170 finished with value: 0.6505200078622005 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:46,230] Trial 171 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:47,789] Trial 172 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:50,502] Trial 173 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:52,227] Trial 174 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 136, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:54,077] Trial 175 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:56,087] Trial 176 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:24:58,179] Trial 177 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 133, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:00,428] Trial 178 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:01,911] Trial 179 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:03,756] Trial 180 finished with value: 0.688588007736944 and parameters: {'n_estimators': 127, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:05,384] Trial 181 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:07,635] Trial 182 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 146, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:10,194] Trial 183 finished with value: 0.6859974223225305 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:12,483] Trial 184 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:14,881] Trial 185 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:18,720] Trial 186 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 131, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:21,812] Trial 187 finished with value: 0.6946464298775897 and parameters: {'n_estimators': 151, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:23,597] Trial 188 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:25,270] Trial 189 finished with value: 0.6974216380182001 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:26,650] Trial 190 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:28,652] Trial 191 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:30,424] Trial 192 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:32,061] Trial 193 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:33,583] Trial 194 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:35,129] Trial 195 finished with value: 0.6859974223225305 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:36,481] Trial 196 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:37,880] Trial 197 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:39,579] Trial 198 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:41,005] Trial 199 finished with value: 0.6517166576345201 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:42,721] Trial 200 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:45,483] Trial 201 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:46,837] Trial 202 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:48,221] Trial 203 finished with value: 0.6859974223225305 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:49,911] Trial 204 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:51,767] Trial 205 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:53,230] Trial 206 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:54,711] Trial 207 finished with value: 0.6148269301757674 and parameters: {'n_estimators': 135, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:56,169] Trial 208 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:57,494] Trial 209 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 130, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:25:59,248] Trial 210 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 133, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:01,299] Trial 211 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:02,744] Trial 212 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:04,334] Trial 213 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:05,883] Trial 214 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:07,204] Trial 215 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:08,662] Trial 216 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:09,576] Trial 217 finished with value: 0.6802792027583887 and parameters: {'n_estimators': 71, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:11,008] Trial 218 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:12,842] Trial 219 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:14,297] Trial 220 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 134, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:15,830] Trial 221 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:17,149] Trial 222 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:18,586] Trial 223 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:20,148] Trial 224 finished with value: 0.6637262995402531 and parameters: {'n_estimators': 145, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:21,530] Trial 225 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:22,840] Trial 226 finished with value: 0.6859974223225305 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:24,407] Trial 227 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:26,048] Trial 228 finished with value: 0.6703867910063723 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:27,456] Trial 229 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:28,872] Trial 230 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:30,438] Trial 231 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:31,928] Trial 232 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:33,299] Trial 233 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:34,809] Trial 234 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:36,411] Trial 235 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 133, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:38,141] Trial 236 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 146, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:39,823] Trial 237 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:41,779] Trial 238 finished with value: 0.6859974223225305 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:43,283] Trial 239 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:45,000] Trial 240 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:46,551] Trial 241 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:47,947] Trial 242 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:49,439] Trial 243 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:51,005] Trial 244 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:52,311] Trial 245 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 136, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:53,983] Trial 246 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 146, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:55,536] Trial 247 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:56,884] Trial 248 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 133, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:26:58,868] Trial 249 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:03,241] Trial 250 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:06,843] Trial 251 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:10,628] Trial 252 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 136, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:14,185] Trial 253 finished with value: 0.6789210699661832 and parameters: {'n_estimators': 146, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:16,742] Trial 254 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:18,539] Trial 255 finished with value: 0.6770651244932164 and parameters: {'n_estimators': 130, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:20,302] Trial 256 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:22,188] Trial 257 finished with value: 0.6859974223225305 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:24,489] Trial 258 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:28,711] Trial 259 finished with value: 0.6600606673407482 and parameters: {'n_estimators': 145, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:30,454] Trial 260 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:32,391] Trial 261 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:33,937] Trial 262 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:35,684] Trial 263 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:37,377] Trial 264 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:38,991] Trial 265 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 146, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:41,006] Trial 266 finished with value: 0.6770651244932164 and parameters: {'n_estimators': 133, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:42,657] Trial 267 finished with value: 0.6548117717104228 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:44,235] Trial 268 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 136, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:47,146] Trial 269 finished with value: 0.667638376630051 and parameters: {'n_estimators': 139, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:48,831] Trial 270 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:50,544] Trial 271 finished with value: 0.6545994832041343 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:52,122] Trial 272 finished with value: 0.6859974223225305 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:53,867] Trial 273 finished with value: 0.6756470479874734 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:57,297] Trial 274 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:27:59,585] Trial 275 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:01,366] Trial 276 finished with value: 0.6820484346571303 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:03,008] Trial 277 finished with value: 0.67760190376975 and parameters: {'n_estimators': 134, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:04,976] Trial 278 finished with value: 0.6770651244932164 and parameters: {'n_estimators': 131, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:07,168] Trial 279 finished with value: 0.6505200078622005 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:09,427] Trial 280 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:12,191] Trial 281 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:15,599] Trial 282 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:18,120] Trial 283 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:20,641] Trial 284 finished with value: 0.6148269301757674 and parameters: {'n_estimators': 136, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:22,565] Trial 285 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:24,112] Trial 286 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:25,745] Trial 287 finished with value: 0.688588007736944 and parameters: {'n_estimators': 127, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:27,540] Trial 288 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 133, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:28,905] Trial 289 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:31,721] Trial 290 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 148, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:33,152] Trial 291 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:33,970] Trial 292 finished with value: 0.6538770924615211 and parameters: {'n_estimators': 84, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:35,998] Trial 293 finished with value: 0.6707226297786287 and parameters: {'n_estimators': 144, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:39,106] Trial 294 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:42,178] Trial 295 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:43,717] Trial 296 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 134, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:45,009] Trial 297 finished with value: 0.6748965897600883 and parameters: {'n_estimators': 99, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:46,832] Trial 298 finished with value: 0.6974216380182001 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:48,251] Trial 299 finished with value: 0.645293623304509 and parameters: {'n_estimators': 130, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:49,700] Trial 300 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:51,366] Trial 301 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 136, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:53,385] Trial 302 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:54,841] Trial 303 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:56,419] Trial 304 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:57,895] Trial 305 finished with value: 0.6770651244932164 and parameters: {'n_estimators': 134, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:28:59,332] Trial 306 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:00,936] Trial 307 finished with value: 0.6946464298775897 and parameters: {'n_estimators': 151, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:02,863] Trial 308 finished with value: 0.6974216380182001 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:04,141] Trial 309 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:06,528] Trial 310 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:08,289] Trial 311 finished with value: 0.6859974223225305 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:09,024] Trial 312 finished with value: 0.6652410558698879 and parameters: {'n_estimators': 66, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:10,393] Trial 313 finished with value: 0.6734978379192393 and parameters: {'n_estimators': 140, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:11,919] Trial 314 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 131, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:13,388] Trial 315 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 146, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:14,708] Trial 316 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:16,130] Trial 317 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:18,539] Trial 318 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:20,384] Trial 319 finished with value: 0.6839260277904513 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:23,121] Trial 320 finished with value: 0.638156304717749 and parameters: {'n_estimators': 134, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:26,647] Trial 321 finished with value: 0.6128994261552402 and parameters: {'n_estimators': 141, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:33,133] Trial 322 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:35,956] Trial 323 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:38,114] Trial 324 finished with value: 0.6972215974689997 and parameters: {'n_estimators': 105, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:41,532] Trial 325 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:44,386] Trial 326 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:46,829] Trial 327 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 133, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:50,093] Trial 328 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:54,110] Trial 329 finished with value: 0.6945076694705592 and parameters: {'n_estimators': 128, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:29:59,345] Trial 330 finished with value: 0.6789210699661832 and parameters: {'n_estimators': 136, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:04,523] Trial 331 finished with value: 0.6974216380182001 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:09,700] Trial 332 finished with value: 0.6637262995402531 and parameters: {'n_estimators': 140, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:12,508] Trial 333 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:14,274] Trial 334 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:16,148] Trial 335 finished with value: 0.6770651244932164 and parameters: {'n_estimators': 131, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:18,075] Trial 336 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:19,509] Trial 337 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:20,810] Trial 338 finished with value: 0.6859974223225305 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:22,379] Trial 339 finished with value: 0.6690931367823996 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:23,957] Trial 340 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 148, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:25,360] Trial 341 finished with value: 0.6525832442526666 and parameters: {'n_estimators': 143, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:26,952] Trial 342 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:28,972] Trial 343 finished with value: 0.6859974223225305 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:30,527] Trial 344 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:32,444] Trial 345 finished with value: 0.6739010028926773 and parameters: {'n_estimators': 141, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:33,792] Trial 346 finished with value: 0.6686864253837126 and parameters: {'n_estimators': 94, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:34,709] Trial 347 finished with value: 0.6829042466114084 and parameters: {'n_estimators': 78, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:36,065] Trial 348 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:36,716] Trial 349 finished with value: 0.6795405727781005 and parameters: {'n_estimators': 56, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:38,293] Trial 350 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 124, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:39,697] Trial 351 finished with value: 0.5961789088104877 and parameters: {'n_estimators': 139, 'max_depth': 2, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:41,531] Trial 352 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 133, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:43,654] Trial 353 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 149, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:45,646] Trial 354 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:47,139] Trial 355 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:48,734] Trial 356 finished with value: 0.6833545445201319 and parameters: {'n_estimators': 118, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:52,553] Trial 357 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:54,211] Trial 358 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:56,595] Trial 359 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:30:58,551] Trial 360 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 136, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:00,583] Trial 361 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:02,658] Trial 362 finished with value: 0.6734978379192393 and parameters: {'n_estimators': 140, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:04,494] Trial 363 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:06,057] Trial 364 finished with value: 0.6974216380182001 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:07,622] Trial 365 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:10,088] Trial 366 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 130, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:12,496] Trial 367 finished with value: 0.6770651244932164 and parameters: {'n_estimators': 134, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:14,284] Trial 368 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:15,928] Trial 369 finished with value: 0.6492803342679642 and parameters: {'n_estimators': 136, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:17,839] Trial 370 finished with value: 0.6600606673407482 and parameters: {'n_estimators': 151, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:19,529] Trial 371 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:21,457] Trial 372 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:23,979] Trial 373 finished with value: 0.6974216380182001 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:26,121] Trial 374 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:28,076] Trial 375 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 134, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:29,736] Trial 376 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:31,509] Trial 377 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:32,982] Trial 378 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:35,232] Trial 379 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:36,629] Trial 380 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:38,428] Trial 381 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:41,676] Trial 382 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:46,720] Trial 383 finished with value: 0.6945076694705592 and parameters: {'n_estimators': 128, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:50,217] Trial 384 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 136, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:55,767] Trial 385 finished with value: 0.673601921030013 and parameters: {'n_estimators': 149, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:31:59,701] Trial 386 finished with value: 0.6757059399425426 and parameters: {'n_estimators': 154, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:04,720] Trial 387 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:06,640] Trial 388 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:08,340] Trial 389 finished with value: 0.6821289742725536 and parameters: {'n_estimators': 135, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:10,383] Trial 390 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 146, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:12,075] Trial 391 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:13,855] Trial 392 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:15,755] Trial 393 finished with value: 0.6690931367823996 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:17,827] Trial 394 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:22,120] Trial 395 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 146, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:24,902] Trial 396 finished with value: 0.6859974223225305 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:27,032] Trial 397 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:30,799] Trial 398 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:34,112] Trial 399 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:35,787] Trial 400 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:37,255] Trial 401 finished with value: 0.67760190376975 and parameters: {'n_estimators': 134, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:38,876] Trial 402 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:40,807] Trial 403 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:43,864] Trial 404 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 149, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:45,377] Trial 405 finished with value: 0.6636768476451802 and parameters: {'n_estimators': 129, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:48,563] Trial 406 finished with value: 0.6734978379192393 and parameters: {'n_estimators': 137, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:50,275] Trial 407 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:53,390] Trial 408 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:55,029] Trial 409 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:56,530] Trial 410 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 134, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:58,062] Trial 411 finished with value: 0.6974216380182001 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:32:59,983] Trial 412 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:04,261] Trial 413 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 131, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:06,997] Trial 414 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:10,212] Trial 415 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:15,657] Trial 416 finished with value: 0.6916865990107821 and parameters: {'n_estimators': 152, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:19,214] Trial 417 finished with value: 0.6734978379192393 and parameters: {'n_estimators': 141, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:21,553] Trial 418 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 146, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:23,911] Trial 419 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 134, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:26,133] Trial 420 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:28,080] Trial 421 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 136, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:29,751] Trial 422 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:31,410] Trial 423 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:32,967] Trial 424 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 149, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:34,779] Trial 425 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:36,727] Trial 426 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:38,272] Trial 427 finished with value: 0.638156304717749 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:40,450] Trial 428 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:41,948] Trial 429 finished with value: 0.6859974223225305 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:43,465] Trial 430 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:45,331] Trial 431 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 146, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:47,238] Trial 432 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:48,751] Trial 433 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:50,094] Trial 434 finished with value: 0.688588007736944 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:52,373] Trial 435 finished with value: 0.6734978379192393 and parameters: {'n_estimators': 140, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:55,892] Trial 436 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 133, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:33:58,058] Trial 437 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 146, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:00,101] Trial 438 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:01,771] Trial 439 finished with value: 0.6489682432581987 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:03,670] Trial 440 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:06,653] Trial 441 finished with value: 0.6798403326338269 and parameters: {'n_estimators': 198, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:08,928] Trial 442 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 136, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:11,466] Trial 443 finished with value: 0.6773642063558807 and parameters: {'n_estimators': 148, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:13,708] Trial 444 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 131, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:16,177] Trial 445 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:18,943] Trial 446 finished with value: 0.6707226297786287 and parameters: {'n_estimators': 143, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:21,408] Trial 447 finished with value: 0.6859974223225305 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:23,347] Trial 448 finished with value: 0.6887195557754687 and parameters: {'n_estimators': 112, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:26,107] Trial 449 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:27,936] Trial 450 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:29,420] Trial 451 finished with value: 0.6946464298775897 and parameters: {'n_estimators': 151, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:31,152] Trial 452 finished with value: 0.6789210699661832 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:32,622] Trial 453 finished with value: 0.6915478386037516 and parameters: {'n_estimators': 129, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:34,037] Trial 454 finished with value: 0.653199071459941 and parameters: {'n_estimators': 90, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:35,551] Trial 455 finished with value: 0.6741514961330141 and parameters: {'n_estimators': 136, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:37,028] Trial 456 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:38,470] Trial 457 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:39,714] Trial 458 finished with value: 0.6128994261552402 and parameters: {'n_estimators': 133, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:41,218] Trial 459 finished with value: 0.6974216380182001 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:42,522] Trial 460 finished with value: 0.6477794556864325 and parameters: {'n_estimators': 138, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:44,122] Trial 461 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:45,934] Trial 462 finished with value: 0.6859974223225305 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:47,512] Trial 463 finished with value: 0.6820484346571303 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:49,074] Trial 464 finished with value: 0.6703867910063723 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:50,415] Trial 465 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:52,076] Trial 466 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 149, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:53,547] Trial 467 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:54,815] Trial 468 finished with value: 0.6148269301757674 and parameters: {'n_estimators': 133, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:56,456] Trial 469 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:57,941] Trial 470 finished with value: 0.6998268184067294 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:34:59,316] Trial 471 finished with value: 0.6976084446643576 and parameters: {'n_estimators': 137, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:00,760] Trial 472 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:02,377] Trial 473 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 145, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:03,657] Trial 474 finished with value: 0.6770651244932164 and parameters: {'n_estimators': 130, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:05,044] Trial 475 finished with value: 0.6692314448836187 and parameters: {'n_estimators': 137, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:06,378] Trial 476 finished with value: 0.6915478386037515 and parameters: {'n_estimators': 134, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:07,921] Trial 477 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 140, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:09,407] Trial 478 finished with value: 0.5961789088104877 and parameters: {'n_estimators': 143, 'max_depth': 2, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:10,978] Trial 479 finished with value: 0.6916865990107821 and parameters: {'n_estimators': 156, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:12,466] Trial 480 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 149, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:13,856] Trial 481 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:15,289] Trial 482 finished with value: 0.7026020265473398 and parameters: {'n_estimators': 146, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:16,682] Trial 483 finished with value: 0.6859974223225305 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:17,986] Trial 484 finished with value: 0.6128994261552402 and parameters: {'n_estimators': 142, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:19,357] Trial 485 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:21,367] Trial 486 finished with value: 0.6506127722406791 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:22,651] Trial 487 finished with value: 0.688588007736944 and parameters: {'n_estimators': 127, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:24,015] Trial 488 finished with value: 0.6770651244932164 and parameters: {'n_estimators': 133, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:25,396] Trial 489 finished with value: 0.6560456619635244 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:27,300] Trial 490 finished with value: 0.6974216380182001 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:28,637] Trial 491 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 136, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:30,012] Trial 492 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:31,452] Trial 493 finished with value: 0.6839260277904513 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:32,961] Trial 494 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:34,304] Trial 495 finished with value: 0.6968669875399217 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:35,794] Trial 496 finished with value: 0.6916865990107821 and parameters: {'n_estimators': 152, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:37,256] Trial 497 finished with value: 0.7059578966308309 and parameters: {'n_estimators': 141, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:38,633] Trial 498 finished with value: 0.6859974223225305 and parameters: {'n_estimators': 135, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
[I 2025-05-02 04:35:40,069] Trial 499 finished with value: 0.6707226297786287 and parameters: {'n_estimators': 145, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 91 with value: 0.7059578966308309.
✅ Best Random Forest Parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}
[I 2025-05-02 04:35:40,072] A new study created in memory with name: no-name-f70f15f6-b72e-46bb-bff1-eaa0e895b06b
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:40,497] Trial 0 finished with value: 0.6717345344241198 and parameters: {'n_estimators': 167, 'max_depth': 3, 'learning_rate': 0.2198200115564924, 'subsample': 0.8732259760588145, 'colsample_bytree': 0.6179619420428031, 'gamma': 3.956308620083316, 'min_child_weight': 3}. Best is trial 0 with value: 0.6717345344241198.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:41,137] Trial 1 finished with value: 0.6320722755505364 and parameters: {'n_estimators': 295, 'max_depth': 10, 'learning_rate': 0.10729212920641941, 'subsample': 0.9117073394939943, 'colsample_bytree': 0.7981173933235772, 'gamma': 1.6863458711067858, 'min_child_weight': 9}. Best is trial 0 with value: 0.6717345344241198.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:41,720] Trial 2 finished with value: 0.6214715452702304 and parameters: {'n_estimators': 214, 'max_depth': 4, 'learning_rate': 0.12906015280272637, 'subsample': 0.6011390301397247, 'colsample_bytree': 0.6502325440151961, 'gamma': 1.3738393764961354, 'min_child_weight': 7}. Best is trial 0 with value: 0.6717345344241198.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:42,313] Trial 3 finished with value: 0.6299330677425894 and parameters: {'n_estimators': 268, 'max_depth': 7, 'learning_rate': 0.09277447279432476, 'subsample': 0.9440205041352855, 'colsample_bytree': 0.7723640059741861, 'gamma': 4.6491214688233615, 'min_child_weight': 5}. Best is trial 0 with value: 0.6717345344241198.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:42,959] Trial 4 finished with value: 0.6197732426303855 and parameters: {'n_estimators': 167, 'max_depth': 6, 'learning_rate': 0.15029455101308734, 'subsample': 0.6579316909940082, 'colsample_bytree': 0.845355864018878, 'gamma': 1.3456015830803958, 'min_child_weight': 9}. Best is trial 0 with value: 0.6717345344241198.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:43,332] Trial 5 finished with value: 0.619047619047619 and parameters: {'n_estimators': 106, 'max_depth': 5, 'learning_rate': 0.28096119849880064, 'subsample': 0.736508169960165, 'colsample_bytree': 0.7693997683899341, 'gamma': 3.269527068632025, 'min_child_weight': 10}. Best is trial 0 with value: 0.6717345344241198.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:43,741] Trial 6 finished with value: 0.6544696100748213 and parameters: {'n_estimators': 130, 'max_depth': 5, 'learning_rate': 0.12053051451211443, 'subsample': 0.6734469256598571, 'colsample_bytree': 0.947686026699868, 'gamma': 3.413266272007241, 'min_child_weight': 3}. Best is trial 0 with value: 0.6717345344241198.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:44,312] Trial 7 finished with value: 0.6467374418160727 and parameters: {'n_estimators': 248, 'max_depth': 7, 'learning_rate': 0.13290635200715745, 'subsample': 0.6433868714604797, 'colsample_bytree': 0.9834496651831431, 'gamma': 4.235881812470035, 'min_child_weight': 3}. Best is trial 0 with value: 0.6717345344241198.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:44,928] Trial 8 finished with value: 0.6087505741073382 and parameters: {'n_estimators': 292, 'max_depth': 4, 'learning_rate': 0.20557163152844496, 'subsample': 0.6095720609287515, 'colsample_bytree': 0.8611181683804248, 'gamma': 1.652167538857987, 'min_child_weight': 9}. Best is trial 0 with value: 0.6717345344241198.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:45,348] Trial 9 finished with value: 0.6626212304676238 and parameters: {'n_estimators': 115, 'max_depth': 4, 'learning_rate': 0.05013601042083668, 'subsample': 0.9810160195157355, 'colsample_bytree': 0.8127902681970606, 'gamma': 1.86707717149946, 'min_child_weight': 6}. Best is trial 0 with value: 0.6717345344241198.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:45,956] Trial 10 finished with value: 0.664590538660306 and parameters: {'n_estimators': 174, 'max_depth': 9, 'learning_rate': 0.22981585164343987, 'subsample': 0.8485143565965902, 'colsample_bytree': 0.6131309702995849, 'gamma': 0.4570585419558211, 'min_child_weight': 2}. Best is trial 0 with value: 0.6717345344241198.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:46,825] Trial 11 finished with value: 0.6807623049219688 and parameters: {'n_estimators': 173, 'max_depth': 9, 'learning_rate': 0.22672823458346722, 'subsample': 0.849092699564619, 'colsample_bytree': 0.6320043315196282, 'gamma': 0.09957634913687557, 'min_child_weight': 1}. Best is trial 11 with value: 0.6807623049219688.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:47,373] Trial 12 finished with value: 0.6995348623008197 and parameters: {'n_estimators': 166, 'max_depth': 9, 'learning_rate': 0.20627401253738362, 'subsample': 0.834634070725238, 'colsample_bytree': 0.6846987479957294, 'gamma': 3.304013029707395, 'min_child_weight': 1}. Best is trial 12 with value: 0.6995348623008197.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:47,955] Trial 13 finished with value: 0.6947342995169082 and parameters: {'n_estimators': 206, 'max_depth': 9, 'learning_rate': 0.298572292681257, 'subsample': 0.7849043474947489, 'colsample_bytree': 0.707663450581738, 'gamma': 2.7677655374550927, 'min_child_weight': 1}. Best is trial 12 with value: 0.6995348623008197.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:48,569] Trial 14 finished with value: 0.682546152271887 and parameters: {'n_estimators': 216, 'max_depth': 8, 'learning_rate': 0.299595036059323, 'subsample': 0.7646760172983874, 'colsample_bytree': 0.7029088951830034, 'gamma': 2.682377886023146, 'min_child_weight': 1}. Best is trial 12 with value: 0.6995348623008197.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:49,134] Trial 15 finished with value: 0.6493239007770281 and parameters: {'n_estimators': 145, 'max_depth': 10, 'learning_rate': 0.18343406633344553, 'subsample': 0.8010247439890033, 'colsample_bytree': 0.7038440700974608, 'gamma': 2.5920945414773753, 'min_child_weight': 4}. Best is trial 12 with value: 0.6995348623008197.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:49,703] Trial 16 finished with value: 0.6583037715408536 and parameters: {'n_estimators': 198, 'max_depth': 8, 'learning_rate': 0.27163207943676554, 'subsample': 0.7279970628845048, 'colsample_bytree': 0.6818999416048082, 'gamma': 3.550687976580062, 'min_child_weight': 1}. Best is trial 12 with value: 0.6995348623008197.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:50,308] Trial 17 finished with value: 0.6944702436016035 and parameters: {'n_estimators': 229, 'max_depth': 9, 'learning_rate': 0.25702865115870727, 'subsample': 0.7969424704575575, 'colsample_bytree': 0.7295241460615487, 'gamma': 3.0050948543456553, 'min_child_weight': 2}. Best is trial 12 with value: 0.6995348623008197.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:51,080] Trial 18 finished with value: 0.6482127896659169 and parameters: {'n_estimators': 192, 'max_depth': 8, 'learning_rate': 0.17995924114921003, 'subsample': 0.8128283650828743, 'colsample_bytree': 0.7412144761382498, 'gamma': 2.114884374058356, 'min_child_weight': 5}. Best is trial 12 with value: 0.6995348623008197.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:51,741] Trial 19 finished with value: 0.6457518758351322 and parameters: {'n_estimators': 148, 'max_depth': 10, 'learning_rate': 0.25196610650897344, 'subsample': 0.9004096930984163, 'colsample_bytree': 0.897448744728708, 'gamma': 3.958022485332263, 'min_child_weight': 7}. Best is trial 12 with value: 0.6995348623008197.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:52,599] Trial 20 finished with value: 0.6360485105277824 and parameters: {'n_estimators': 245, 'max_depth': 9, 'learning_rate': 0.06578184301067472, 'subsample': 0.7075351524788194, 'colsample_bytree': 0.6659609896672649, 'gamma': 4.871322179193646, 'min_child_weight': 2}. Best is trial 12 with value: 0.6995348623008197.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:53,283] Trial 21 finished with value: 0.6962409291807996 and parameters: {'n_estimators': 225, 'max_depth': 9, 'learning_rate': 0.255797641299532, 'subsample': 0.7758530528164678, 'colsample_bytree': 0.7309416857434718, 'gamma': 2.9431718396941426, 'min_child_weight': 2}. Best is trial 12 with value: 0.6995348623008197.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:54,111] Trial 22 finished with value: 0.6916335243231098 and parameters: {'n_estimators': 191, 'max_depth': 8, 'learning_rate': 0.015784662408042216, 'subsample': 0.7671311103737382, 'colsample_bytree': 0.7333661882483158, 'gamma': 2.4004290933209815, 'min_child_weight': 1}. Best is trial 12 with value: 0.6995348623008197.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:54,699] Trial 23 finished with value: 0.7021793355023169 and parameters: {'n_estimators': 218, 'max_depth': 10, 'learning_rate': 0.28640934691073683, 'subsample': 0.826339079518715, 'colsample_bytree': 0.6864787027688489, 'gamma': 2.9296695842322196, 'min_child_weight': 2}. Best is trial 23 with value: 0.7021793355023169.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:55,333] Trial 24 finished with value: 0.6741721563460694 and parameters: {'n_estimators': 240, 'max_depth': 10, 'learning_rate': 0.24430759779068717, 'subsample': 0.8342741954275911, 'colsample_bytree': 0.6782875307244755, 'gamma': 3.0885115501626164, 'min_child_weight': 4}. Best is trial 23 with value: 0.7021793355023169.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:56,036] Trial 25 finished with value: 0.6876853642811089 and parameters: {'n_estimators': 264, 'max_depth': 10, 'learning_rate': 0.1922086038098766, 'subsample': 0.8876577397478007, 'colsample_bytree': 0.7637403428092447, 'gamma': 3.759353401150202, 'min_child_weight': 2}. Best is trial 23 with value: 0.7021793355023169.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:56,791] Trial 26 finished with value: 0.6861285965956492 and parameters: {'n_estimators': 225, 'max_depth': 7, 'learning_rate': 0.27289606494349533, 'subsample': 0.8287878899397152, 'colsample_bytree': 0.6472728964231391, 'gamma': 4.340592891070543, 'min_child_weight': 4}. Best is trial 23 with value: 0.7021793355023169.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:57,430] Trial 27 finished with value: 0.7046829563546889 and parameters: {'n_estimators': 185, 'max_depth': 9, 'learning_rate': 0.1721709113945155, 'subsample': 0.9337407189992843, 'colsample_bytree': 0.6015092464522892, 'gamma': 2.2390927528531357, 'min_child_weight': 3}. Best is trial 27 with value: 0.7046829563546889.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:57,971] Trial 28 finished with value: 0.679978041282389 and parameters: {'n_estimators': 153, 'max_depth': 8, 'learning_rate': 0.16585044251228306, 'subsample': 0.9450048617727056, 'colsample_bytree': 0.6184047707931039, 'gamma': 2.3192005940902023, 'min_child_weight': 3}. Best is trial 27 with value: 0.7046829563546889.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:58,547] Trial 29 finished with value: 0.6807865376696018 and parameters: {'n_estimators': 185, 'max_depth': 6, 'learning_rate': 0.20971222677910778, 'subsample': 0.9988016538883572, 'colsample_bytree': 0.6127585447957471, 'gamma': 0.9997000257194473, 'min_child_weight': 3}. Best is trial 27 with value: 0.7046829563546889.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:35:59,262] Trial 30 finished with value: 0.6625889407830249 and parameters: {'n_estimators': 158, 'max_depth': 10, 'learning_rate': 0.15432783776889705, 'subsample': 0.9298592007268399, 'colsample_bytree': 0.6009562748459093, 'gamma': 2.1735316617131577, 'min_child_weight': 4}. Best is trial 27 with value: 0.7046829563546889.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:35:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:00,029] Trial 31 finished with value: 0.7276975612379339 and parameters: {'n_estimators': 209, 'max_depth': 9, 'learning_rate': 0.23498142354999396, 'subsample': 0.8645261990122115, 'colsample_bytree': 0.6652687854380085, 'gamma': 2.9334603870092155, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:00,670] Trial 32 finished with value: 0.6998766574159729 and parameters: {'n_estimators': 178, 'max_depth': 9, 'learning_rate': 0.22879814215428693, 'subsample': 0.8788927549369344, 'colsample_bytree': 0.652763175958318, 'gamma': 3.7782481866095443, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:01,385] Trial 33 finished with value: 0.6720772946859903 and parameters: {'n_estimators': 207, 'max_depth': 10, 'learning_rate': 0.2289198936252281, 'subsample': 0.8720772767752922, 'colsample_bytree': 0.6456504978355652, 'gamma': 3.9817982372455605, 'min_child_weight': 3}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:02,123] Trial 34 finished with value: 0.7106601660090492 and parameters: {'n_estimators': 184, 'max_depth': 8, 'learning_rate': 0.23863446103014213, 'subsample': 0.8766205808256716, 'colsample_bytree': 0.6635611857429344, 'gamma': 2.720698733709588, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:02,813] Trial 35 finished with value: 0.674149646107179 and parameters: {'n_estimators': 213, 'max_depth': 8, 'learning_rate': 0.28331434208133727, 'subsample': 0.9242363398409938, 'colsample_bytree': 0.6333669325393825, 'gamma': 1.7288519465582266, 'min_child_weight': 5}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:03,430] Trial 36 finished with value: 0.6693427346198251 and parameters: {'n_estimators': 194, 'max_depth': 10, 'learning_rate': 0.247106110550962, 'subsample': 0.9574180078382831, 'colsample_bytree': 0.8063284477496424, 'gamma': 1.994805593092867, 'min_child_weight': 3}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:03,949] Trial 37 finished with value: 0.6925568211780836 and parameters: {'n_estimators': 136, 'max_depth': 7, 'learning_rate': 0.09573654829723104, 'subsample': 0.866492554742214, 'colsample_bytree': 0.6657766640865433, 'gamma': 2.5812074303373342, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:04,601] Trial 38 finished with value: 0.6424513480440532 and parameters: {'n_estimators': 261, 'max_depth': 3, 'learning_rate': 0.26648931382625946, 'subsample': 0.899565246430407, 'colsample_bytree': 0.6950806330423815, 'gamma': 1.249059452497071, 'min_child_weight': 6}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:05,131] Trial 39 finished with value: 0.6796258847320525 and parameters: {'n_estimators': 183, 'max_depth': 8, 'learning_rate': 0.2864923140183455, 'subsample': 0.9665077564379485, 'colsample_bytree': 0.6021046612036522, 'gamma': 2.889233968284215, 'min_child_weight': 3}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:05,826] Trial 40 finished with value: 0.6813523701616122 and parameters: {'n_estimators': 235, 'max_depth': 6, 'learning_rate': 0.13779309615472715, 'subsample': 0.9165060147954265, 'colsample_bytree': 0.628188977812275, 'gamma': 3.2078591856044336, 'min_child_weight': 4}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:06,368] Trial 41 finished with value: 0.7210689690615685 and parameters: {'n_estimators': 183, 'max_depth': 9, 'learning_rate': 0.23492606984748432, 'subsample': 0.8824267543117333, 'colsample_bytree': 0.6571986612175557, 'gamma': 3.4685047826676527, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:06,956] Trial 42 finished with value: 0.6970161373214102 and parameters: {'n_estimators': 203, 'max_depth': 9, 'learning_rate': 0.21525158679577353, 'subsample': 0.9021537802002908, 'colsample_bytree': 0.6611301638775579, 'gamma': 3.5167661903659684, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:07,500] Trial 43 finished with value: 0.7040803343903648 and parameters: {'n_estimators': 163, 'max_depth': 9, 'learning_rate': 0.24093275586488977, 'subsample': 0.86045369111638, 'colsample_bytree': 0.637553068270643, 'gamma': 2.400081076882936, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:08,053] Trial 44 finished with value: 0.6087287434506847 and parameters: {'n_estimators': 167, 'max_depth': 9, 'learning_rate': 0.23954550972010422, 'subsample': 0.8564361342768532, 'colsample_bytree': 0.631708910269239, 'gamma': 2.417258624928146, 'min_child_weight': 8}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:08,617] Trial 45 finished with value: 0.7011493286238892 and parameters: {'n_estimators': 159, 'max_depth': 7, 'learning_rate': 0.169892638156291, 'subsample': 0.8809396048205861, 'colsample_bytree': 0.6424860520447693, 'gamma': 2.2342236750889906, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:09,185] Trial 46 finished with value: 0.672831608005521 and parameters: {'n_estimators': 184, 'max_depth': 8, 'learning_rate': 0.19752010523947164, 'subsample': 0.9378402100518853, 'colsample_bytree': 0.6677509728991216, 'gamma': 1.6067281058106768, 'min_child_weight': 3}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:09,770] Trial 47 finished with value: 0.7054480541410633 and parameters: {'n_estimators': 123, 'max_depth': 9, 'learning_rate': 0.21588550107814927, 'subsample': 0.8562761042928481, 'colsample_bytree': 0.7162667027678137, 'gamma': 2.7366467433845356, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:10,271] Trial 48 finished with value: 0.6857387006045655 and parameters: {'n_estimators': 102, 'max_depth': 9, 'learning_rate': 0.21489945469495997, 'subsample': 0.8925526118417242, 'colsample_bytree': 0.7196530490892992, 'gamma': 3.2211084052949106, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:10,746] Trial 49 finished with value: 0.6890451228286565 and parameters: {'n_estimators': 115, 'max_depth': 8, 'learning_rate': 0.19837050879017465, 'subsample': 0.9151927911760646, 'colsample_bytree': 0.7758655828383932, 'gamma': 2.6776805219884046, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:11,235] Trial 50 finished with value: 0.660421233612723 and parameters: {'n_estimators': 131, 'max_depth': 9, 'learning_rate': 0.1826951495656784, 'subsample': 0.850549109912915, 'colsample_bytree': 0.7552564295350933, 'gamma': 3.366597090470597, 'min_child_weight': 10}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:11,702] Trial 51 finished with value: 0.7017711753218092 and parameters: {'n_estimators': 122, 'max_depth': 9, 'learning_rate': 0.23933399066228953, 'subsample': 0.8626994336563016, 'colsample_bytree': 0.6250906219228548, 'gamma': 1.9354699892817395, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:12,338] Trial 52 finished with value: 0.7056231884057971 and parameters: {'n_estimators': 174, 'max_depth': 9, 'learning_rate': 0.22085258841231234, 'subsample': 0.8470499020140618, 'colsample_bytree': 0.6749173651024287, 'gamma': 2.765162282135174, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:12,896] Trial 53 finished with value: 0.7099141741186145 and parameters: {'n_estimators': 174, 'max_depth': 8, 'learning_rate': 0.26253887638756485, 'subsample': 0.8076768977114263, 'colsample_bytree': 0.7107801497659441, 'gamma': 2.8155591041186683, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:13,426] Trial 54 finished with value: 0.6959528214616096 and parameters: {'n_estimators': 174, 'max_depth': 8, 'learning_rate': 0.2626592802768843, 'subsample': 0.7938482638741597, 'colsample_bytree': 0.7163143096468545, 'gamma': 3.6694561753932806, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:13,969] Trial 55 finished with value: 0.6914276904101141 and parameters: {'n_estimators': 147, 'max_depth': 7, 'learning_rate': 0.22295869358204556, 'subsample': 0.8134981532166934, 'colsample_bytree': 0.8290735602431575, 'gamma': 2.778584019411076, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:14,453] Trial 56 finished with value: 0.6941277997364953 and parameters: {'n_estimators': 142, 'max_depth': 8, 'learning_rate': 0.23298172912865517, 'subsample': 0.8424830045402413, 'colsample_bytree': 0.6906995283455936, 'gamma': 3.1097830050054585, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:15,029] Trial 57 finished with value: 0.676938486032711 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.21979205283586095, 'subsample': 0.8165595524515141, 'colsample_bytree': 0.7466951978121651, 'gamma': 2.804408475751591, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:15,620] Trial 58 finished with value: 0.702480654303041 and parameters: {'n_estimators': 209, 'max_depth': 7, 'learning_rate': 0.2617102176847422, 'subsample': 0.7590587547836958, 'colsample_bytree': 0.707808318979773, 'gamma': 2.538052254651989, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:16,148] Trial 59 finished with value: 0.6639678592262179 and parameters: {'n_estimators': 170, 'max_depth': 9, 'learning_rate': 0.27417453523197466, 'subsample': 0.7469134435356096, 'colsample_bytree': 0.6740934906919966, 'gamma': 3.4343199567574527, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:16,697] Trial 60 finished with value: 0.692999934591054 and parameters: {'n_estimators': 194, 'max_depth': 10, 'learning_rate': 0.24900659697512031, 'subsample': 0.8427557983152001, 'colsample_bytree': 0.7877674955521061, 'gamma': 4.14213949781816, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:17,260] Trial 61 finished with value: 0.6879783029181734 and parameters: {'n_estimators': 189, 'max_depth': 9, 'learning_rate': 0.11621141150573536, 'subsample': 0.8735098807933402, 'colsample_bytree': 0.8933470095958623, 'gamma': 3.031504250233578, 'min_child_weight': 3}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:17,810] Trial 62 finished with value: 0.7107246376811593 and parameters: {'n_estimators': 176, 'max_depth': 9, 'learning_rate': 0.20480001318584723, 'subsample': 0.9063430632027358, 'colsample_bytree': 0.6570377026412871, 'gamma': 2.6777765764568047, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:18,493] Trial 63 finished with value: 0.719199394500042 and parameters: {'n_estimators': 180, 'max_depth': 9, 'learning_rate': 0.19996304586765165, 'subsample': 0.8907230712024778, 'colsample_bytree': 0.6567445018420377, 'gamma': 2.6865903829225064, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:19,043] Trial 64 finished with value: 0.7079992471296819 and parameters: {'n_estimators': 164, 'max_depth': 8, 'learning_rate': 0.2020677185203139, 'subsample': 0.8859120829195132, 'colsample_bytree': 0.6606166253749581, 'gamma': 2.5613235477187457, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:19,579] Trial 65 finished with value: 0.711231884057971 and parameters: {'n_estimators': 178, 'max_depth': 8, 'learning_rate': 0.1984248459622548, 'subsample': 0.905586573486027, 'colsample_bytree': 0.6556372715234097, 'gamma': 3.19885554945828, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:20,137] Trial 66 finished with value: 0.7025362318840579 and parameters: {'n_estimators': 178, 'max_depth': 5, 'learning_rate': 0.20496431663806242, 'subsample': 0.9113694013429896, 'colsample_bytree': 0.6988189017760482, 'gamma': 3.173220201315028, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:20,679] Trial 67 finished with value: 0.6922845330797085 and parameters: {'n_estimators': 180, 'max_depth': 8, 'learning_rate': 0.1893183777559379, 'subsample': 0.9524893219671838, 'colsample_bytree': 0.6548338521926038, 'gamma': 3.3480381925039544, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:21,178] Trial 68 finished with value: 0.7124377914202152 and parameters: {'n_estimators': 155, 'max_depth': 8, 'learning_rate': 0.2368774992132428, 'subsample': 0.9055343705834864, 'colsample_bytree': 0.684365179224483, 'gamma': 3.5905170180445154, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:21,713] Trial 69 finished with value: 0.7065065081901345 and parameters: {'n_estimators': 155, 'max_depth': 7, 'learning_rate': 0.23401533017650594, 'subsample': 0.9012794508389546, 'colsample_bytree': 0.6831373203515615, 'gamma': 3.6135143021671374, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:22,546] Trial 70 finished with value: 0.681749832329983 and parameters: {'n_estimators': 298, 'max_depth': 10, 'learning_rate': 0.1766899911890989, 'subsample': 0.9716692001069145, 'colsample_bytree': 0.6502968314973705, 'gamma': 4.4190932066133275, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:23,119] Trial 71 finished with value: 0.7173717631535543 and parameters: {'n_estimators': 199, 'max_depth': 8, 'learning_rate': 0.25667186301721717, 'subsample': 0.908435761619771, 'colsample_bytree': 0.6756255450075437, 'gamma': 3.825095275921572, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:23,756] Trial 72 finished with value: 0.6924196637980172 and parameters: {'n_estimators': 199, 'max_depth': 8, 'learning_rate': 0.16306346632724153, 'subsample': 0.924671696890099, 'colsample_bytree': 0.6163993588944724, 'gamma': 3.504492958394586, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:24,328] Trial 73 finished with value: 0.7122335286257581 and parameters: {'n_estimators': 220, 'max_depth': 8, 'learning_rate': 0.2501612045186091, 'subsample': 0.9113835999623512, 'colsample_bytree': 0.6748164238558768, 'gamma': 3.7997272262845634, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:24,924] Trial 74 finished with value: 0.7119070335503921 and parameters: {'n_estimators': 218, 'max_depth': 9, 'learning_rate': 0.2526236779833084, 'subsample': 0.9091922565195024, 'colsample_bytree': 0.9890833880394996, 'gamma': 3.76612301405196, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:25,516] Trial 75 finished with value: 0.685804389874695 and parameters: {'n_estimators': 220, 'max_depth': 7, 'learning_rate': 0.25236012618904524, 'subsample': 0.9203716944455321, 'colsample_bytree': 0.9675092641927052, 'gamma': 4.07485853889379, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:26,076] Trial 76 finished with value: 0.7039393939393939 and parameters: {'n_estimators': 207, 'max_depth': 6, 'learning_rate': 0.29444396900552466, 'subsample': 0.8903518413309703, 'colsample_bytree': 0.688096142627232, 'gamma': 3.8373586783001845, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:26,721] Trial 77 finished with value: 0.6810192582625515 and parameters: {'n_estimators': 229, 'max_depth': 8, 'learning_rate': 0.25618060777277807, 'subsample': 0.9419220669757411, 'colsample_bytree': 0.9930279398594772, 'gamma': 3.8886786315894946, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:27,437] Trial 78 finished with value: 0.6856964651136714 and parameters: {'n_estimators': 220, 'max_depth': 9, 'learning_rate': 0.27272511039657993, 'subsample': 0.9875275968940858, 'colsample_bytree': 0.9324374065067842, 'gamma': 4.567476787342949, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:28,177] Trial 79 finished with value: 0.6628097814406788 and parameters: {'n_estimators': 249, 'max_depth': 10, 'learning_rate': 0.24602076441439227, 'subsample': 0.888659417623394, 'colsample_bytree': 0.6420111726504227, 'gamma': 3.684645455688308, 'min_child_weight': 8}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:29,052] Trial 80 finished with value: 0.7057356170399649 and parameters: {'n_estimators': 215, 'max_depth': 9, 'learning_rate': 0.14519788799751207, 'subsample': 0.9084915618646704, 'colsample_bytree': 0.8766906911124595, 'gamma': 4.208056266529298, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:29,631] Trial 81 finished with value: 0.7024586288416076 and parameters: {'n_estimators': 211, 'max_depth': 9, 'learning_rate': 0.21007046841793814, 'subsample': 0.9073715207895346, 'colsample_bytree': 0.6719883431699636, 'gamma': 3.7458527297866944, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:30,318] Trial 82 finished with value: 0.6939244059820859 and parameters: {'n_estimators': 287, 'max_depth': 9, 'learning_rate': 0.22818866593172793, 'subsample': 0.9364714372085398, 'colsample_bytree': 0.9250881409000095, 'gamma': 4.019799080712886, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:30,875] Trial 83 finished with value: 0.688312262308562 and parameters: {'n_estimators': 191, 'max_depth': 8, 'learning_rate': 0.2504604463230106, 'subsample': 0.9510086105960471, 'colsample_bytree': 0.6516809095668721, 'gamma': 3.5249680869668283, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:31,447] Trial 84 finished with value: 0.6891220250609704 and parameters: {'n_estimators': 204, 'max_depth': 10, 'learning_rate': 0.23614881707745639, 'subsample': 0.8962775306796047, 'colsample_bytree': 0.6804656683960286, 'gamma': 3.278251175976185, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:32,000] Trial 85 finished with value: 0.7093516104616937 and parameters: {'n_estimators': 195, 'max_depth': 9, 'learning_rate': 0.1927135862396162, 'subsample': 0.9274648939378722, 'colsample_bytree': 0.6984844143113036, 'gamma': 3.0426773949668555, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:32,629] Trial 86 finished with value: 0.6827687900235928 and parameters: {'n_estimators': 187, 'max_depth': 9, 'learning_rate': 0.2255997575451457, 'subsample': 0.8753106026764305, 'colsample_bytree': 0.6567958944906175, 'gamma': 3.3977953115865764, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:33,173] Trial 87 finished with value: 0.6787752983912818 and parameters: {'n_estimators': 169, 'max_depth': 9, 'learning_rate': 0.2780246988773917, 'subsample': 0.6329351703247337, 'colsample_bytree': 0.6235041594299795, 'gamma': 3.8719976273512766, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:33,796] Trial 88 finished with value: 0.7053654024051803 and parameters: {'n_estimators': 225, 'max_depth': 8, 'learning_rate': 0.21130347037687322, 'subsample': 0.9132783175418923, 'colsample_bytree': 0.6420995711634891, 'gamma': 3.6245501510228273, 'min_child_weight': 3}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:34,406] Trial 89 finished with value: 0.7034762051598313 and parameters: {'n_estimators': 236, 'max_depth': 8, 'learning_rate': 0.26735168664827724, 'subsample': 0.8814644177715016, 'colsample_bytree': 0.7246140482482859, 'gamma': 4.303262059513357, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:34,913] Trial 90 finished with value: 0.6424152546700576 and parameters: {'n_estimators': 161, 'max_depth': 7, 'learning_rate': 0.24321920152295903, 'subsample': 0.8685621490289493, 'colsample_bytree': 0.6676582836626729, 'gamma': 2.8928160424614373, 'min_child_weight': 6}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:35,624] Trial 91 finished with value: 0.6956717773054621 and parameters: {'n_estimators': 180, 'max_depth': 8, 'learning_rate': 0.2350744914069587, 'subsample': 0.8967125951833781, 'colsample_bytree': 0.6609165738267242, 'gamma': 2.6758852433711104, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:36,210] Trial 92 finished with value: 0.6998545824399363 and parameters: {'n_estimators': 202, 'max_depth': 8, 'learning_rate': 0.2199073669627199, 'subsample': 0.9221463921708658, 'colsample_bytree': 0.635284834930457, 'gamma': 2.9632641613346866, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:36,786] Trial 93 finished with value: 0.7068992248062015 and parameters: {'n_estimators': 195, 'max_depth': 8, 'learning_rate': 0.25737929707773083, 'subsample': 0.9064787099096375, 'colsample_bytree': 0.8453132778459278, 'gamma': 3.172189370316052, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:37,587] Trial 94 finished with value: 0.6150436112429467 and parameters: {'n_estimators': 152, 'max_depth': 9, 'learning_rate': 0.18678393327600817, 'subsample': 0.8842214383116354, 'colsample_bytree': 0.6777771242944431, 'gamma': 0.008671726460038442, 'min_child_weight': 3}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:38,178] Trial 95 finished with value: 0.7141758005587793 and parameters: {'n_estimators': 188, 'max_depth': 9, 'learning_rate': 0.24218809410167735, 'subsample': 0.9328734411648284, 'colsample_bytree': 0.690584919584064, 'gamma': 2.4322270374794357, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:38,774] Trial 96 finished with value: 0.7062582345191041 and parameters: {'n_estimators': 198, 'max_depth': 9, 'learning_rate': 0.24333519475962664, 'subsample': 0.9339424740243328, 'colsample_bytree': 0.6894831287634888, 'gamma': 2.391015429035382, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:39,370] Trial 97 finished with value: 0.7052161431948666 and parameters: {'n_estimators': 213, 'max_depth': 9, 'learning_rate': 0.19699157706781334, 'subsample': 0.9471481898807665, 'colsample_bytree': 0.7068756062936276, 'gamma': 2.126966537002395, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:39,934] Trial 98 finished with value: 0.7011290866194809 and parameters: {'n_estimators': 190, 'max_depth': 10, 'learning_rate': 0.23049601251895782, 'subsample': 0.9639805185922985, 'colsample_bytree': 0.6957208247664332, 'gamma': 3.2863675172708398, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:40,966] Trial 99 finished with value: 0.7062153530100952 and parameters: {'n_estimators': 179, 'max_depth': 9, 'learning_rate': 0.05912510852798103, 'subsample': 0.9150796616308237, 'colsample_bytree': 0.6739248909627993, 'gamma': 0.37353513257161985, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:41,531] Trial 100 finished with value: 0.6841625557904628 and parameters: {'n_estimators': 171, 'max_depth': 3, 'learning_rate': 0.2673292834194128, 'subsample': 0.9323998205696062, 'colsample_bytree': 0.6087128262398693, 'gamma': 3.433377009143198, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:42,102] Trial 101 finished with value: 0.7148998163471658 and parameters: {'n_estimators': 185, 'max_depth': 9, 'learning_rate': 0.25729363206002265, 'subsample': 0.8981142125292362, 'colsample_bytree': 0.666442391302203, 'gamma': 2.2820209871323494, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:42,785] Trial 102 finished with value: 0.7119986518368722 and parameters: {'n_estimators': 187, 'max_depth': 9, 'learning_rate': 0.25767218643550566, 'subsample': 0.8986106978411665, 'colsample_bytree': 0.6474924197293818, 'gamma': 2.434056027304922, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:43,377] Trial 103 finished with value: 0.6658074534161491 and parameters: {'n_estimators': 184, 'max_depth': 9, 'learning_rate': 0.25341109771232445, 'subsample': 0.7048393863489273, 'colsample_bytree': 0.6463671805375933, 'gamma': 2.4770419271660584, 'min_child_weight': 3}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:44,483] Trial 104 finished with value: 0.6908076972861026 and parameters: {'n_estimators': 205, 'max_depth': 9, 'learning_rate': 0.25956708097781117, 'subsample': 0.8944454041971213, 'colsample_bytree': 0.683836168789365, 'gamma': 2.2884107969692415, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:45,146] Trial 105 finished with value: 0.6678555770470663 and parameters: {'n_estimators': 189, 'max_depth': 10, 'learning_rate': 0.28810839753680395, 'subsample': 0.8645700003722898, 'colsample_bytree': 0.6688945359072623, 'gamma': 2.080317400210105, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:45,786] Trial 106 finished with value: 0.724514338575393 and parameters: {'n_estimators': 229, 'max_depth': 9, 'learning_rate': 0.27958087893325834, 'subsample': 0.9010381212279237, 'colsample_bytree': 0.6322234856766148, 'gamma': 3.744866340576933, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:46,399] Trial 107 finished with value: 0.6774519716885743 and parameters: {'n_estimators': 228, 'max_depth': 9, 'learning_rate': 0.27872721194108646, 'subsample': 0.9180264774361038, 'colsample_bytree': 0.6338300490857963, 'gamma': 3.7670048408024726, 'min_child_weight': 3}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:46,991] Trial 108 finished with value: 0.7076911869811424 and parameters: {'n_estimators': 244, 'max_depth': 9, 'learning_rate': 0.2945573453674837, 'subsample': 0.8799406857570159, 'colsample_bytree': 0.6217537028233519, 'gamma': 3.992298254903768, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:47,665] Trial 109 finished with value: 0.685232137653453 and parameters: {'n_estimators': 219, 'max_depth': 10, 'learning_rate': 0.2673276930725255, 'subsample': 0.8965157626445888, 'colsample_bytree': 0.8222010024694587, 'gamma': 4.101100627683466, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:48,283] Trial 110 finished with value: 0.684880756300625 and parameters: {'n_estimators': 210, 'max_depth': 9, 'learning_rate': 0.2501506113721471, 'subsample': 0.8549037669382118, 'colsample_bytree': 0.6093397836024267, 'gamma': 3.9304025552294957, 'min_child_weight': 3}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:48,909] Trial 111 finished with value: 0.692330333865949 and parameters: {'n_estimators': 223, 'max_depth': 9, 'learning_rate': 0.2389918959269882, 'subsample': 0.8886079318214063, 'colsample_bytree': 0.6497532022510621, 'gamma': 3.560401233747123, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:49,721] Trial 112 finished with value: 0.6887878787878787 and parameters: {'n_estimators': 233, 'max_depth': 8, 'learning_rate': 0.020225468161672477, 'subsample': 0.9034377544645626, 'colsample_bytree': 0.6642392847931878, 'gamma': 2.4873603195664495, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:50,276] Trial 113 finished with value: 0.6941622077025804 and parameters: {'n_estimators': 182, 'max_depth': 9, 'learning_rate': 0.2602955413116786, 'subsample': 0.9220049030869901, 'colsample_bytree': 0.640646143662646, 'gamma': 1.8392088634469421, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:50,828] Trial 114 finished with value: 0.6584381678553741 and parameters: {'n_estimators': 197, 'max_depth': 9, 'learning_rate': 0.24793765250764144, 'subsample': 0.9273506785337802, 'colsample_bytree': 0.6587889992167653, 'gamma': 3.655178413042615, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:51,398] Trial 115 finished with value: 0.651136900924135 and parameters: {'n_estimators': 216, 'max_depth': 8, 'learning_rate': 0.27169001791584263, 'subsample': 0.8741101428646243, 'colsample_bytree': 0.6293330287495407, 'gamma': 2.3303085345324765, 'min_child_weight': 7}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:51,972] Trial 116 finished with value: 0.6974647988312584 and parameters: {'n_estimators': 201, 'max_depth': 9, 'learning_rate': 0.28372055530014095, 'subsample': 0.9124468258700534, 'colsample_bytree': 0.6912830295186217, 'gamma': 3.8104530557074203, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:52,502] Trial 117 finished with value: 0.6943669705709212 and parameters: {'n_estimators': 167, 'max_depth': 8, 'learning_rate': 0.25350710169786794, 'subsample': 0.9415294124804188, 'colsample_bytree': 0.7384362672141165, 'gamma': 2.622721372638264, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:53,200] Trial 118 finished with value: 0.6972542258851233 and parameters: {'n_estimators': 191, 'max_depth': 10, 'learning_rate': 0.24325681137631053, 'subsample': 0.9018719360924264, 'colsample_bytree': 0.6787430587604468, 'gamma': 3.1225134255464937, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:53,745] Trial 119 finished with value: 0.6665099785584694 and parameters: {'n_estimators': 186, 'max_depth': 9, 'learning_rate': 0.22543051638071981, 'subsample': 0.8887039029389093, 'colsample_bytree': 0.651154373898125, 'gamma': 2.1818798386350995, 'min_child_weight': 5}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:54,275] Trial 120 finished with value: 0.7014987997221133 and parameters: {'n_estimators': 176, 'max_depth': 9, 'learning_rate': 0.2760337354831407, 'subsample': 0.8679925285368602, 'colsample_bytree': 0.6703950492392817, 'gamma': 3.4237301706332666, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:54,815] Trial 121 finished with value: 0.7061678300114933 and parameters: {'n_estimators': 176, 'max_depth': 9, 'learning_rate': 0.23053189809600466, 'subsample': 0.9067008866320998, 'colsample_bytree': 0.6587790200965307, 'gamma': 2.8453458461303245, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:55,362] Trial 122 finished with value: 0.7137014922583841 and parameters: {'n_estimators': 172, 'max_depth': 9, 'learning_rate': 0.26468910932423784, 'subsample': 0.8986086390135168, 'colsample_bytree': 0.635942323329093, 'gamma': 2.028308895180961, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:55,936] Trial 123 finished with value: 0.702160094371419 and parameters: {'n_estimators': 183, 'max_depth': 9, 'learning_rate': 0.26066972997748417, 'subsample': 0.8806262499007547, 'colsample_bytree': 0.6429005338290957, 'gamma': 1.5836200849491209, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:56,550] Trial 124 finished with value: 0.7029892648925413 and parameters: {'n_estimators': 232, 'max_depth': 8, 'learning_rate': 0.2651506712077153, 'subsample': 0.8930001381265366, 'colsample_bytree': 0.6303721168571459, 'gamma': 1.9803920797210695, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:57,096] Trial 125 finished with value: 0.6896866911483007 and parameters: {'n_estimators': 172, 'max_depth': 9, 'learning_rate': 0.2545936479193985, 'subsample': 0.9129464085008991, 'colsample_bytree': 0.6172112908620355, 'gamma': 1.768063530224329, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:57,674] Trial 126 finished with value: 0.7135489025313262 and parameters: {'n_estimators': 166, 'max_depth': 10, 'learning_rate': 0.2376555152660686, 'subsample': 0.8994584867848323, 'colsample_bytree': 0.6659611911478995, 'gamma': 3.722703000023092, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:58,264] Trial 127 finished with value: 0.6939525520072632 and parameters: {'n_estimators': 159, 'max_depth': 10, 'learning_rate': 0.23923832019567598, 'subsample': 0.929957049169933, 'colsample_bytree': 0.9629901707227146, 'gamma': 2.066810140080894, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:59,164] Trial 128 finished with value: 0.7057732739046337 and parameters: {'n_estimators': 153, 'max_depth': 10, 'learning_rate': 0.24470357567488632, 'subsample': 0.8936677744855152, 'colsample_bytree': 0.6860102741927235, 'gamma': 3.716649919271996, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:36:59,777] Trial 129 finished with value: 0.7083001909897765 and parameters: {'n_estimators': 167, 'max_depth': 10, 'learning_rate': 0.2336991409440289, 'subsample': 0.9565037173795812, 'colsample_bytree': 0.7939629739597713, 'gamma': 3.9981198955507917, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:36:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:00,389] Trial 130 finished with value: 0.6946969696969696 and parameters: {'n_estimators': 142, 'max_depth': 9, 'learning_rate': 0.2713705429389706, 'subsample': 0.9186218714753934, 'colsample_bytree': 0.7026389368695796, 'gamma': 4.224654697399375, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:00,914] Trial 131 finished with value: 0.693483592241934 and parameters: {'n_estimators': 165, 'max_depth': 7, 'learning_rate': 0.24895084268414433, 'subsample': 0.9051396964416649, 'colsample_bytree': 0.6657503356541087, 'gamma': 3.85389900264951, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:01,453] Trial 132 finished with value: 0.6973565441650549 and parameters: {'n_estimators': 180, 'max_depth': 8, 'learning_rate': 0.2200117520550066, 'subsample': 0.8974170748155648, 'colsample_bytree': 0.652060585889045, 'gamma': 3.5666391650515537, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:02,005] Trial 133 finished with value: 0.6788767186961151 and parameters: {'n_estimators': 188, 'max_depth': 9, 'learning_rate': 0.25713212414021197, 'subsample': 0.8835422860057702, 'colsample_bytree': 0.6372900653035404, 'gamma': 3.2791015676997204, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:02,750] Trial 134 finished with value: 0.6730442804890584 and parameters: {'n_estimators': 207, 'max_depth': 8, 'learning_rate': 0.2369734499426641, 'subsample': 0.9233789138765365, 'colsample_bytree': 0.6788651569611212, 'gamma': 3.4724092624541694, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:03,430] Trial 135 finished with value: 0.6883420151342009 and parameters: {'n_estimators': 223, 'max_depth': 9, 'learning_rate': 0.2650381906862063, 'subsample': 0.9026398532033876, 'colsample_bytree': 0.6727985539211494, 'gamma': 2.2661680403216025, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:04,027] Trial 136 finished with value: 0.6822723067866454 and parameters: {'n_estimators': 193, 'max_depth': 9, 'learning_rate': 0.28882606097998587, 'subsample': 0.8753738223358415, 'colsample_bytree': 0.6479064864047395, 'gamma': 3.6686590475741863, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:04,640] Trial 137 finished with value: 0.6923160173160172 and parameters: {'n_estimators': 239, 'max_depth': 5, 'learning_rate': 0.28181031339049206, 'subsample': 0.9380423007514314, 'colsample_bytree': 0.6611875197667881, 'gamma': 2.443556336957627, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:05,171] Trial 138 finished with value: 0.7007006232538148 and parameters: {'n_estimators': 162, 'max_depth': 10, 'learning_rate': 0.1594626778914886, 'subsample': 0.8887236400613603, 'colsample_bytree': 0.6229211621953945, 'gamma': 2.5569012467818975, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:05,683] Trial 139 finished with value: 0.69205841953298 and parameters: {'n_estimators': 157, 'max_depth': 6, 'learning_rate': 0.22620461863703306, 'subsample': 0.9118022616248053, 'colsample_bytree': 0.6372363524662769, 'gamma': 3.3562824478675894, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:06,336] Trial 140 finished with value: 0.6780224072360983 and parameters: {'n_estimators': 173, 'max_depth': 9, 'learning_rate': 0.21339144230362628, 'subsample': 0.8612780018893388, 'colsample_bytree': 0.6556234128894016, 'gamma': 3.732633482086817, 'min_child_weight': 4}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:06,894] Trial 141 finished with value: 0.7150518956776779 and parameters: {'n_estimators': 179, 'max_depth': 9, 'learning_rate': 0.17759827431551978, 'subsample': 0.9082013224353105, 'colsample_bytree': 0.6646023012042976, 'gamma': 2.677950254995281, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:07,457] Trial 142 finished with value: 0.6922222222222223 and parameters: {'n_estimators': 179, 'max_depth': 9, 'learning_rate': 0.25210296119568926, 'subsample': 0.9010299636258651, 'colsample_bytree': 0.6676401758208531, 'gamma': 3.0331482883700587, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:08,099] Trial 143 finished with value: 0.6808510638297871 and parameters: {'n_estimators': 188, 'max_depth': 9, 'learning_rate': 0.1809649203666209, 'subsample': 0.9183000372273642, 'colsample_bytree': 0.6958222264686118, 'gamma': 2.6460301621895415, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:08,670] Trial 144 finished with value: 0.6923135144226725 and parameters: {'n_estimators': 170, 'max_depth': 9, 'learning_rate': 0.1760844595871097, 'subsample': 0.9097165427865351, 'colsample_bytree': 0.6848400488227383, 'gamma': 2.887095394458128, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:09,256] Trial 145 finished with value: 0.7095520421607378 and parameters: {'n_estimators': 184, 'max_depth': 8, 'learning_rate': 0.16907859404709286, 'subsample': 0.9267637504334211, 'colsample_bytree': 0.6755227233467874, 'gamma': 2.7517191278469095, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:09,867] Trial 146 finished with value: 0.7116316554960791 and parameters: {'n_estimators': 213, 'max_depth': 9, 'learning_rate': 0.14713273894329054, 'subsample': 0.8962022187068701, 'colsample_bytree': 0.6453239686406093, 'gamma': 2.3675598093292516, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:10,471] Trial 147 finished with value: 0.7030064754856614 and parameters: {'n_estimators': 211, 'max_depth': 9, 'learning_rate': 0.1487595630503088, 'subsample': 0.8871808289750429, 'colsample_bytree': 0.645722561443976, 'gamma': 2.196406909638118, 'min_child_weight': 3}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:11,062] Trial 148 finished with value: 0.7205295321391528 and parameters: {'n_estimators': 216, 'max_depth': 9, 'learning_rate': 0.24618305690289075, 'subsample': 0.8961075455172572, 'colsample_bytree': 0.6288943790939953, 'gamma': 2.3915507646215532, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:11,657] Trial 149 finished with value: 0.7121184088806661 and parameters: {'n_estimators': 218, 'max_depth': 9, 'learning_rate': 0.24389454227618138, 'subsample': 0.8733335858575662, 'colsample_bytree': 0.628904017838953, 'gamma': 2.5359621408408404, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:12,416] Trial 150 finished with value: 0.6887113503209711 and parameters: {'n_estimators': 199, 'max_depth': 10, 'learning_rate': 0.24524237114973896, 'subsample': 0.8683742311876697, 'colsample_bytree': 0.6089624490114509, 'gamma': 2.445719895080165, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:13,081] Trial 151 finished with value: 0.6974334703009701 and parameters: {'n_estimators': 217, 'max_depth': 9, 'learning_rate': 0.2406289714363149, 'subsample': 0.8810660727495957, 'colsample_bytree': 0.6163077302653526, 'gamma': 2.6211749787646657, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:13,680] Trial 152 finished with value: 0.697623862487361 and parameters: {'n_estimators': 219, 'max_depth': 9, 'learning_rate': 0.25727446444993524, 'subsample': 0.8767302653298866, 'colsample_bytree': 0.6299772619819817, 'gamma': 2.314252735861402, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:14,295] Trial 153 finished with value: 0.7110586718246292 and parameters: {'n_estimators': 229, 'max_depth': 9, 'learning_rate': 0.23335134840265245, 'subsample': 0.8984256789108837, 'colsample_bytree': 0.6649384858971094, 'gamma': 2.5283370052016694, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:14,967] Trial 154 finished with value: 0.6856060606060606 and parameters: {'n_estimators': 226, 'max_depth': 9, 'learning_rate': 0.24772057499831301, 'subsample': 0.9138658792754483, 'colsample_bytree': 0.6256660048169865, 'gamma': 3.9058172016152706, 'min_child_weight': 3}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:15,544] Trial 155 finished with value: 0.6930907540881965 and parameters: {'n_estimators': 193, 'max_depth': 9, 'learning_rate': 0.26252508361638993, 'subsample': 0.8904742319825679, 'colsample_bytree': 0.6363557427311053, 'gamma': 2.2681858467742786, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:16,060] Trial 156 finished with value: 0.7196479345361333 and parameters: {'n_estimators': 149, 'max_depth': 9, 'learning_rate': 0.2522269530114693, 'subsample': 0.9044259706545421, 'colsample_bytree': 0.9124506041873535, 'gamma': 1.9140203586788556, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:16,581] Trial 157 finished with value: 0.6830764724020968 and parameters: {'n_estimators': 145, 'max_depth': 9, 'learning_rate': 0.2700214040344718, 'subsample': 0.8490753724145008, 'colsample_bytree': 0.9067092008049976, 'gamma': 1.8475958100132555, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:17,111] Trial 158 finished with value: 0.688083264253477 and parameters: {'n_estimators': 136, 'max_depth': 9, 'learning_rate': 0.2406175374016803, 'subsample': 0.8993646679325418, 'colsample_bytree': 0.8456808412760604, 'gamma': 2.032870766951564, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:17,628] Trial 159 finished with value: 0.6975072463768116 and parameters: {'n_estimators': 149, 'max_depth': 9, 'learning_rate': 0.2472063549674066, 'subsample': 0.8829333543077877, 'colsample_bytree': 0.6552943928640725, 'gamma': 1.9678857192207975, 'min_child_weight': 3}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:18,256] Trial 160 finished with value: 0.6966376559874644 and parameters: {'n_estimators': 203, 'max_depth': 9, 'learning_rate': 0.23078098159085217, 'subsample': 0.8713089843393053, 'colsample_bytree': 0.6725468986462061, 'gamma': 2.1318124836209797, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:18,938] Trial 161 finished with value: 0.6856984273820537 and parameters: {'n_estimators': 215, 'max_depth': 9, 'learning_rate': 0.2533876424743647, 'subsample': 0.9074845659417741, 'colsample_bytree': 0.970362402093108, 'gamma': 4.985067086972457, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:19,593] Trial 162 finished with value: 0.7124169553026554 and parameters: {'n_estimators': 222, 'max_depth': 9, 'learning_rate': 0.25914127919336205, 'subsample': 0.9204761672657615, 'colsample_bytree': 0.9933036160036093, 'gamma': 1.538036994797517, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:20,212] Trial 163 finished with value: 0.6956748087167504 and parameters: {'n_estimators': 222, 'max_depth': 9, 'learning_rate': 0.26150188073743097, 'subsample': 0.9237620933677719, 'colsample_bytree': 0.9335632578922439, 'gamma': 1.26109376621425, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:20,837] Trial 164 finished with value: 0.7033838383838383 and parameters: {'n_estimators': 230, 'max_depth': 9, 'learning_rate': 0.27759315314218036, 'subsample': 0.9181863493385117, 'colsample_bytree': 0.9519104396844831, 'gamma': 1.459336639652153, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:21,420] Trial 165 finished with value: 0.6965506125080594 and parameters: {'n_estimators': 207, 'max_depth': 10, 'learning_rate': 0.25686519095944366, 'subsample': 0.9341171231171914, 'colsample_bytree': 0.6614593958628353, 'gamma': 1.6569773480196668, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:21,961] Trial 166 finished with value: 0.6974103196628636 and parameters: {'n_estimators': 182, 'max_depth': 9, 'learning_rate': 0.24157856874426936, 'subsample': 0.8917563756815665, 'colsample_bytree': 0.8871778299715386, 'gamma': 2.383033092727573, 'min_child_weight': 3}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:22,669] Trial 167 finished with value: 0.6998521290611948 and parameters: {'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.2354010225439713, 'subsample': 0.9028119008960742, 'colsample_bytree': 0.6418553296864221, 'gamma': 2.697644837282595, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:23,195] Trial 168 finished with value: 0.676396388643877 and parameters: {'n_estimators': 156, 'max_depth': 9, 'learning_rate': 0.26728694147640686, 'subsample': 0.9428402753174316, 'colsample_bytree': 0.6002072273054678, 'gamma': 1.4400101715334857, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:23,754] Trial 169 finished with value: 0.7127672030772335 and parameters: {'n_estimators': 175, 'max_depth': 10, 'learning_rate': 0.24669805594467586, 'subsample': 0.911140940141651, 'colsample_bytree': 0.6507537882951913, 'gamma': 1.8953173030219408, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:24,278] Trial 170 finished with value: 0.6227938964109176 and parameters: {'n_estimators': 163, 'max_depth': 10, 'learning_rate': 0.22422653919887728, 'subsample': 0.927990604596009, 'colsample_bytree': 0.6819108799590748, 'gamma': 1.0032901440723043, 'min_child_weight': 10}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:24,827] Trial 171 finished with value: 0.6852951247522535 and parameters: {'n_estimators': 176, 'max_depth': 10, 'learning_rate': 0.24949246170253525, 'subsample': 0.9151057277986004, 'colsample_bytree': 0.6515824697024132, 'gamma': 2.1984747874339705, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:25,386] Trial 172 finished with value: 0.6949857044266983 and parameters: {'n_estimators': 173, 'max_depth': 10, 'learning_rate': 0.24611609279078348, 'subsample': 0.8955225625571488, 'colsample_bytree': 0.9135359621935327, 'gamma': 1.805549876498195, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:26,002] Trial 173 finished with value: 0.7016469038208168 and parameters: {'n_estimators': 225, 'max_depth': 9, 'learning_rate': 0.2617587375344049, 'subsample': 0.9085295790266464, 'colsample_bytree': 0.7736398246521148, 'gamma': 1.5750741526014482, 'min_child_weight': 2}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:26,596] Trial 174 finished with value: 0.720791962174941 and parameters: {'n_estimators': 186, 'max_depth': 10, 'learning_rate': 0.255700861574021, 'subsample': 0.890020998265446, 'colsample_bytree': 0.9775610176617411, 'gamma': 1.9093439369295033, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:27,151] Trial 175 finished with value: 0.7106097048187705 and parameters: {'n_estimators': 182, 'max_depth': 10, 'learning_rate': 0.23766178994890558, 'subsample': 0.8877426825797442, 'colsample_bytree': 0.6691201950471938, 'gamma': 1.89771695430508, 'min_child_weight': 1}. Best is trial 31 with value: 0.7276975612379339.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:27,714] Trial 176 finished with value: 0.7296969696969697 and parameters: {'n_estimators': 170, 'max_depth': 10, 'learning_rate': 0.2528051299968366, 'subsample': 0.8811976844274624, 'colsample_bytree': 0.976178432096357, 'gamma': 1.7341641914446353, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:28,289] Trial 177 finished with value: 0.682632360217714 and parameters: {'n_estimators': 168, 'max_depth': 10, 'learning_rate': 0.2523095064003903, 'subsample': 0.9042006434293691, 'colsample_bytree': 0.9798860085781614, 'gamma': 1.7559285693749698, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:29,296] Trial 178 finished with value: 0.7131718695383291 and parameters: {'n_estimators': 171, 'max_depth': 10, 'learning_rate': 0.2680320104269979, 'subsample': 0.8857335072534303, 'colsample_bytree': 0.9964739563175418, 'gamma': 1.6489469924423106, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:29,909] Trial 179 finished with value: 0.7011435312244211 and parameters: {'n_estimators': 171, 'max_depth': 10, 'learning_rate': 0.2724718222459976, 'subsample': 0.8816671238397259, 'colsample_bytree': 0.9836785507809462, 'gamma': 1.4863809621015986, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:30,576] Trial 180 finished with value: 0.7005793157842847 and parameters: {'n_estimators': 177, 'max_depth': 10, 'learning_rate': 0.26743868216766714, 'subsample': 0.8579298065003779, 'colsample_bytree': 0.9935727639656049, 'gamma': 1.7144380444425997, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:31,248] Trial 181 finished with value: 0.697121212121212 and parameters: {'n_estimators': 165, 'max_depth': 10, 'learning_rate': 0.2588304325978121, 'subsample': 0.8929170903116465, 'colsample_bytree': 0.9747044882128026, 'gamma': 1.949942555628583, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:32,411] Trial 182 finished with value: 0.6894087422202924 and parameters: {'n_estimators': 159, 'max_depth': 10, 'learning_rate': 0.25208647133023127, 'subsample': 0.9157262635390498, 'colsample_bytree': 0.9593769546629197, 'gamma': 1.6795188804014232, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:33,034] Trial 183 finished with value: 0.6937479643019998 and parameters: {'n_estimators': 176, 'max_depth': 10, 'learning_rate': 0.2773902963822614, 'subsample': 0.8844131440795288, 'colsample_bytree': 0.9961274722693303, 'gamma': 1.850515453222416, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:33,721] Trial 184 finished with value: 0.7017093207366762 and parameters: {'n_estimators': 169, 'max_depth': 10, 'learning_rate': 0.13000423743360104, 'subsample': 0.9037897604437093, 'colsample_bytree': 0.9885690491783784, 'gamma': 1.3375664608311313, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:34,376] Trial 185 finished with value: 0.7177971014492753 and parameters: {'n_estimators': 187, 'max_depth': 10, 'learning_rate': 0.2649566882641592, 'subsample': 0.9106335979356872, 'colsample_bytree': 0.9856882207768243, 'gamma': 1.5358446487159831, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:35,001] Trial 186 finished with value: 0.7038691528070902 and parameters: {'n_estimators': 187, 'max_depth': 10, 'learning_rate': 0.26446693177089153, 'subsample': 0.8943930948538054, 'colsample_bytree': 0.9801720673391066, 'gamma': 1.6319895652057848, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:35,573] Trial 187 finished with value: 0.6780822510822511 and parameters: {'n_estimators': 179, 'max_depth': 10, 'learning_rate': 0.2735545810729537, 'subsample': 0.9216628055763452, 'colsample_bytree': 0.9977360381436527, 'gamma': 1.5364217038873622, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:36,173] Trial 188 finished with value: 0.6381457498201254 and parameters: {'n_estimators': 195, 'max_depth': 10, 'learning_rate': 0.2571650674607417, 'subsample': 0.9099520075047648, 'colsample_bytree': 0.9849596486872387, 'gamma': 1.350504174373657, 'min_child_weight': 8}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:36,772] Trial 189 finished with value: 0.716798418972332 and parameters: {'n_estimators': 173, 'max_depth': 10, 'learning_rate': 0.28326198259037944, 'subsample': 0.8869567194892927, 'colsample_bytree': 0.9711029295049948, 'gamma': 1.9892921224187539, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:37,325] Trial 190 finished with value: 0.7003223726627981 and parameters: {'n_estimators': 173, 'max_depth': 10, 'learning_rate': 0.2755616183765328, 'subsample': 0.8787017682078301, 'colsample_bytree': 0.9736330673167252, 'gamma': 2.0454160671285804, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:37,932] Trial 191 finished with value: 0.7175899432767535 and parameters: {'n_estimators': 184, 'max_depth': 10, 'learning_rate': 0.26894294982544475, 'subsample': 0.88677589078813, 'colsample_bytree': 0.9572873785554229, 'gamma': 1.761861924801515, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:38,505] Trial 192 finished with value: 0.692753511058784 and parameters: {'n_estimators': 186, 'max_depth': 10, 'learning_rate': 0.2876816730300251, 'subsample': 0.8884892079558677, 'colsample_bytree': 0.9761956920557365, 'gamma': 1.8975555421550672, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:39,094] Trial 193 finished with value: 0.699554677206851 and parameters: {'n_estimators': 180, 'max_depth': 10, 'learning_rate': 0.2926238973485239, 'subsample': 0.8669757804004689, 'colsample_bytree': 0.9542555702213258, 'gamma': 1.6900440600701836, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:39,675] Trial 194 finished with value: 0.6960345855694692 and parameters: {'n_estimators': 191, 'max_depth': 10, 'learning_rate': 0.27932185215592487, 'subsample': 0.8975876488908989, 'colsample_bytree': 0.9647423164325725, 'gamma': 1.7648097077558307, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:40,249] Trial 195 finished with value: 0.7176309814145152 and parameters: {'n_estimators': 183, 'max_depth': 10, 'learning_rate': 0.2985167260692056, 'subsample': 0.8852435497334108, 'colsample_bytree': 0.9461544206824746, 'gamma': 1.958029185516069, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:40,810] Trial 196 finished with value: 0.728509738653232 and parameters: {'n_estimators': 185, 'max_depth': 10, 'learning_rate': 0.28305013429419235, 'subsample': 0.8776702526029707, 'colsample_bytree': 0.9499874073946727, 'gamma': 2.0205809833749697, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:41,372] Trial 197 finished with value: 0.6968167573808345 and parameters: {'n_estimators': 183, 'max_depth': 10, 'learning_rate': 0.2985260142643783, 'subsample': 0.8784574397960461, 'colsample_bytree': 0.9445236831137223, 'gamma': 2.0867169860048604, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:41,961] Trial 198 finished with value: 0.6902328330309528 and parameters: {'n_estimators': 190, 'max_depth': 10, 'learning_rate': 0.2932979172210548, 'subsample': 0.8706248244421033, 'colsample_bytree': 0.957538857757357, 'gamma': 2.0134470617324034, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:42,733] Trial 199 finished with value: 0.7109619863419255 and parameters: {'n_estimators': 184, 'max_depth': 10, 'learning_rate': 0.2860082336644083, 'subsample': 0.8855411012397283, 'colsample_bytree': 0.9714591543011356, 'gamma': 1.7635731757846669, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:43,305] Trial 200 finished with value: 0.7034778665089224 and parameters: {'n_estimators': 186, 'max_depth': 10, 'learning_rate': 0.2999783151460915, 'subsample': 0.8607676063945583, 'colsample_bytree': 0.9678628199403243, 'gamma': 1.9623184861046457, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:44,225] Trial 201 finished with value: 0.6740425531914893 and parameters: {'n_estimators': 178, 'max_depth': 10, 'learning_rate': 0.28548019601951785, 'subsample': 0.8903233602052085, 'colsample_bytree': 0.9423911800222078, 'gamma': 1.872761179189339, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:44,908] Trial 202 finished with value: 0.7047474747474747 and parameters: {'n_estimators': 174, 'max_depth': 10, 'learning_rate': 0.27004936364031046, 'subsample': 0.8758153361841738, 'colsample_bytree': 0.9395935806932036, 'gamma': 2.1429398201274767, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:45,503] Trial 203 finished with value: 0.702202255109232 and parameters: {'n_estimators': 180, 'max_depth': 10, 'learning_rate': 0.2828869595175105, 'subsample': 0.8851280439178111, 'colsample_bytree': 0.9632576394386207, 'gamma': 1.922060393305636, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:46,096] Trial 204 finished with value: 0.698455085507418 and parameters: {'n_estimators': 195, 'max_depth': 10, 'learning_rate': 0.26598005892309406, 'subsample': 0.9009325342889192, 'colsample_bytree': 0.9522091860999687, 'gamma': 1.8187569819175389, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:46,646] Trial 205 finished with value: 0.6846790890269151 and parameters: {'n_estimators': 170, 'max_depth': 10, 'learning_rate': 0.2795460225914887, 'subsample': 0.8902453510488276, 'colsample_bytree': 0.9854247042629389, 'gamma': 2.0192536082924524, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:47,229] Trial 206 finished with value: 0.6976342944536909 and parameters: {'n_estimators': 190, 'max_depth': 10, 'learning_rate': 0.29189944243961524, 'subsample': 0.8776713807564633, 'colsample_bytree': 0.925419782480047, 'gamma': 2.199220409757862, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:47,796] Trial 207 finished with value: 0.6954890077243018 and parameters: {'n_estimators': 183, 'max_depth': 10, 'learning_rate': 0.27131777406789875, 'subsample': 0.8368528276530773, 'colsample_bytree': 0.9808388704148642, 'gamma': 1.6849610486228042, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:48,381] Trial 208 finished with value: 0.6940402247855664 and parameters: {'n_estimators': 175, 'max_depth': 10, 'learning_rate': 0.2619471228864446, 'subsample': 0.8977079142629353, 'colsample_bytree': 0.9570938826093571, 'gamma': 1.9225371808615401, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:48,982] Trial 209 finished with value: 0.68808800115791 and parameters: {'n_estimators': 187, 'max_depth': 10, 'learning_rate': 0.28055722627879837, 'subsample': 0.8662063264666285, 'colsample_bytree': 0.9654340002491882, 'gamma': 2.110901686969263, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:49,664] Trial 210 finished with value: 0.7011485063399957 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.08706387197930558, 'subsample': 0.8836591722014852, 'colsample_bytree': 0.9984999333022146, 'gamma': 1.812941128770501, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:50,212] Trial 211 finished with value: 0.699511678357324 and parameters: {'n_estimators': 166, 'max_depth': 10, 'learning_rate': 0.24478756028656537, 'subsample': 0.9047824268032688, 'colsample_bytree': 0.9474727916207588, 'gamma': 2.2837739559029293, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:50,751] Trial 212 finished with value: 0.6910417309075958 and parameters: {'n_estimators': 176, 'max_depth': 10, 'learning_rate': 0.25474031330967495, 'subsample': 0.8946453152517602, 'colsample_bytree': 0.9892864430668808, 'gamma': 3.6388994732583173, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:51,390] Trial 213 finished with value: 0.7048287668163444 and parameters: {'n_estimators': 141, 'max_depth': 10, 'learning_rate': 0.24097640707364495, 'subsample': 0.9078354414355574, 'colsample_bytree': 0.66097777311205, 'gamma': 2.05914021489421, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:52,117] Trial 214 finished with value: 0.6884195997239475 and parameters: {'n_estimators': 162, 'max_depth': 10, 'learning_rate': 0.2312836143208024, 'subsample': 0.7822671694396415, 'colsample_bytree': 0.9784145092091627, 'gamma': 1.926051220278281, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:52,970] Trial 215 finished with value: 0.6978099683233819 and parameters: {'n_estimators': 172, 'max_depth': 10, 'learning_rate': 0.24791694295641079, 'subsample': 0.8979319459688236, 'colsample_bytree': 0.6576342255871339, 'gamma': 1.6377099477283161, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:53,601] Trial 216 finished with value: 0.6767833749147347 and parameters: {'n_estimators': 183, 'max_depth': 10, 'learning_rate': 0.26737704689476177, 'subsample': 0.8905968642708556, 'colsample_bytree': 0.9712803172163652, 'gamma': 3.5353371238020097, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:54,265] Trial 217 finished with value: 0.6928121203349167 and parameters: {'n_estimators': 192, 'max_depth': 9, 'learning_rate': 0.2740775802819549, 'subsample': 0.8743946012620604, 'colsample_bytree': 0.9380229120117454, 'gamma': 1.768793526800092, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:54,882] Trial 218 finished with value: 0.6522946793159559 and parameters: {'n_estimators': 178, 'max_depth': 10, 'learning_rate': 0.23855284141340038, 'subsample': 0.911089792808043, 'colsample_bytree': 0.6775897185358634, 'gamma': 2.1825932029500112, 'min_child_weight': 5}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:55,471] Trial 219 finished with value: 0.6891152038423083 and parameters: {'n_estimators': 199, 'max_depth': 4, 'learning_rate': 0.2527432712241061, 'subsample': 0.9016046737630575, 'colsample_bytree': 0.6382699901088948, 'gamma': 3.8483899294830852, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:56,173] Trial 220 finished with value: 0.657156009239964 and parameters: {'n_estimators': 252, 'max_depth': 9, 'learning_rate': 0.2636390256100979, 'subsample': 0.6793824936087007, 'colsample_bytree': 0.6693995745808481, 'gamma': 2.0119024670115775, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:56,706] Trial 221 finished with value: 0.652536231884058 and parameters: {'n_estimators': 172, 'max_depth': 9, 'learning_rate': 0.2574644992242952, 'subsample': 0.9160298182150315, 'colsample_bytree': 0.988804549415534, 'gamma': 1.5949807780257965, 'min_child_weight': 9}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:57,467] Trial 222 finished with value: 0.6821502514049097 and parameters: {'n_estimators': 281, 'max_depth': 9, 'learning_rate': 0.25953691606354884, 'subsample': 0.9193617502728435, 'colsample_bytree': 0.9911731232700143, 'gamma': 1.5000315865647358, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:58,014] Trial 223 finished with value: 0.6903564307005565 and parameters: {'n_estimators': 167, 'max_depth': 9, 'learning_rate': 0.24603265464969562, 'subsample': 0.9051676409873473, 'colsample_bytree': 0.7581764811141221, 'gamma': 1.5663285433243228, 'min_child_weight': 2}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:58,571] Trial 224 finished with value: 0.70617439703154 and parameters: {'n_estimators': 187, 'max_depth': 9, 'learning_rate': 0.25043177437319986, 'subsample': 0.8850147061685756, 'colsample_bytree': 0.9767780864937375, 'gamma': 1.8711975928833269, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:59,153] Trial 225 finished with value: 0.6788405797101449 and parameters: {'n_estimators': 154, 'max_depth': 9, 'learning_rate': 0.26960458654750935, 'subsample': 0.8955638291447348, 'colsample_bytree': 0.9986388336111951, 'gamma': 1.7464460687946413, 'min_child_weight': 2}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:37:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:37:59,902] Trial 226 finished with value: 0.7137549831082028 and parameters: {'n_estimators': 180, 'max_depth': 10, 'learning_rate': 0.2570202121737473, 'subsample': 0.9301569593379635, 'colsample_bytree': 0.9843624499466327, 'gamma': 2.3575305788011414, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:00,512] Trial 227 finished with value: 0.6950828157349896 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.2357690102432083, 'subsample': 0.9345033250175081, 'colsample_bytree': 0.9650413790522363, 'gamma': 2.360131471814692, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:01,079] Trial 228 finished with value: 0.6954084769612721 and parameters: {'n_estimators': 175, 'max_depth': 10, 'learning_rate': 0.26357892765799584, 'subsample': 0.8814889046251159, 'colsample_bytree': 0.9815086292963954, 'gamma': 2.521828377577299, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:01,640] Trial 229 finished with value: 0.702998021903797 and parameters: {'n_estimators': 184, 'max_depth': 10, 'learning_rate': 0.25349393962143923, 'subsample': 0.8919135502971135, 'colsample_bytree': 0.6483415654013668, 'gamma': 2.3298736622074476, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:02,194] Trial 230 finished with value: 0.7175427617855652 and parameters: {'n_estimators': 177, 'max_depth': 10, 'learning_rate': 0.2837444148836471, 'subsample': 0.9084320884992056, 'colsample_bytree': 0.8684280879780439, 'gamma': 2.444784745178383, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:02,942] Trial 231 finished with value: 0.7099491114275168 and parameters: {'n_estimators': 178, 'max_depth': 10, 'learning_rate': 0.1380332412778982, 'subsample': 0.9109774107612675, 'colsample_bytree': 0.925680413495589, 'gamma': 2.4439597292338586, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:03,520] Trial 232 finished with value: 0.7134350890581894 and parameters: {'n_estimators': 169, 'max_depth': 10, 'learning_rate': 0.28285866771726975, 'subsample': 0.9019110661010816, 'colsample_bytree': 0.8671128193611185, 'gamma': 2.571877520588227, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:04,148] Trial 233 finished with value: 0.7041093637578374 and parameters: {'n_estimators': 170, 'max_depth': 10, 'learning_rate': 0.28768357071285, 'subsample': 0.9014466262101646, 'colsample_bytree': 0.8464015432564734, 'gamma': 2.8217137936302747, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:04,761] Trial 234 finished with value: 0.7163561076604554 and parameters: {'n_estimators': 179, 'max_depth': 10, 'learning_rate': 0.2840515219707988, 'subsample': 0.9272032043097732, 'colsample_bytree': 0.953905209339535, 'gamma': 2.6389475905251087, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:05,379] Trial 235 finished with value: 0.7118622220309934 and parameters: {'n_estimators': 180, 'max_depth': 10, 'learning_rate': 0.28372661100249674, 'subsample': 0.9275071628028634, 'colsample_bytree': 0.8365376031400995, 'gamma': 2.564788916251932, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:05,981] Trial 236 finished with value: 0.6664525455414981 and parameters: {'n_estimators': 188, 'max_depth': 10, 'learning_rate': 0.292095995310107, 'subsample': 0.6015539673952618, 'colsample_bytree': 0.9534607095909481, 'gamma': 2.5944144998042153, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:06,813] Trial 237 finished with value: 0.6706082749487865 and parameters: {'n_estimators': 185, 'max_depth': 10, 'learning_rate': 0.2810320451790872, 'subsample': 0.8897500214791051, 'colsample_bytree': 0.8604466299306965, 'gamma': 2.703695248561768, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:07,373] Trial 238 finished with value: 0.7048714742814122 and parameters: {'n_estimators': 179, 'max_depth': 10, 'learning_rate': 0.2783783016607108, 'subsample': 0.9284194040478841, 'colsample_bytree': 0.8852609635483021, 'gamma': 2.4688075966534053, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:07,928] Trial 239 finished with value: 0.6970285650211644 and parameters: {'n_estimators': 173, 'max_depth': 10, 'learning_rate': 0.2895948361185594, 'subsample': 0.9000039812132585, 'colsample_bytree': 0.904198372744281, 'gamma': 2.6283591585171404, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:08,541] Trial 240 finished with value: 0.697238031039851 and parameters: {'n_estimators': 183, 'max_depth': 10, 'learning_rate': 0.2707208510251748, 'subsample': 0.9440104682290406, 'colsample_bytree': 0.949386210724509, 'gamma': 2.3922844966116523, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:09,263] Trial 241 finished with value: 0.7259800422311448 and parameters: {'n_estimators': 175, 'max_depth': 10, 'learning_rate': 0.27498494093705306, 'subsample': 0.9099030823352873, 'colsample_bytree': 0.8120822275382115, 'gamma': 2.2846477110736307, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:09,986] Trial 242 finished with value: 0.7097671119907637 and parameters: {'n_estimators': 177, 'max_depth': 10, 'learning_rate': 0.27324694479867023, 'subsample': 0.9153854209647736, 'colsample_bytree': 0.8700026731755096, 'gamma': 2.2669730849573377, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:10,696] Trial 243 finished with value: 0.7143980227810014 and parameters: {'n_estimators': 168, 'max_depth': 10, 'learning_rate': 0.2843032967139667, 'subsample': 0.882476842836454, 'colsample_bytree': 0.8119940712843986, 'gamma': 2.766069329665924, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:11,279] Trial 244 finished with value: 0.6762187088274045 and parameters: {'n_estimators': 168, 'max_depth': 10, 'learning_rate': 0.28497691812658027, 'subsample': 0.8746852470927974, 'colsample_bytree': 0.807759029675575, 'gamma': 2.71031906716493, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:11,851] Trial 245 finished with value: 0.7044010677007072 and parameters: {'n_estimators': 188, 'max_depth': 10, 'learning_rate': 0.2832560968583665, 'subsample': 0.8959337892788943, 'colsample_bytree': 0.785996654557278, 'gamma': 2.7489141676524973, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:12,365] Trial 246 finished with value: 0.6535867462786982 and parameters: {'n_estimators': 163, 'max_depth': 10, 'learning_rate': 0.27421254443495835, 'subsample': 0.9051288162515475, 'colsample_bytree': 0.8178415052607557, 'gamma': 2.8394688741391807, 'min_child_weight': 6}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:12,976] Trial 247 finished with value: 0.6491952750092285 and parameters: {'n_estimators': 193, 'max_depth': 10, 'learning_rate': 0.289188192705348, 'subsample': 0.8831032978001166, 'colsample_bytree': 0.9130359181080238, 'gamma': 2.5455327205832448, 'min_child_weight': 4}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:13,502] Trial 248 finished with value: 0.7110923789805778 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.2796298034336314, 'subsample': 0.9214698544999927, 'colsample_bytree': 0.8118591620769711, 'gamma': 2.9207072338375784, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:14,224] Trial 249 finished with value: 0.6899967013029854 and parameters: {'n_estimators': 123, 'max_depth': 10, 'learning_rate': 0.27671774505595, 'subsample': 0.8944517974312395, 'colsample_bytree': 0.8519836136829182, 'gamma': 2.478417357964626, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:14,819] Trial 250 finished with value: 0.728238122126321 and parameters: {'n_estimators': 174, 'max_depth': 10, 'learning_rate': 0.298806112620404, 'subsample': 0.9080359143162459, 'colsample_bytree': 0.8758505203794866, 'gamma': 2.23553138029726, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:15,427] Trial 251 finished with value: 0.7275684505241548 and parameters: {'n_estimators': 178, 'max_depth': 10, 'learning_rate': 0.29722507928483677, 'subsample': 0.9114283718899322, 'colsample_bytree': 0.8923008792735151, 'gamma': 2.218507526371116, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:15,993] Trial 252 finished with value: 0.7038626903571609 and parameters: {'n_estimators': 176, 'max_depth': 10, 'learning_rate': 0.29505078175457816, 'subsample': 0.935017148958126, 'colsample_bytree': 0.8875469762558679, 'gamma': 2.2333839204923516, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:16,559] Trial 253 finished with value: 0.7079079987894576 and parameters: {'n_estimators': 185, 'max_depth': 9, 'learning_rate': 0.2913525500830042, 'subsample': 0.9171698139185462, 'colsample_bytree': 0.826265951315246, 'gamma': 2.1334095387658873, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:17,118] Trial 254 finished with value: 0.7228288474810214 and parameters: {'n_estimators': 180, 'max_depth': 9, 'learning_rate': 0.29656623771791507, 'subsample': 0.9089473767571797, 'colsample_bytree': 0.892861600918541, 'gamma': 2.351215062320775, 'min_child_weight': 1}. Best is trial 176 with value: 0.7296969696969697.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:17,681] Trial 255 finished with value: 0.7373807111497082 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.2922804682185496, 'subsample': 0.9230225753924792, 'colsample_bytree': 0.9014160829455783, 'gamma': 2.261870780607632, 'min_child_weight': 1}. Best is trial 255 with value: 0.7373807111497082.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:18,346] Trial 256 finished with value: 0.713465966657456 and parameters: {'n_estimators': 185, 'max_depth': 9, 'learning_rate': 0.2986283417091764, 'subsample': 0.9125469972222874, 'colsample_bytree': 0.8933064084371347, 'gamma': 2.293688128429994, 'min_child_weight': 1}. Best is trial 255 with value: 0.7373807111497082.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:18,964] Trial 257 finished with value: 0.6726346799757663 and parameters: {'n_estimators': 192, 'max_depth': 10, 'learning_rate': 0.2976700078242961, 'subsample': 0.8243815412272518, 'colsample_bytree': 0.8967131038073162, 'gamma': 2.209585505143963, 'min_child_weight': 1}. Best is trial 255 with value: 0.7373807111497082.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:19,531] Trial 258 finished with value: 0.7335658914728682 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.29992967788998104, 'subsample': 0.9096679626886078, 'colsample_bytree': 0.8826297966291876, 'gamma': 2.360665439875768, 'min_child_weight': 1}. Best is trial 255 with value: 0.7373807111497082.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:20,135] Trial 259 finished with value: 0.7078289300216211 and parameters: {'n_estimators': 177, 'max_depth': 10, 'learning_rate': 0.2996415949316504, 'subsample': 0.9134464614652282, 'colsample_bytree': 0.8799591387090049, 'gamma': 2.244061216878798, 'min_child_weight': 1}. Best is trial 255 with value: 0.7373807111497082.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:20,738] Trial 260 finished with value: 0.7003913617164699 and parameters: {'n_estimators': 183, 'max_depth': 10, 'learning_rate': 0.2942971781156234, 'subsample': 0.9064632801968932, 'colsample_bytree': 0.9103829069457464, 'gamma': 2.3745798431629637, 'min_child_weight': 1}. Best is trial 255 with value: 0.7373807111497082.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:21,307] Trial 261 finished with value: 0.6974315308496623 and parameters: {'n_estimators': 178, 'max_depth': 10, 'learning_rate': 0.2939699384142546, 'subsample': 0.9198992865285192, 'colsample_bytree': 0.8716075151064469, 'gamma': 2.1097454513101965, 'min_child_weight': 1}. Best is trial 255 with value: 0.7373807111497082.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:21,872] Trial 262 finished with value: 0.7323236714975845 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.2907665825083558, 'subsample': 0.9092647756044804, 'colsample_bytree': 0.9037292222607177, 'gamma': 2.158345106034691, 'min_child_weight': 1}. Best is trial 255 with value: 0.7373807111497082.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:22,437] Trial 263 finished with value: 0.7393629929221436 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.29787608316033587, 'subsample': 0.9080918418000333, 'colsample_bytree': 0.9053139751916761, 'gamma': 2.1689115186149914, 'min_child_weight': 1}. Best is trial 263 with value: 0.7393629929221436.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:23,301] Trial 264 finished with value: 0.7228415888767415 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.2999731977770656, 'subsample': 0.9245912415282553, 'colsample_bytree': 0.9038136994313672, 'gamma': 2.1446537312137206, 'min_child_weight': 1}. Best is trial 263 with value: 0.7393629929221436.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:23,871] Trial 265 finished with value: 0.7057265467451803 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.2970851883768844, 'subsample': 0.918186550648662, 'colsample_bytree': 0.9171140453420602, 'gamma': 2.1372975947758444, 'min_child_weight': 1}. Best is trial 263 with value: 0.7393629929221436.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:24,440] Trial 266 finished with value: 0.7153876586095431 and parameters: {'n_estimators': 189, 'max_depth': 10, 'learning_rate': 0.2917227510036308, 'subsample': 0.9235068858576279, 'colsample_bytree': 0.901729449252813, 'gamma': 2.175221415289587, 'min_child_weight': 1}. Best is trial 263 with value: 0.7393629929221436.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:25,019] Trial 267 finished with value: 0.7217687074829933 and parameters: {'n_estimators': 175, 'max_depth': 10, 'learning_rate': 0.29921908161334293, 'subsample': 0.9110141399230456, 'colsample_bytree': 0.8959887950466167, 'gamma': 2.054303918247542, 'min_child_weight': 1}. Best is trial 263 with value: 0.7393629929221436.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:25,642] Trial 268 finished with value: 0.6970999618416032 and parameters: {'n_estimators': 173, 'max_depth': 10, 'learning_rate': 0.2998912550893044, 'subsample': 0.9113923747753963, 'colsample_bytree': 0.8902261996289021, 'gamma': 2.084884680594557, 'min_child_weight': 1}. Best is trial 263 with value: 0.7393629929221436.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:26,258] Trial 269 finished with value: 0.7174992291088499 and parameters: {'n_estimators': 184, 'max_depth': 10, 'learning_rate': 0.2944978914713143, 'subsample': 0.9070321634541285, 'colsample_bytree': 0.9015171016100958, 'gamma': 2.061885733062367, 'min_child_weight': 1}. Best is trial 263 with value: 0.7393629929221436.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:26,830] Trial 270 finished with value: 0.7467670188642833 and parameters: {'n_estimators': 184, 'max_depth': 10, 'learning_rate': 0.2949424037202682, 'subsample': 0.9085237438425097, 'colsample_bytree': 0.899500021587377, 'gamma': 2.265477208921092, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:27,415] Trial 271 finished with value: 0.7024934277047523 and parameters: {'n_estimators': 184, 'max_depth': 10, 'learning_rate': 0.29999301332946443, 'subsample': 0.9058922431983423, 'colsample_bytree': 0.8982333116223765, 'gamma': 2.2981115014732145, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:27,983] Trial 272 finished with value: 0.7298614180850206 and parameters: {'n_estimators': 187, 'max_depth': 10, 'learning_rate': 0.2938271548417532, 'subsample': 0.9110866601238506, 'colsample_bytree': 0.8995706588351661, 'gamma': 2.1619988540796946, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:28,545] Trial 273 finished with value: 0.7093276971035659 and parameters: {'n_estimators': 188, 'max_depth': 10, 'learning_rate': 0.2917392350892224, 'subsample': 0.917623468280211, 'colsample_bytree': 0.9192026896228417, 'gamma': 2.227748766649743, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:29,444] Trial 274 finished with value: 0.7109603415834419 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.2909928454030253, 'subsample': 0.9122155346253911, 'colsample_bytree': 0.8828388198217874, 'gamma': 2.2212884694646036, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:30,024] Trial 275 finished with value: 0.699768115942029 and parameters: {'n_estimators': 190, 'max_depth': 10, 'learning_rate': 0.2997440234224346, 'subsample': 0.9258483341911352, 'colsample_bytree': 0.8938693385805692, 'gamma': 2.3412541707535097, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:30,673] Trial 276 finished with value: 0.7110527770102238 and parameters: {'n_estimators': 177, 'max_depth': 10, 'learning_rate': 0.2893258021661657, 'subsample': 0.911299083866845, 'colsample_bytree': 0.9048571186972051, 'gamma': 2.119026795059659, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:31,572] Trial 277 finished with value: 0.7173296330558124 and parameters: {'n_estimators': 196, 'max_depth': 10, 'learning_rate': 0.2959900692817602, 'subsample': 0.920594565046854, 'colsample_bytree': 0.878577945594018, 'gamma': 2.1986393941160896, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:32,162] Trial 278 finished with value: 0.7190301081072976 and parameters: {'n_estimators': 186, 'max_depth': 10, 'learning_rate': 0.2882105638436399, 'subsample': 0.9023244918133398, 'colsample_bytree': 0.907454791215151, 'gamma': 1.995116447380226, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:32,771] Trial 279 finished with value: 0.7050146235715153 and parameters: {'n_estimators': 186, 'max_depth': 10, 'learning_rate': 0.29263930489731477, 'subsample': 0.8972313129030962, 'colsample_bytree': 0.9098953948781392, 'gamma': 1.9691589013663324, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:33,370] Trial 280 finished with value: 0.6942409291807997 and parameters: {'n_estimators': 190, 'max_depth': 10, 'learning_rate': 0.28989195669672496, 'subsample': 0.9038058852299201, 'colsample_bytree': 0.8970466367336636, 'gamma': 1.9971235672706409, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:33,974] Trial 281 finished with value: 0.6950873551288704 and parameters: {'n_estimators': 182, 'max_depth': 10, 'learning_rate': 0.2996171603908196, 'subsample': 0.8935970114617628, 'colsample_bytree': 0.9035890176264287, 'gamma': 2.1128809813342273, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:34,484] Trial 282 finished with value: 0.6989561228017684 and parameters: {'n_estimators': 107, 'max_depth': 10, 'learning_rate': 0.295240562588548, 'subsample': 0.9025671047253394, 'colsample_bytree': 0.9194562123388075, 'gamma': 2.0856279308529015, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:35,073] Trial 283 finished with value: 0.7282675611101671 and parameters: {'n_estimators': 187, 'max_depth': 10, 'learning_rate': 0.2887905880841385, 'subsample': 0.9150520493081725, 'colsample_bytree': 0.8902266638237446, 'gamma': 2.3122839830635358, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:35,649] Trial 284 finished with value: 0.7354408287076206 and parameters: {'n_estimators': 192, 'max_depth': 10, 'learning_rate': 0.28743080525433407, 'subsample': 0.9137023787661757, 'colsample_bytree': 0.8875950191465916, 'gamma': 2.2915848448609464, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:36,240] Trial 285 finished with value: 0.7351834720937405 and parameters: {'n_estimators': 194, 'max_depth': 10, 'learning_rate': 0.28880035169839235, 'subsample': 0.9232905008062958, 'colsample_bytree': 0.8937943759403664, 'gamma': 2.315606116369638, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:36,840] Trial 286 finished with value: 0.7251156336725255 and parameters: {'n_estimators': 196, 'max_depth': 10, 'learning_rate': 0.2883250631716695, 'subsample': 0.9241881960748001, 'colsample_bytree': 0.8848035322083687, 'gamma': 2.346270459220081, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:37,443] Trial 287 finished with value: 0.7394927536231883 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.28970323684813937, 'subsample': 0.9282615148013695, 'colsample_bytree': 0.8892122270100155, 'gamma': 2.3242021470420107, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:38,043] Trial 288 finished with value: 0.6984621474517565 and parameters: {'n_estimators': 199, 'max_depth': 10, 'learning_rate': 0.28898614685643825, 'subsample': 0.9372289806188243, 'colsample_bytree': 0.8885777248884518, 'gamma': 2.3254905883008163, 'min_child_weight': 2}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:38,640] Trial 289 finished with value: 0.6803265575004706 and parameters: {'n_estimators': 204, 'max_depth': 10, 'learning_rate': 0.2869347644872802, 'subsample': 0.9392091864155386, 'colsample_bytree': 0.8913019106921596, 'gamma': 2.3049126950189684, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:39,243] Trial 290 finished with value: 0.7022727272727273 and parameters: {'n_estimators': 195, 'max_depth': 10, 'learning_rate': 0.29357049629162707, 'subsample': 0.928135415510653, 'colsample_bytree': 0.8790353462905667, 'gamma': 2.3716702261207074, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:39,848] Trial 291 finished with value: 0.7220544091827296 and parameters: {'n_estimators': 202, 'max_depth': 10, 'learning_rate': 0.29341879350147415, 'subsample': 0.9274687927306567, 'colsample_bytree': 0.8959929604605122, 'gamma': 2.2789502461017945, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:40,457] Trial 292 finished with value: 0.7033808853068991 and parameters: {'n_estimators': 208, 'max_depth': 10, 'learning_rate': 0.28850527281389066, 'subsample': 0.9328310465379609, 'colsample_bytree': 0.8845189095987592, 'gamma': 2.249466428025589, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:41,965] Trial 293 finished with value: 0.7024586288416076 and parameters: {'n_estimators': 201, 'max_depth': 10, 'learning_rate': 0.29399107218340076, 'subsample': 0.924716220465844, 'colsample_bytree': 0.8958813503204441, 'gamma': 2.402957869729606, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:42,587] Trial 294 finished with value: 0.690302213234468 and parameters: {'n_estimators': 203, 'max_depth': 10, 'learning_rate': 0.288075358323895, 'subsample': 0.9516706529283215, 'colsample_bytree': 0.8738054781397709, 'gamma': 2.211721435419307, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:43,321] Trial 295 finished with value: 0.7305799933294317 and parameters: {'n_estimators': 199, 'max_depth': 10, 'learning_rate': 0.29455117520872215, 'subsample': 0.9230257908282111, 'colsample_bytree': 0.8892525055716143, 'gamma': 2.3309517607142776, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:43,920] Trial 296 finished with value: 0.6915873015873016 and parameters: {'n_estimators': 197, 'max_depth': 10, 'learning_rate': 0.29270365192751757, 'subsample': 0.9319726583624286, 'colsample_bytree': 0.8865510938095172, 'gamma': 2.299718882504189, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:44,505] Trial 297 finished with value: 0.7252534627171868 and parameters: {'n_estimators': 195, 'max_depth': 10, 'learning_rate': 0.29552966777559975, 'subsample': 0.9246099263900542, 'colsample_bytree': 0.8997842141212613, 'gamma': 2.1715195130739273, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:45,080] Trial 298 finished with value: 0.6559456731982171 and parameters: {'n_estimators': 199, 'max_depth': 10, 'learning_rate': 0.2953483320707585, 'subsample': 0.9394889066283336, 'colsample_bytree': 0.8982475181574173, 'gamma': 2.205177379788881, 'min_child_weight': 7}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:45,664] Trial 299 finished with value: 0.7079011203618049 and parameters: {'n_estimators': 195, 'max_depth': 10, 'learning_rate': 0.299521111910655, 'subsample': 0.9222405616224522, 'colsample_bytree': 0.8920053522719792, 'gamma': 2.419131832234662, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:46,311] Trial 300 finished with value: 0.725377107364685 and parameters: {'n_estimators': 193, 'max_depth': 10, 'learning_rate': 0.2999906392278851, 'subsample': 0.9276160003614561, 'colsample_bytree': 0.8784022796276978, 'gamma': 2.2831354055277298, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:46,920] Trial 301 finished with value: 0.7114624505928854 and parameters: {'n_estimators': 202, 'max_depth': 10, 'learning_rate': 0.2864078380396965, 'subsample': 0.9298146954740819, 'colsample_bytree': 0.8626251205247698, 'gamma': 2.3064673046814796, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:47,529] Trial 302 finished with value: 0.7072463768115942 and parameters: {'n_estimators': 194, 'max_depth': 10, 'learning_rate': 0.29444793637235983, 'subsample': 0.942094563111534, 'colsample_bytree': 0.877832627068196, 'gamma': 4.73266331879361, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:48,126] Trial 303 finished with value: 0.7276666666666667 and parameters: {'n_estimators': 197, 'max_depth': 10, 'learning_rate': 0.2999164926859964, 'subsample': 0.9224937783096974, 'colsample_bytree': 0.8818376930414529, 'gamma': 2.174420624254883, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:48,705] Trial 304 finished with value: 0.7079011203618049 and parameters: {'n_estimators': 198, 'max_depth': 10, 'learning_rate': 0.28859614324516103, 'subsample': 0.9254248849961576, 'colsample_bytree': 0.8818460577649723, 'gamma': 2.1803527451728666, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:49,621] Trial 305 finished with value: 0.6918617000987359 and parameters: {'n_estimators': 205, 'max_depth': 4, 'learning_rate': 0.29992349764257875, 'subsample': 0.9462542344301553, 'colsample_bytree': 0.9038745683451603, 'gamma': 2.2925228418797237, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:50,206] Trial 306 finished with value: 0.6823893064901299 and parameters: {'n_estimators': 193, 'max_depth': 10, 'learning_rate': 0.2936728813208006, 'subsample': 0.9346199491029709, 'colsample_bytree': 0.8875884141952367, 'gamma': 2.4500576235185725, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:50,800] Trial 307 finished with value: 0.7183505265420159 and parameters: {'n_estimators': 197, 'max_depth': 10, 'learning_rate': 0.2827171876209639, 'subsample': 0.9213483627799458, 'colsample_bytree': 0.8773634480044028, 'gamma': 2.1769136504412807, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:51,448] Trial 308 finished with value: 0.7220072117653722 and parameters: {'n_estimators': 201, 'max_depth': 10, 'learning_rate': 0.2882187596168726, 'subsample': 0.9203490770080262, 'colsample_bytree': 0.8917285993586758, 'gamma': 2.3780547689987013, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:52,074] Trial 309 finished with value: 0.6976635350465137 and parameters: {'n_estimators': 192, 'max_depth': 10, 'learning_rate': 0.29400841310281484, 'subsample': 0.930019980110003, 'colsample_bytree': 0.8569440318726074, 'gamma': 2.2863291023827137, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:52,699] Trial 310 finished with value: 0.703677150786309 and parameters: {'n_estimators': 197, 'max_depth': 10, 'learning_rate': 0.28077432320260626, 'subsample': 0.9193218703037063, 'colsample_bytree': 0.901959026105187, 'gamma': 2.2338208118700145, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:53,277] Trial 311 finished with value: 0.7258325624421832 and parameters: {'n_estimators': 192, 'max_depth': 10, 'learning_rate': 0.28870652830061355, 'subsample': 0.9269227576828655, 'colsample_bytree': 0.8740806451126788, 'gamma': 2.434325567507145, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:53,839] Trial 312 finished with value: 0.717706583095773 and parameters: {'n_estimators': 192, 'max_depth': 6, 'learning_rate': 0.2860068786607452, 'subsample': 0.9378355875734948, 'colsample_bytree': 0.8733128416253533, 'gamma': 2.4479029810239528, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:54,405] Trial 313 finished with value: 0.6984189723320158 and parameters: {'n_estimators': 192, 'max_depth': 10, 'learning_rate': 0.2996275176086421, 'subsample': 0.916814075899388, 'colsample_bytree': 0.8835825215613085, 'gamma': 4.465591119216553, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:54,978] Trial 314 finished with value: 0.6675873682069495 and parameters: {'n_estimators': 195, 'max_depth': 10, 'learning_rate': 0.2890927660617528, 'subsample': 0.9587294121002219, 'colsample_bytree': 0.8689924614334763, 'gamma': 2.461233339003192, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:55,566] Trial 315 finished with value: 0.7209873707028581 and parameters: {'n_estimators': 191, 'max_depth': 10, 'learning_rate': 0.27933418894462125, 'subsample': 0.9246693235698306, 'colsample_bytree': 0.9102208154692089, 'gamma': 2.1529190381784367, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:56,176] Trial 316 finished with value: 0.718926919518964 and parameters: {'n_estimators': 190, 'max_depth': 10, 'learning_rate': 0.29993743790438454, 'subsample': 0.917544269423869, 'colsample_bytree': 0.8818565656280352, 'gamma': 2.3494900934059713, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:56,791] Trial 317 finished with value: 0.6975420729220121 and parameters: {'n_estimators': 196, 'max_depth': 10, 'learning_rate': 0.28483875908030154, 'subsample': 0.9474435763586507, 'colsample_bytree': 0.8881458290057348, 'gamma': 2.1412602595059242, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:57,420] Trial 318 finished with value: 0.6851657659111074 and parameters: {'n_estimators': 207, 'max_depth': 10, 'learning_rate': 0.29178001277164595, 'subsample': 0.9340139946143903, 'colsample_bytree': 0.9019755794880663, 'gamma': 2.500239140879306, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:57,978] Trial 319 finished with value: 0.72677426438296 and parameters: {'n_estimators': 189, 'max_depth': 10, 'learning_rate': 0.2940732262953548, 'subsample': 0.9172907755826794, 'colsample_bytree': 0.8768325214503783, 'gamma': 2.389068505136459, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:58,816] Trial 320 finished with value: 0.7010408432147562 and parameters: {'n_estimators': 190, 'max_depth': 10, 'learning_rate': 0.2858870519101602, 'subsample': 0.9291517826228524, 'colsample_bytree': 0.8622818381340074, 'gamma': 2.232010273375467, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:38:59,447] Trial 321 finished with value: 0.7458757323465927 and parameters: {'n_estimators': 194, 'max_depth': 10, 'learning_rate': 0.29208517332985867, 'subsample': 0.9178190860861803, 'colsample_bytree': 0.8773493608419559, 'gamma': 2.380955004746045, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:38:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:00,037] Trial 322 finished with value: 0.689731729879741 and parameters: {'n_estimators': 199, 'max_depth': 10, 'learning_rate': 0.279830212986902, 'subsample': 0.9152333888359798, 'colsample_bytree': 0.8696898627827633, 'gamma': 2.5164333707071824, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:00,706] Trial 323 finished with value: 0.6961075375226786 and parameters: {'n_estimators': 194, 'max_depth': 10, 'learning_rate': 0.2900326330838733, 'subsample': 0.9193592075460952, 'colsample_bytree': 0.8777480461241282, 'gamma': 2.415388062921135, 'min_child_weight': 4}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:01,506] Trial 324 finished with value: 0.7240034892099974 and parameters: {'n_estimators': 198, 'max_depth': 10, 'learning_rate': 0.2837169722012642, 'subsample': 0.9182831056293058, 'colsample_bytree': 0.8743136302267945, 'gamma': 2.3468454307578486, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:02,211] Trial 325 finished with value: 0.6933135704874835 and parameters: {'n_estimators': 193, 'max_depth': 3, 'learning_rate': 0.2925214356572791, 'subsample': 0.9341854312725034, 'colsample_bytree': 0.881690110480638, 'gamma': 2.296079089309465, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:02,860] Trial 326 finished with value: 0.6908463688812227 and parameters: {'n_estimators': 188, 'max_depth': 10, 'learning_rate': 0.28943131700580355, 'subsample': 0.7311512205025154, 'colsample_bytree': 0.8624314967769569, 'gamma': 2.5029874581498808, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:03,542] Trial 327 finished with value: 0.7057971014492753 and parameters: {'n_estimators': 202, 'max_depth': 10, 'learning_rate': 0.27788895681848347, 'subsample': 0.9144259065290463, 'colsample_bytree': 0.8878610174164966, 'gamma': 2.3683431210825776, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:04,424] Trial 328 finished with value: 0.7274569402228976 and parameters: {'n_estimators': 241, 'max_depth': 10, 'learning_rate': 0.29406185649835714, 'subsample': 0.9259045318957854, 'colsample_bytree': 0.9289086508914275, 'gamma': 2.240918074819973, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:05,012] Trial 329 finished with value: 0.6708707345425531 and parameters: {'n_estimators': 191, 'max_depth': 10, 'learning_rate': 0.2936361709231173, 'subsample': 0.9420900539507332, 'colsample_bytree': 0.9204194012361828, 'gamma': 2.238275837163413, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:05,690] Trial 330 finished with value: 0.7309977324263038 and parameters: {'n_estimators': 273, 'max_depth': 10, 'learning_rate': 0.2938727390903144, 'subsample': 0.9306189485168214, 'colsample_bytree': 0.9128640940636358, 'gamma': 2.1256257930573934, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:06,333] Trial 331 finished with value: 0.6897682061927002 and parameters: {'n_estimators': 239, 'max_depth': 10, 'learning_rate': 0.29462330471117987, 'subsample': 0.9319348330188946, 'colsample_bytree': 0.9298260433221506, 'gamma': 2.1053969252240354, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:07,122] Trial 332 finished with value: 0.7006757581799403 and parameters: {'n_estimators': 189, 'max_depth': 10, 'learning_rate': 0.11790173716833023, 'subsample': 0.9402977861901595, 'colsample_bytree': 0.9129393862496344, 'gamma': 2.169378110254991, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:07,822] Trial 333 finished with value: 0.7084934277047523 and parameters: {'n_estimators': 187, 'max_depth': 10, 'learning_rate': 0.294920765759776, 'subsample': 0.9735712286447564, 'colsample_bytree': 0.9157410714840057, 'gamma': 2.230004653640239, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:08,541] Trial 334 finished with value: 0.6785683364254793 and parameters: {'n_estimators': 291, 'max_depth': 10, 'learning_rate': 0.29997894452862806, 'subsample': 0.9524431557437121, 'colsample_bytree': 0.8981005031629294, 'gamma': 2.081001627314287, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:09,226] Trial 335 finished with value: 0.7114093463472345 and parameters: {'n_estimators': 274, 'max_depth': 10, 'learning_rate': 0.2852253695250094, 'subsample': 0.9289350367424656, 'colsample_bytree': 0.9080436594950513, 'gamma': 2.4291567338737865, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:09,921] Trial 336 finished with value: 0.7288467468393464 and parameters: {'n_estimators': 258, 'max_depth': 10, 'learning_rate': 0.29348735443540064, 'subsample': 0.9238190228927832, 'colsample_bytree': 0.9258826860517259, 'gamma': 2.2607479084849977, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:10,677] Trial 337 finished with value: 0.6752630654369784 and parameters: {'n_estimators': 262, 'max_depth': 10, 'learning_rate': 0.2888832131449386, 'subsample': 0.7962713572077058, 'colsample_bytree': 0.933457599887755, 'gamma': 2.2704745453374366, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:11,431] Trial 338 finished with value: 0.6869565217391305 and parameters: {'n_estimators': 270, 'max_depth': 10, 'learning_rate': 0.28315203034881187, 'subsample': 0.9135426306896327, 'colsample_bytree': 0.9165534251269427, 'gamma': 2.5234848107713255, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:12,559] Trial 339 finished with value: 0.637488109588017 and parameters: {'n_estimators': 248, 'max_depth': 10, 'learning_rate': 0.2915211656976963, 'subsample': 0.9358847631343293, 'colsample_bytree': 0.9228863965581731, 'gamma': 2.3772437128049777, 'min_child_weight': 8}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:13,281] Trial 340 finished with value: 0.6714562569213731 and parameters: {'n_estimators': 254, 'max_depth': 10, 'learning_rate': 0.2944562502016422, 'subsample': 0.6371652181368528, 'colsample_bytree': 0.8746878100163714, 'gamma': 2.0613666726713458, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:14,039] Trial 341 finished with value: 0.7203825488931871 and parameters: {'n_estimators': 277, 'max_depth': 10, 'learning_rate': 0.10843055919051087, 'subsample': 0.9216954050002241, 'colsample_bytree': 0.8537077429367458, 'gamma': 2.27016268481891, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:14,800] Trial 342 finished with value: 0.7188563899868248 and parameters: {'n_estimators': 272, 'max_depth': 10, 'learning_rate': 0.2865567011920494, 'subsample': 0.9136670098151348, 'colsample_bytree': 0.9326875074493731, 'gamma': 2.421977819243049, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:15,463] Trial 343 finished with value: 0.6863963249822442 and parameters: {'n_estimators': 256, 'max_depth': 10, 'learning_rate': 0.279742883600113, 'subsample': 0.9473472265230838, 'colsample_bytree': 0.8916280723016657, 'gamma': 2.1904678228155827, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:16,158] Trial 344 finished with value: 0.6928228738303832 and parameters: {'n_estimators': 265, 'max_depth': 10, 'learning_rate': 0.2998565126144002, 'subsample': 0.7669746484174775, 'colsample_bytree': 0.7462194873226783, 'gamma': 2.326758666664674, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:16,894] Trial 345 finished with value: 0.7058016408431561 and parameters: {'n_estimators': 286, 'max_depth': 10, 'learning_rate': 0.290576444264343, 'subsample': 0.9300087906453088, 'colsample_bytree': 0.8671829109126041, 'gamma': 2.102286573734, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:17,487] Trial 346 finished with value: 0.7093432007400555 and parameters: {'n_estimators': 185, 'max_depth': 10, 'learning_rate': 0.2947291950831429, 'subsample': 0.923841641468111, 'colsample_bytree': 0.9092911651276384, 'gamma': 2.2543829261507704, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:18,450] Trial 347 finished with value: 0.7110297217869571 and parameters: {'n_estimators': 258, 'max_depth': 10, 'learning_rate': 0.285059535358681, 'subsample': 0.9146022139595114, 'colsample_bytree': 0.9279517674565423, 'gamma': 2.481932336681099, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:19,154] Trial 348 finished with value: 0.7199578579504574 and parameters: {'n_estimators': 280, 'max_depth': 10, 'learning_rate': 0.2905512742951523, 'subsample': 0.9218985114814371, 'colsample_bytree': 0.8917670324871987, 'gamma': 2.3709885866850646, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:19,733] Trial 349 finished with value: 0.7063452779985091 and parameters: {'n_estimators': 189, 'max_depth': 10, 'learning_rate': 0.2764501079798537, 'subsample': 0.9347878513469552, 'colsample_bytree': 0.8806494222360945, 'gamma': 2.5631168794736463, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:20,432] Trial 350 finished with value: 0.7085106382978724 and parameters: {'n_estimators': 268, 'max_depth': 10, 'learning_rate': 0.29600060952159896, 'subsample': 0.9119499248672341, 'colsample_bytree': 0.8985951066077768, 'gamma': 2.1627584761533623, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:21,109] Trial 351 finished with value: 0.7066929965325631 and parameters: {'n_estimators': 264, 'max_depth': 10, 'learning_rate': 0.2997774482159351, 'subsample': 0.9424218934065742, 'colsample_bytree': 0.873803341589584, 'gamma': 2.0475277849205296, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:21,714] Trial 352 finished with value: 0.7177304964539007 and parameters: {'n_estimators': 187, 'max_depth': 10, 'learning_rate': 0.285667803988098, 'subsample': 0.9271301222888079, 'colsample_bytree': 0.9078574470950055, 'gamma': 2.2602934892390705, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:22,547] Trial 353 finished with value: 0.6964593029231715 and parameters: {'n_estimators': 191, 'max_depth': 10, 'learning_rate': 0.02854372609756964, 'subsample': 0.9169991796841064, 'colsample_bytree': 0.8864507729860895, 'gamma': 2.3938866875975795, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:23,301] Trial 354 finished with value: 0.6769536465749091 and parameters: {'n_estimators': 285, 'max_depth': 5, 'learning_rate': 0.2910142167261989, 'subsample': 0.74952826634515, 'colsample_bytree': 0.9246330462523501, 'gamma': 2.1524398252434516, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:23,891] Trial 355 finished with value: 0.707665162260907 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.28068806380545697, 'subsample': 0.9080460010207683, 'colsample_bytree': 0.837504470695317, 'gamma': 2.328816084596324, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:24,569] Trial 356 finished with value: 0.6546382978723404 and parameters: {'n_estimators': 258, 'max_depth': 10, 'learning_rate': 0.29484948031956176, 'subsample': 0.8045466871571274, 'colsample_bytree': 0.8010427859732068, 'gamma': 2.47124654484428, 'min_child_weight': 5}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:25,182] Trial 357 finished with value: 0.7166051822573561 and parameters: {'n_estimators': 211, 'max_depth': 10, 'learning_rate': 0.2886980823443755, 'subsample': 0.9257456172900823, 'colsample_bytree': 0.8905672394237985, 'gamma': 2.235144356389822, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:25,758] Trial 358 finished with value: 0.684850948509485 and parameters: {'n_estimators': 184, 'max_depth': 10, 'learning_rate': 0.28211898782810424, 'subsample': 0.9341213934876718, 'colsample_bytree': 0.8803511921346941, 'gamma': 2.1192473987549434, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:26,808] Trial 359 finished with value: 0.7056969696969697 and parameters: {'n_estimators': 196, 'max_depth': 10, 'learning_rate': 0.29969663578766753, 'subsample': 0.9194051851900819, 'colsample_bytree': 0.9006638511732332, 'gamma': 2.0038861940298065, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:27,602] Trial 360 finished with value: 0.7360692102928128 and parameters: {'n_estimators': 244, 'max_depth': 10, 'learning_rate': 0.29262869850765344, 'subsample': 0.9096418909268406, 'colsample_bytree': 0.9154534405385905, 'gamma': 2.3000684415744916, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:28,304] Trial 361 finished with value: 0.669257991755464 and parameters: {'n_estimators': 245, 'max_depth': 10, 'learning_rate': 0.2861711777116853, 'subsample': 0.7087669375252541, 'colsample_bytree': 0.9178847495488474, 'gamma': 2.3712902631134485, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:29,056] Trial 362 finished with value: 0.7121710924184947 and parameters: {'n_estimators': 251, 'max_depth': 10, 'learning_rate': 0.2914372168201324, 'subsample': 0.907889670358853, 'colsample_bytree': 0.9118469380954476, 'gamma': 2.5559598231301597, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:29,701] Trial 363 finished with value: 0.7245045844424726 and parameters: {'n_estimators': 238, 'max_depth': 10, 'learning_rate': 0.2764794893413611, 'subsample': 0.9111001569542743, 'colsample_bytree': 0.9063290550049403, 'gamma': 2.2261407085091665, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:30,312] Trial 364 finished with value: 0.6929707061362935 and parameters: {'n_estimators': 175, 'max_depth': 10, 'learning_rate': 0.2832642305089518, 'subsample': 0.91589958701835, 'colsample_bytree': 0.923791085496666, 'gamma': 0.5004260644700871, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:30,973] Trial 365 finished with value: 0.6910874704491725 and parameters: {'n_estimators': 244, 'max_depth': 10, 'learning_rate': 0.2922261964827028, 'subsample': 0.9046288594207377, 'colsample_bytree': 0.8969091283742453, 'gamma': 2.4224038911127295, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:31,645] Trial 366 finished with value: 0.6592224745138714 and parameters: {'n_estimators': 259, 'max_depth': 10, 'learning_rate': 0.28770131651721353, 'subsample': 0.9182845630973305, 'colsample_bytree': 0.913897186885542, 'gamma': 2.1377146915338305, 'min_child_weight': 7}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:32,313] Trial 367 finished with value: 0.7116642839122025 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.2953582883559152, 'subsample': 0.9127543914237382, 'colsample_bytree': 0.9332294709045978, 'gamma': 2.312843829982492, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:33,039] Trial 368 finished with value: 0.7009358499045051 and parameters: {'n_estimators': 245, 'max_depth': 10, 'learning_rate': 0.07446733273661141, 'subsample': 0.9227960466116012, 'colsample_bytree': 0.9053835385699073, 'gamma': 2.078922739343796, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:33,646] Trial 369 finished with value: 0.707475357703982 and parameters: {'n_estimators': 204, 'max_depth': 10, 'learning_rate': 0.27677148764398934, 'subsample': 0.9040699560229203, 'colsample_bytree': 0.8934197527235864, 'gamma': 2.2153035565711074, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:34,451] Trial 370 finished with value: 0.7099240855762595 and parameters: {'n_estimators': 232, 'max_depth': 10, 'learning_rate': 0.2940003406093717, 'subsample': 0.9101849013461064, 'colsample_bytree': 0.9380678153864936, 'gamma': 2.4761473117235444, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:35,079] Trial 371 finished with value: 0.7134514927827997 and parameters: {'n_estimators': 187, 'max_depth': 10, 'learning_rate': 0.28493480908693497, 'subsample': 0.8444574539795019, 'colsample_bytree': 0.8879261506927676, 'gamma': 2.307204297206535, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:35,647] Trial 372 finished with value: 0.6383281940589989 and parameters: {'n_estimators': 182, 'max_depth': 10, 'learning_rate': 0.28933436764862375, 'subsample': 0.994305187307196, 'colsample_bytree': 0.9196238649412065, 'gamma': 2.5869011263547645, 'min_child_weight': 10}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:36,344] Trial 373 finished with value: 0.6958626727058197 and parameters: {'n_estimators': 172, 'max_depth': 10, 'learning_rate': 0.28131054570771985, 'subsample': 0.9388156696305269, 'colsample_bytree': 0.9027399480406663, 'gamma': 2.0135681617520325, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:36,959] Trial 374 finished with value: 0.6840118577075099 and parameters: {'n_estimators': 179, 'max_depth': 10, 'learning_rate': 0.2950653222639308, 'subsample': 0.9276460809704761, 'colsample_bytree': 0.8663764986768505, 'gamma': 2.176149917302344, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:37,763] Trial 375 finished with value: 0.7319919827320382 and parameters: {'n_estimators': 296, 'max_depth': 10, 'learning_rate': 0.2897090129873739, 'subsample': 0.9182569463148362, 'colsample_bytree': 0.8966881545003976, 'gamma': 2.3972460092054857, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:38,495] Trial 376 finished with value: 0.7049577277719598 and parameters: {'n_estimators': 275, 'max_depth': 10, 'learning_rate': 0.2951490194173186, 'subsample': 0.9053349323703248, 'colsample_bytree': 0.7804946930083954, 'gamma': 2.330150718529145, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:39,072] Trial 377 finished with value: 0.7047457718265171 and parameters: {'n_estimators': 174, 'max_depth': 10, 'learning_rate': 0.29977578402392396, 'subsample': 0.9160789104388658, 'colsample_bytree': 0.8960132572094657, 'gamma': 2.200549893579169, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:39,791] Trial 378 finished with value: 0.7066836262719705 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.28759654877723173, 'subsample': 0.9189090622258567, 'colsample_bytree': 0.9132510344565721, 'gamma': 2.0240288860310764, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:40,527] Trial 379 finished with value: 0.7043818082274538 and parameters: {'n_estimators': 292, 'max_depth': 10, 'learning_rate': 0.280500794577378, 'subsample': 0.8529922145943064, 'colsample_bytree': 0.763851920886724, 'gamma': 2.2796393086420412, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:41,268] Trial 380 finished with value: 0.7150757760291454 and parameters: {'n_estimators': 294, 'max_depth': 10, 'learning_rate': 0.2916876489829431, 'subsample': 0.910432600691988, 'colsample_bytree': 0.9032638920498667, 'gamma': 2.3951767472420844, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:41] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:42,050] Trial 381 finished with value: 0.6801572856982361 and parameters: {'n_estimators': 177, 'max_depth': 10, 'learning_rate': 0.2849684200689285, 'subsample': 0.9025113687272689, 'colsample_bytree': 0.8852246582979805, 'gamma': 2.1072490118656293, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:42,771] Trial 382 finished with value: 0.7198581560283689 and parameters: {'n_estimators': 265, 'max_depth': 10, 'learning_rate': 0.29983319218860693, 'subsample': 0.9220817609815097, 'colsample_bytree': 0.8957856385373216, 'gamma': 2.2545580836251644, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:42] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:43,713] Trial 383 finished with value: 0.691883116883117 and parameters: {'n_estimators': 297, 'max_depth': 10, 'learning_rate': 0.29393507673151104, 'subsample': 0.9320612904945721, 'colsample_bytree': 0.9115761479597517, 'gamma': 2.4943519565706778, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:43] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:44,417] Trial 384 finished with value: 0.7063657681302842 and parameters: {'n_estimators': 184, 'max_depth': 10, 'learning_rate': 0.2756437245841483, 'subsample': 0.909008524731621, 'colsample_bytree': 0.8866386259555947, 'gamma': 2.378468623572409, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:45,231] Trial 385 finished with value: 0.6977111540941328 and parameters: {'n_estimators': 289, 'max_depth': 10, 'learning_rate': 0.2906952157687284, 'subsample': 0.9147270173025002, 'colsample_bytree': 0.7325092121186071, 'gamma': 2.1565357821202027, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:45,921] Trial 386 finished with value: 0.7177694334650856 and parameters: {'n_estimators': 249, 'max_depth': 10, 'learning_rate': 0.28408786185810664, 'subsample': 0.900189171224266, 'colsample_bytree': 0.9258428218503401, 'gamma': 2.3040656023505273, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:46,681] Trial 387 finished with value: 0.7117092198581562 and parameters: {'n_estimators': 283, 'max_depth': 7, 'learning_rate': 0.29532214312451616, 'subsample': 0.9189959005151913, 'colsample_bytree': 0.9003558940003656, 'gamma': 2.05947466991583, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:46] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:47,514] Trial 388 finished with value: 0.690253376713004 and parameters: {'n_estimators': 269, 'max_depth': 10, 'learning_rate': 0.2899372246272816, 'subsample': 0.8241023703854725, 'colsample_bytree': 0.8939200262354531, 'gamma': 2.5924150912359, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:48,241] Trial 389 finished with value: 0.6287305992393875 and parameters: {'n_estimators': 186, 'max_depth': 10, 'learning_rate': 0.2807244697789483, 'subsample': 0.9352246102075344, 'colsample_bytree': 0.9416715014490205, 'gamma': 2.1684086609708544, 'min_child_weight': 9}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:48] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:48,907] Trial 390 finished with value: 0.6506366235558783 and parameters: {'n_estimators': 234, 'max_depth': 10, 'learning_rate': 0.2999230961439157, 'subsample': 0.947274975795946, 'colsample_bytree': 0.918356067022972, 'gamma': 2.428688292590588, 'min_child_weight': 6}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:49,649] Trial 391 finished with value: 0.7262341390456892 and parameters: {'n_estimators': 252, 'max_depth': 10, 'learning_rate': 0.28731434489802316, 'subsample': 0.9239130641822186, 'colsample_bytree': 0.9068047823247218, 'gamma': 2.245276824115215, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:49] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:50,558] Trial 392 finished with value: 0.6878787878787879 and parameters: {'n_estimators': 243, 'max_depth': 10, 'learning_rate': 0.294496313483369, 'subsample': 0.9581084407130864, 'colsample_bytree': 0.9054193566640347, 'gamma': 1.931550360136217, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:50] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:51,250] Trial 393 finished with value: 0.7183367839889578 and parameters: {'n_estimators': 252, 'max_depth': 10, 'learning_rate': 0.2875299126347598, 'subsample': 0.9285573930150408, 'colsample_bytree': 0.9106218301312903, 'gamma': 2.2297290856536622, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:51] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:51,942] Trial 394 finished with value: 0.6875646619585265 and parameters: {'n_estimators': 251, 'max_depth': 10, 'learning_rate': 0.2941742492667154, 'subsample': 0.9412788229274316, 'colsample_bytree': 0.8907923383338439, 'gamma': 2.0689299203184652, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:52,706] Trial 395 finished with value: 0.726063829787234 and parameters: {'n_estimators': 247, 'max_depth': 10, 'learning_rate': 0.2883831210006025, 'subsample': 0.9226861307377109, 'colsample_bytree': 0.9010467619979343, 'gamma': 2.3082011590330573, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:53,433] Trial 396 finished with value: 0.6982539682539682 and parameters: {'n_estimators': 254, 'max_depth': 10, 'learning_rate': 0.28297413142434963, 'subsample': 0.9279393896832723, 'colsample_bytree': 0.8795998322265491, 'gamma': 2.171830815100674, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:54,196] Trial 397 finished with value: 0.7011667434841499 and parameters: {'n_estimators': 278, 'max_depth': 10, 'learning_rate': 0.2945178660513501, 'subsample': 0.9174021524360167, 'colsample_bytree': 0.9236590012118504, 'gamma': 2.4905260838523318, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:54,863] Trial 398 finished with value: 0.7156771799628943 and parameters: {'n_estimators': 241, 'max_depth': 10, 'learning_rate': 0.2896127297220206, 'subsample': 0.930530597119943, 'colsample_bytree': 0.906913066402056, 'gamma': 2.384393048399716, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:55,471] Trial 399 finished with value: 0.6913340965012698 and parameters: {'n_estimators': 189, 'max_depth': 10, 'learning_rate': 0.294930844588856, 'subsample': 0.9376427410326188, 'colsample_bytree': 0.8945190091309605, 'gamma': 1.96321346436673, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:56,205] Trial 400 finished with value: 0.7319973322662399 and parameters: {'n_estimators': 262, 'max_depth': 10, 'learning_rate': 0.2860070541469448, 'subsample': 0.9075769035042094, 'colsample_bytree': 0.9178444767989873, 'gamma': 2.231792692604799, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:56,836] Trial 401 finished with value: 0.6770397856112141 and parameters: {'n_estimators': 198, 'max_depth': 10, 'learning_rate': 0.2994498682384609, 'subsample': 0.8994733919570453, 'colsample_bytree': 0.930953275467472, 'gamma': 2.0849264259733147, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:57,610] Trial 402 finished with value: 0.7319385342789598 and parameters: {'n_estimators': 262, 'max_depth': 10, 'learning_rate': 0.2784128520608375, 'subsample': 0.9062314419953668, 'colsample_bytree': 0.918664859309149, 'gamma': 2.34557053816199, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:58,882] Trial 403 finished with value: 0.6776853642811089 and parameters: {'n_estimators': 266, 'max_depth': 10, 'learning_rate': 0.27527854443263244, 'subsample': 0.9056596556502491, 'colsample_bytree': 0.9194386318659828, 'gamma': 2.180082669104738, 'min_child_weight': 4}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:39:59,728] Trial 404 finished with value: 0.7207480356483679 and parameters: {'n_estimators': 261, 'max_depth': 10, 'learning_rate': 0.27945100988972477, 'subsample': 0.8967379386136143, 'colsample_bytree': 0.9280869174626043, 'gamma': 2.3379218701242586, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:39:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:00,431] Trial 405 finished with value: 0.7244547803617573 and parameters: {'n_estimators': 259, 'max_depth': 10, 'learning_rate': 0.28413194476993786, 'subsample': 0.9089108734126341, 'colsample_bytree': 0.9137322631033094, 'gamma': 2.252807127548678, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:01,134] Trial 406 finished with value: 0.7138459058671824 and parameters: {'n_estimators': 269, 'max_depth': 10, 'learning_rate': 0.28107969922704024, 'subsample': 0.9010881078795484, 'colsample_bytree': 0.9409354913439771, 'gamma': 2.0086702718682488, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:01,844] Trial 407 finished with value: 0.7326266749123891 and parameters: {'n_estimators': 272, 'max_depth': 10, 'learning_rate': 0.2895409775180564, 'subsample': 0.910342514039446, 'colsample_bytree': 0.9164386062888875, 'gamma': 2.1392131127786818, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:02,554] Trial 408 finished with value: 0.6858191856452726 and parameters: {'n_estimators': 273, 'max_depth': 10, 'learning_rate': 0.2733026357744545, 'subsample': 0.9073865228621288, 'colsample_bytree': 0.9159750795771143, 'gamma': 2.095351339134568, 'min_child_weight': 2}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:03,307] Trial 409 finished with value: 0.6921985815602836 and parameters: {'n_estimators': 270, 'max_depth': 10, 'learning_rate': 0.28664296602042, 'subsample': 0.9121901173646855, 'colsample_bytree': 0.898984733602759, 'gamma': 2.1208551187741214, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:04,030] Trial 410 finished with value: 0.6704347826086956 and parameters: {'n_estimators': 277, 'max_depth': 10, 'learning_rate': 0.2816857859286591, 'subsample': 0.8932454487367927, 'colsample_bytree': 0.9109821019007214, 'gamma': 1.9667422388943383, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:04,759] Trial 411 finished with value: 0.7253829787234043 and parameters: {'n_estimators': 281, 'max_depth': 10, 'learning_rate': 0.28838628747856937, 'subsample': 0.6195936121578732, 'colsample_bytree': 0.88683111237726, 'gamma': 2.477879699733239, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:05,751] Trial 412 finished with value: 0.6850489115583728 and parameters: {'n_estimators': 265, 'max_depth': 10, 'learning_rate': 0.27722720688301133, 'subsample': 0.8996830826459116, 'colsample_bytree': 0.9196470057536317, 'gamma': 1.86093725614628, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:06,479] Trial 413 finished with value: 0.7226468769325913 and parameters: {'n_estimators': 263, 'max_depth': 10, 'learning_rate': 0.29074932465781556, 'subsample': 0.9077557915945218, 'colsample_bytree': 0.9040656830133548, 'gamma': 1.108249319451085, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:07,167] Trial 414 finished with value: 0.7161021855550731 and parameters: {'n_estimators': 259, 'max_depth': 10, 'learning_rate': 0.29949059873462247, 'subsample': 0.9153584963012792, 'colsample_bytree': 0.8947232899949786, 'gamma': 2.3403591653763605, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:07,925] Trial 415 finished with value: 0.7090581367298693 and parameters: {'n_estimators': 267, 'max_depth': 10, 'learning_rate': 0.2850853580670979, 'subsample': 0.9046270338662776, 'colsample_bytree': 0.913974065017625, 'gamma': 2.1753876183266208, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:08,650] Trial 416 finished with value: 0.6958243657020783 and parameters: {'n_estimators': 274, 'max_depth': 10, 'learning_rate': 0.29991958866938195, 'subsample': 0.8955038583549548, 'colsample_bytree': 0.9002008573041944, 'gamma': 2.6286322371229516, 'min_child_weight': 2}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:09,375] Trial 417 finished with value: 0.7226630251237097 and parameters: {'n_estimators': 261, 'max_depth': 10, 'learning_rate': 0.29194497803685854, 'subsample': 0.9162602264007076, 'colsample_bytree': 0.88536911629955, 'gamma': 2.3078238720652973, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:10,039] Trial 418 finished with value: 0.6967526327100795 and parameters: {'n_estimators': 255, 'max_depth': 10, 'learning_rate': 0.2780370418493192, 'subsample': 0.9108283913049778, 'colsample_bytree': 0.9231385001871093, 'gamma': 2.0414678077535653, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:10,630] Trial 419 finished with value: 0.6993432550885967 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.2845906200668928, 'subsample': 0.8604677081749008, 'colsample_bytree': 0.9058114853046587, 'gamma': 2.1890023993165224, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:11,251] Trial 420 finished with value: 0.6878723404255319 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.29107675396932375, 'subsample': 0.903727938138229, 'colsample_bytree': 0.8910333392188645, 'gamma': 2.431149134588646, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:11,852] Trial 421 finished with value: 0.7104082452648595 and parameters: {'n_estimators': 207, 'max_depth': 10, 'learning_rate': 0.2946858952571315, 'subsample': 0.9181752571231893, 'colsample_bytree': 0.9102449329712482, 'gamma': 2.511887296213521, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:12,632] Trial 422 finished with value: 0.7064210965018418 and parameters: {'n_estimators': 288, 'max_depth': 10, 'learning_rate': 0.27265579391941186, 'subsample': 0.8950454459418322, 'colsample_bytree': 0.8842137184058178, 'gamma': 2.268038112378972, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:13,635] Trial 423 finished with value: 0.718939393939394 and parameters: {'n_estimators': 272, 'max_depth': 10, 'learning_rate': 0.28851475548515293, 'subsample': 0.9116460349014697, 'colsample_bytree': 0.898729499509089, 'gamma': 2.119756028985497, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:14,617] Trial 424 finished with value: 0.7241607565011821 and parameters: {'n_estimators': 263, 'max_depth': 10, 'learning_rate': 0.2823298873240329, 'subsample': 0.9215547909654522, 'colsample_bytree': 0.8916032354912189, 'gamma': 2.3686487701460837, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:15,233] Trial 425 finished with value: 0.6983747680890537 and parameters: {'n_estimators': 205, 'max_depth': 10, 'learning_rate': 0.2938818820115595, 'subsample': 0.904738255970153, 'colsample_bytree': 0.9209952723222886, 'gamma': 2.2135943067679467, 'min_child_weight': 2}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:15,828] Trial 426 finished with value: 0.7077616152844116 and parameters: {'n_estimators': 194, 'max_depth': 10, 'learning_rate': 0.29980506762306586, 'subsample': 0.9222971744262559, 'colsample_bytree': 0.9057059033759761, 'gamma': 2.034341543971395, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:16,404] Trial 427 finished with value: 0.7059967465246968 and parameters: {'n_estimators': 179, 'max_depth': 10, 'learning_rate': 0.2896127751193475, 'subsample': 0.8355822211429603, 'colsample_bytree': 0.8719981857666685, 'gamma': 2.3368239282244128, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:17,091] Trial 428 finished with value: 0.6991569080213316 and parameters: {'n_estimators': 256, 'max_depth': 10, 'learning_rate': 0.28361109512344695, 'subsample': 0.8995503340111806, 'colsample_bytree': 0.8826775366198337, 'gamma': 2.569636214548946, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:17,652] Trial 429 finished with value: 0.6890247662883658 and parameters: {'n_estimators': 170, 'max_depth': 6, 'learning_rate': 0.2947687456305816, 'subsample': 0.9145591776407784, 'colsample_bytree': 0.8984316361095304, 'gamma': 2.4261255488773243, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:18,496] Trial 430 finished with value: 0.6961702127659575 and parameters: {'n_estimators': 283, 'max_depth': 10, 'learning_rate': 0.2770551375066573, 'subsample': 0.9335389258047957, 'colsample_bytree': 0.9161885291215524, 'gamma': 2.135764689744798, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:19,117] Trial 431 finished with value: 0.7082893361311041 and parameters: {'n_estimators': 184, 'max_depth': 10, 'learning_rate': 0.2884125963767107, 'subsample': 0.9108717550752601, 'colsample_bytree': 0.9322714210394357, 'gamma': 1.9077378118971697, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:19,699] Trial 432 finished with value: 0.7067435875872509 and parameters: {'n_estimators': 186, 'max_depth': 7, 'learning_rate': 0.29976195780976306, 'subsample': 0.9241187969160674, 'colsample_bytree': 0.8906220295149604, 'gamma': 2.2585088523299217, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:20,296] Trial 433 finished with value: 0.7037607560718928 and parameters: {'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.2850819095522585, 'subsample': 0.8918921294076987, 'colsample_bytree': 0.9081459984369411, 'gamma': 2.3330488072020064, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:20,885] Trial 434 finished with value: 0.655195806352143 and parameters: {'n_estimators': 177, 'max_depth': 10, 'learning_rate': 0.2927017884491634, 'subsample': 0.8673814978338488, 'colsample_bytree': 0.8769552207508913, 'gamma': 2.1624176459153848, 'min_child_weight': 5}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:21,928] Trial 435 finished with value: 0.7177139836508146 and parameters: {'n_estimators': 183, 'max_depth': 10, 'learning_rate': 0.27993810481714726, 'subsample': 0.902862114898446, 'colsample_bytree': 0.8994789926402083, 'gamma': 2.0120456915052265, 'min_child_weight': 2}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:24,163] Trial 436 finished with value: 0.7310675140462374 and parameters: {'n_estimators': 267, 'max_depth': 10, 'learning_rate': 0.28995102722856364, 'subsample': 0.9153791529735688, 'colsample_bytree': 0.9367978437921277, 'gamma': 2.4773929367907797, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:25,066] Trial 437 finished with value: 0.7122415645819901 and parameters: {'n_estimators': 267, 'max_depth': 10, 'learning_rate': 0.2716690192973842, 'subsample': 0.9230360232940815, 'colsample_bytree': 0.9458626431899161, 'gamma': 2.6761091251209006, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:25,905] Trial 438 finished with value: 0.6925559947299078 and parameters: {'n_estimators': 270, 'max_depth': 10, 'learning_rate': 0.2871122915766476, 'subsample': 0.9310377731929826, 'colsample_bytree': 0.9367268510990227, 'gamma': 2.5562118129240234, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:26,828] Trial 439 finished with value: 0.6935606706450695 and parameters: {'n_estimators': 262, 'max_depth': 10, 'learning_rate': 0.28037271690294063, 'subsample': 0.6756934324998162, 'colsample_bytree': 0.9371227693771683, 'gamma': 2.460274168652505, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:30,733] Trial 440 finished with value: 0.7069546529120997 and parameters: {'n_estimators': 265, 'max_depth': 10, 'learning_rate': 0.290437212810182, 'subsample': 0.9171393078911866, 'colsample_bytree': 0.9265081466474906, 'gamma': 2.5199806708684114, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:31,921] Trial 441 finished with value: 0.6976309128302484 and parameters: {'n_estimators': 270, 'max_depth': 10, 'learning_rate': 0.28456863313043707, 'subsample': 0.9422380297716877, 'colsample_bytree': 0.923583625042093, 'gamma': 2.416632716179037, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:32,748] Trial 442 finished with value: 0.7059903381642513 and parameters: {'n_estimators': 259, 'max_depth': 10, 'learning_rate': 0.29371905173473395, 'subsample': 0.9074361850673374, 'colsample_bytree': 0.9305780297141439, 'gamma': 2.635540015839314, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:34,190] Trial 443 finished with value: 0.7171369102682702 and parameters: {'n_estimators': 277, 'max_depth': 10, 'learning_rate': 0.2744558116393858, 'subsample': 0.9306031091192212, 'colsample_bytree': 0.9173564948687797, 'gamma': 2.349671340055224, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:35,189] Trial 444 finished with value: 0.7118696162930461 and parameters: {'n_estimators': 274, 'max_depth': 10, 'learning_rate': 0.28940111129814233, 'subsample': 0.9168822804416932, 'colsample_bytree': 0.917247361875768, 'gamma': 3.0852248507229487, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:36,012] Trial 445 finished with value: 0.6972898550724638 and parameters: {'n_estimators': 264, 'max_depth': 10, 'learning_rate': 0.29500129952869864, 'subsample': 0.896489328686581, 'colsample_bytree': 0.9474499977230063, 'gamma': 2.266210935456833, 'min_child_weight': 2}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:36,768] Trial 446 finished with value: 0.712118408880666 and parameters: {'n_estimators': 210, 'max_depth': 10, 'learning_rate': 0.27964834800250765, 'subsample': 0.9119161988486009, 'colsample_bytree': 0.9364104567472478, 'gamma': 2.4160390188881413, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:37,404] Trial 447 finished with value: 0.7010185183596047 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.28556696597102915, 'subsample': 0.7752647220411385, 'colsample_bytree': 0.7165142503687916, 'gamma': 2.2859263706051696, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:38,328] Trial 448 finished with value: 0.6734624587954494 and parameters: {'n_estimators': 295, 'max_depth': 10, 'learning_rate': 0.2998821052287057, 'subsample': 0.6627872576832703, 'colsample_bytree': 0.9082318616349536, 'gamma': 2.4995008581283957, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:44] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:45,300] Trial 449 finished with value: 0.6953333333333334 and parameters: {'n_estimators': 196, 'max_depth': 10, 'learning_rate': 0.290826827062427, 'subsample': 0.9250711880814734, 'colsample_bytree': 0.9274577920742887, 'gamma': 0.3143399435882732, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:45] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:47] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:52] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:53] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:54,033] Trial 450 finished with value: 0.6973605621431709 and parameters: {'n_estimators': 269, 'max_depth': 10, 'learning_rate': 0.16145041962427462, 'subsample': 0.9380118263569285, 'colsample_bytree': 0.8644600649053027, 'gamma': 2.128548042737266, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:55,370] Trial 451 finished with value: 0.6894228779632046 and parameters: {'n_estimators': 257, 'max_depth': 4, 'learning_rate': 0.28337777286306315, 'subsample': 0.9047673527600193, 'colsample_bytree': 0.9134243913455813, 'gamma': 2.370401021847982, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:55] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:56] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:57,507] Trial 452 finished with value: 0.717445266728338 and parameters: {'n_estimators': 190, 'max_depth': 10, 'learning_rate': 0.2948186459438708, 'subsample': 0.9202362857018247, 'colsample_bytree': 0.8847055201635552, 'gamma': 2.215798713546471, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:58,325] Trial 453 finished with value: 0.6931600731109614 and parameters: {'n_estimators': 203, 'max_depth': 10, 'learning_rate': 0.2885100260039098, 'subsample': 0.890923981897785, 'colsample_bytree': 0.9012806169177769, 'gamma': 2.0766840555630393, 'min_child_weight': 2}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:58] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:40:59,698] Trial 454 finished with value: 0.6886718101874897 and parameters: {'n_estimators': 262, 'max_depth': 10, 'learning_rate': 0.27746738806705235, 'subsample': 0.9507285517097067, 'colsample_bytree': 0.9230051658947774, 'gamma': 1.864118432505581, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:40:59] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:00] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:01,355] Trial 455 finished with value: 0.7189463019250253 and parameters: {'n_estimators': 274, 'max_depth': 10, 'learning_rate': 0.2945445103217034, 'subsample': 0.9141525174770905, 'colsample_bytree': 0.9069499609292083, 'gamma': 2.467686462531512, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:01] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:02,372] Trial 456 finished with value: 0.7158929722759511 and parameters: {'n_estimators': 196, 'max_depth': 10, 'learning_rate': 0.28592859374938795, 'subsample': 0.8998133529247493, 'colsample_bytree': 0.8946656753062279, 'gamma': 2.306247793021612, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:02] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:03,396] Trial 457 finished with value: 0.7016464032421479 and parameters: {'n_estimators': 267, 'max_depth': 10, 'learning_rate': 0.2908761087809904, 'subsample': 0.9311412900623024, 'colsample_bytree': 0.8815142533014036, 'gamma': 1.9514800392619325, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:03] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:04,196] Trial 458 finished with value: 0.7065553780169876 and parameters: {'n_estimators': 189, 'max_depth': 10, 'learning_rate': 0.27221172747036565, 'subsample': 0.9229019830346679, 'colsample_bytree': 0.91278335700104, 'gamma': 2.2135675927343303, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:04] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:05,016] Trial 459 finished with value: 0.7225778082963352 and parameters: {'n_estimators': 192, 'max_depth': 10, 'learning_rate': 0.2955004292102215, 'subsample': 0.9070710104972904, 'colsample_bytree': 0.8923558504413469, 'gamma': 2.5576209498027658, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:05,728] Trial 460 finished with value: 0.7045750449424297 and parameters: {'n_estimators': 185, 'max_depth': 10, 'learning_rate': 0.28112895450947945, 'subsample': 0.9138599453993305, 'colsample_bytree': 0.9432516617782614, 'gamma': 2.3891980981257515, 'min_child_weight': 2}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:05] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:06,503] Trial 461 finished with value: 0.6865530761690596 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.19304924031960852, 'subsample': 0.9333266937930474, 'colsample_bytree': 0.9032828459522056, 'gamma': 2.0729664288589227, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:06] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:07,255] Trial 462 finished with value: 0.7019586013524657 and parameters: {'n_estimators': 187, 'max_depth': 10, 'learning_rate': 0.289907902216777, 'subsample': 0.817150675741877, 'colsample_bytree': 0.9201543905956908, 'gamma': 2.186026449360349, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:07] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:08,117] Trial 463 finished with value: 0.728524374176548 and parameters: {'n_estimators': 261, 'max_depth': 10, 'learning_rate': 0.29915890628524755, 'subsample': 0.9212215237058362, 'colsample_bytree': 0.871130361043662, 'gamma': 2.3064743375706303, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:08] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:08,961] Trial 464 finished with value: 0.72454235168945 and parameters: {'n_estimators': 255, 'max_depth': 10, 'learning_rate': 0.2848761275915798, 'subsample': 0.9004337449148758, 'colsample_bytree': 0.8582368727580588, 'gamma': 2.632717769234317, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:09] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:10,383] Trial 465 finished with value: 0.6958276643990929 and parameters: {'n_estimators': 260, 'max_depth': 10, 'learning_rate': 0.094573728063146, 'subsample': 0.8741777866189603, 'colsample_bytree': 0.9313566997438719, 'gamma': 2.4253324337624607, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:10] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:11,255] Trial 466 finished with value: 0.7056092843326887 and parameters: {'n_estimators': 279, 'max_depth': 10, 'learning_rate': 0.1530370937868616, 'subsample': 0.9084803336412696, 'colsample_bytree': 0.8694721648959394, 'gamma': 2.336695527855519, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:11] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:12,078] Trial 467 finished with value: 0.7001525458668316 and parameters: {'n_estimators': 262, 'max_depth': 10, 'learning_rate': 0.29498848675442535, 'subsample': 0.8907267919548586, 'colsample_bytree': 0.9115017532670072, 'gamma': 2.2867920082085194, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:12,742] Trial 468 finished with value: 0.6956963591375043 and parameters: {'n_estimators': 257, 'max_depth': 10, 'learning_rate': 0.2806949896104794, 'subsample': 0.9163146386479988, 'colsample_bytree': 0.8991300241277861, 'gamma': 2.516423849551125, 'min_child_weight': 2}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:12] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:13,363] Trial 469 finished with value: 0.7240908623702333 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.28987911179419135, 'subsample': 0.9234816388591867, 'colsample_bytree': 0.8770192131104978, 'gamma': 2.4031706513877573, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:13] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:14,309] Trial 470 finished with value: 0.7365294802386242 and parameters: {'n_estimators': 267, 'max_depth': 10, 'learning_rate': 0.299858170238877, 'subsample': 0.9069439611521121, 'colsample_bytree': 0.8888566816763952, 'gamma': 2.278983230118661, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:14] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:15,125] Trial 471 finished with value: 0.6751594843639246 and parameters: {'n_estimators': 270, 'max_depth': 10, 'learning_rate': 0.2955325394043898, 'subsample': 0.9021635482039715, 'colsample_bytree': 0.8897960010688865, 'gamma': 2.2615321984581036, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:15] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:15,860] Trial 472 finished with value: 0.7198027036901717 and parameters: {'n_estimators': 267, 'max_depth': 10, 'learning_rate': 0.2986415077252456, 'subsample': 0.910741388462507, 'colsample_bytree': 0.8729251381393298, 'gamma': 2.324896759686825, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:16,647] Trial 473 finished with value: 0.7067773479475606 and parameters: {'n_estimators': 263, 'max_depth': 10, 'learning_rate': 0.29977681828121977, 'subsample': 0.9169168421387818, 'colsample_bytree': 0.8896074779383076, 'gamma': 2.1813534774602443, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:16] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:17,443] Trial 474 finished with value: 0.6519107821975536 and parameters: {'n_estimators': 264, 'max_depth': 10, 'learning_rate': 0.29082851853908537, 'subsample': 0.9289771489566556, 'colsample_bytree': 0.8831045577907269, 'gamma': 2.1001181212502367, 'min_child_weight': 8}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:17] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:18,503] Trial 475 finished with value: 0.7069974890973966 and parameters: {'n_estimators': 273, 'max_depth': 10, 'learning_rate': 0.2878928646471061, 'subsample': 0.9442683936560843, 'colsample_bytree': 0.8977120629183613, 'gamma': 2.4444024474545976, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:18] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:19,298] Trial 476 finished with value: 0.7288773097891639 and parameters: {'n_estimators': 267, 'max_depth': 10, 'learning_rate': 0.29487182074070534, 'subsample': 0.9070954850147621, 'colsample_bytree': 0.9043706525195374, 'gamma': 2.276209700366477, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:19] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:20,115] Trial 477 finished with value: 0.7111702127659575 and parameters: {'n_estimators': 266, 'max_depth': 10, 'learning_rate': 0.28412834102065043, 'subsample': 0.8984151797980633, 'colsample_bytree': 0.9066594375216939, 'gamma': 2.3587461238694187, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:20] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:20,956] Trial 478 finished with value: 0.7396859903381643 and parameters: {'n_estimators': 271, 'max_depth': 10, 'learning_rate': 0.2929115630149129, 'subsample': 0.9085474337986553, 'colsample_bytree': 0.9165562484279831, 'gamma': 2.262227739998789, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:21,805] Trial 479 finished with value: 0.7175693101225016 and parameters: {'n_estimators': 270, 'max_depth': 10, 'learning_rate': 0.29409571976726834, 'subsample': 0.9059079040664887, 'colsample_bytree': 0.9198917050488638, 'gamma': 2.0212870999486494, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:21] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:22,584] Trial 480 finished with value: 0.7019146880460478 and parameters: {'n_estimators': 270, 'max_depth': 10, 'learning_rate': 0.29969226910637087, 'subsample': 0.8941269545294294, 'colsample_bytree': 0.9153381789874734, 'gamma': 2.203932633161951, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:22] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:23,565] Trial 481 finished with value: 0.7049185484776992 and parameters: {'n_estimators': 275, 'max_depth': 10, 'learning_rate': 0.2923529035574756, 'subsample': 0.9075146148949395, 'colsample_bytree': 0.9316977788815874, 'gamma': 2.5084529464737884, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:24,547] Trial 482 finished with value: 0.7124863292131818 and parameters: {'n_estimators': 278, 'max_depth': 10, 'learning_rate': 0.2847291803367032, 'subsample': 0.9201151521535167, 'colsample_bytree': 0.924643691656436, 'gamma': 2.121925133375655, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:25,374] Trial 483 finished with value: 0.6829536465749091 and parameters: {'n_estimators': 267, 'max_depth': 10, 'learning_rate': 0.27573406353973434, 'subsample': 0.9382020467097668, 'colsample_bytree': 0.9109872223965342, 'gamma': 2.2802046310008848, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:25] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:26,590] Trial 484 finished with value: 0.6834248124164868 and parameters: {'n_estimators': 273, 'max_depth': 10, 'learning_rate': 0.29421191212928266, 'subsample': 0.8983839069700812, 'colsample_bytree': 0.9382031237615609, 'gamma': 2.378363657966614, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:26] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:27,453] Trial 485 finished with value: 0.7057292430714357 and parameters: {'n_estimators': 265, 'max_depth': 10, 'learning_rate': 0.2997569062214895, 'subsample': 0.913028121664563, 'colsample_bytree': 0.9061814822685337, 'gamma': 2.0018679543936093, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:27] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:28,357] Trial 486 finished with value: 0.7019806763285025 and parameters: {'n_estimators': 259, 'max_depth': 10, 'learning_rate': 0.28901743929047796, 'subsample': 0.9280315193758462, 'colsample_bytree': 0.9181375617163146, 'gamma': 2.2349220891146535, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:28] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:29,245] Trial 487 finished with value: 0.7030900012178785 and parameters: {'n_estimators': 261, 'max_depth': 10, 'learning_rate': 0.28160916405672676, 'subsample': 0.9037294708433008, 'colsample_bytree': 0.9275558622745654, 'gamma': 2.1257961125146894, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:29] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:30,208] Trial 488 finished with value: 0.7028528407410395 and parameters: {'n_estimators': 270, 'max_depth': 10, 'learning_rate': 0.05303060037224512, 'subsample': 0.9201578508164905, 'colsample_bytree': 0.9061747287905139, 'gamma': 2.448343049522896, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:30] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:31,207] Trial 489 finished with value: 0.7047474747474747 and parameters: {'n_estimators': 282, 'max_depth': 10, 'learning_rate': 0.04098912706693386, 'subsample': 0.9116889466193753, 'colsample_bytree': 0.899540282907951, 'gamma': 2.310786613695533, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:32,074] Trial 490 finished with value: 0.7144927536231884 and parameters: {'n_estimators': 268, 'max_depth': 10, 'learning_rate': 0.29104775831299495, 'subsample': 0.9255519485597044, 'colsample_bytree': 0.9146012047970585, 'gamma': 2.556167094546641, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:32] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:33,243] Trial 491 finished with value: 0.6195410628019324 and parameters: {'n_estimators': 273, 'max_depth': 10, 'learning_rate': 0.294994782114364, 'subsample': 0.9013654575745442, 'colsample_bytree': 0.9207872261287816, 'gamma': 0.8203546364840242, 'min_child_weight': 6}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:33] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:34,046] Trial 492 finished with value: 0.7203666714912915 and parameters: {'n_estimators': 277, 'max_depth': 10, 'learning_rate': 0.2999911788714543, 'subsample': 0.9170964814217007, 'colsample_bytree': 0.9521020967731214, 'gamma': 2.2376611642165236, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:34] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:34,874] Trial 493 finished with value: 0.6932752700216689 and parameters: {'n_estimators': 261, 'max_depth': 3, 'learning_rate': 0.28593779964487426, 'subsample': 0.8892821446459387, 'colsample_bytree': 0.9012886147918143, 'gamma': 2.3588691487674733, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:35,669] Trial 494 finished with value: 0.7169998255712542 and parameters: {'n_estimators': 266, 'max_depth': 10, 'learning_rate': 0.2784541356463463, 'subsample': 0.9362787205880445, 'colsample_bytree': 0.914202159796149, 'gamma': 2.1298682096428934, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:35] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:36,489] Trial 495 finished with value: 0.7248792270531401 and parameters: {'n_estimators': 263, 'max_depth': 10, 'learning_rate': 0.28946028691543263, 'subsample': 0.9081574609162856, 'colsample_bytree': 0.9251543383130062, 'gamma': 1.848844140237805, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:37,339] Trial 496 finished with value: 0.7079748549323017 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.29296324648654654, 'subsample': 0.9242232659184056, 'colsample_bytree': 0.8955216866341354, 'gamma': 1.9560113933636345, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:37] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:38,131] Trial 497 finished with value: 0.6963695547002501 and parameters: {'n_estimators': 255, 'max_depth': 10, 'learning_rate': 0.2844920689917614, 'subsample': 0.8969929361645569, 'colsample_bytree': 0.9375058944382813, 'gamma': 2.47841119238028, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:38] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:39,549] Trial 498 finished with value: 0.684206338496294 and parameters: {'n_estimators': 272, 'max_depth': 10, 'learning_rate': 0.011191698097468339, 'subsample': 0.9647776464123277, 'colsample_bytree': 0.9062171890774515, 'gamma': 2.241916006131739, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:39] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
c:\Users\x-hp\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\training.py:183: UserWarning: [04:41:40] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738:
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
[I 2025-05-02 04:41:40,632] Trial 499 finished with value: 0.7048457874445716 and parameters: {'n_estimators': 267, 'max_depth': 6, 'learning_rate': 0.2938396230901952, 'subsample': 0.9140781136126124, 'colsample_bytree': 0.962133187011063, 'gamma': 2.0607555362125947, 'min_child_weight': 1}. Best is trial 270 with value: 0.7467670188642833.
✅ Best XGBoost Parameters: {'n_estimators': 184, 'max_depth': 10, 'learning_rate': 0.2949424037202682, 'subsample': 0.9085237438425097, 'colsample_bytree': 0.899500021587377, 'gamma': 2.265477208921092, 'min_child_weight': 1}
✅ Best model selected based on F1: XGBoost
02-05-2025 04:41:41 Retraining best model on original full dataset...
02-05-2025 04:41:42 ✅ Exported and logged final model to W&B as artifact: final_model_xgboost.pkl
