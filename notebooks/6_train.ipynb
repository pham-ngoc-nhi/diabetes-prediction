{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae786992",
   "metadata": {},
   "source": [
    "# Step 6: Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbedb260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (0.19.8)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: optuna in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from wandb) (5.29.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from wandb) (2.10.6)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from wandb) (2.24.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from wandb) (65.5.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from imbalanced-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from imbalanced-learn) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from optuna) (1.15.2)\n",
      "Requirement already satisfied: colorlog in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from optuna) (2.0.40)\n",
      "Requirement already satisfied: tqdm in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: Mako in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\x-hp\\onedrive - national economics university\\desktop\\ml ops\\.venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb imbalanced-learn xgboost optuna joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d3d866b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import wandb\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import optuna\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s', datefmt='%d-%m-%Y %H:%M:%S')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd3a0d1",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00c54f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    wandb.login()\n",
    "    run = wandb.init(project=\"diabetes\",entity=\"ngocnhi-p4work-national-economics-university\", job_type=\"train\")\n",
    "    artifact = run.use_artifact(\"train.csv:latest\")\n",
    "    artifact_dir = artifact.download()\n",
    "    df = pd.read_csv(os.path.join(artifact_dir, \"train.csv\"))\n",
    "    logger.info(f\"Tập dữ liệu đã load với shape: {df.shape}\")\n",
    "    return df, run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbbd600",
   "metadata": {},
   "source": [
    "## 2. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4a6d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    # Split data into training and validation sets\n",
    "    X = df.drop(columns=[\"OUTCOME\"])\n",
    "    y = df[\"OUTCOME\"]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    logger.info(f\"Train shape: {X_train.shape}, Validation shape: {X_val.shape}\") # log train and validation shapes\n",
    "    # Handle class imbalance using SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    logger.info(f\"After SMOTE - Counts: {y_train_res.value_counts().to_dict()}\") # log class counts after SMOTE\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    return X_train_scaled, X_val_scaled, y_train_res, y_val, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "551eff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base_models(X_train, y_train, X_val, y_val):\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=500),\n",
    "        'Random Forest': RandomForestClassifier(random_state=42),\n",
    "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    }\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_val, preds),\n",
    "            'precision': precision_score(y_val, preds),\n",
    "            'recall': recall_score(y_val, preds),\n",
    "            'f1': f1_score(y_val, preds)\n",
    "        }\n",
    "        logger.info(f\"{name} - {metrics}\")\n",
    "        print(f\"\\n{name} Classification Report:\\n\", classification_report(y_val, preds))\n",
    "        print(f\"Confusion Matrix:\\n{confusion_matrix(y_val, preds)}\")\n",
    "        results[name] = model\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf45c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_random_forest(X_train, y_train):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'random_state': 42,\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        }\n",
    "\n",
    "        model = RandomForestClassifier(**params)\n",
    "        return cross_val_score(model, X_train, y_train, scoring='accuracy', cv=3).mean()\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=500)\n",
    "    logger.info(f\"Best RF params: {study.best_params}\")\n",
    "    return RandomForestClassifier(**study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c904937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_xgboost(X_train, y_train):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'random_state': 42,\n",
    "            'eval_metric': 'logloss',\n",
    "            'use_label_encoder': False\n",
    "        }\n",
    "        model = XGBClassifier(**params)\n",
    "        return cross_val_score(model, X_train, y_train, scoring='accuracy', cv=3).mean()\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=500)\n",
    "    logger.info(f\"Best XGBoost params: {study.best_params}\")\n",
    "    return XGBClassifier(**study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "450af27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_log_model(model, scaler, run, filename='final_model.pkl'):\n",
    "    joblib.dump((model, scaler), filename)\n",
    "    artifact = wandb.Artifact(name=filename, type='model')\n",
    "    artifact.add_file(filename)\n",
    "    run.log_artifact(artifact)\n",
    "    logger.info(f\"Đã lưu mô hình và scaler vào W&B: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51be735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmlcolongmay\u001b[0m (\u001b[33mmlcolongmay-neu\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.5s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\FINAL\\diabetes_project_MLOPS\\diabetes_project_MLOPS\\wandb\\run-20250504_013211-mvf6bi6e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes/runs/mvf6bi6e' target=\"_blank\">pious-dust-105</a></strong> to <a href='https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes' target=\"_blank\">https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes/runs/mvf6bi6e' target=\"_blank\">https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes/runs/mvf6bi6e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "04-05-2025 01:32:21 Tập dữ liệu đã load với shape: (537, 9)\n",
      "04-05-2025 01:32:21 Train shape: (429, 8), Validation shape: (108, 8)\n",
      "04-05-2025 01:32:21 After SMOTE - Counts: {0: 280, 1: 280}\n",
      "04-05-2025 01:32:21 Logistic Regression - {'accuracy': 0.7592592592592593, 'precision': 0.6304347826086957, 'recall': 0.7631578947368421, 'f1': 0.6904761904761905}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80        70\n",
      "           1       0.63      0.76      0.69        38\n",
      "\n",
      "    accuracy                           0.76       108\n",
      "   macro avg       0.74      0.76      0.75       108\n",
      "weighted avg       0.78      0.76      0.76       108\n",
      "\n",
      "Confusion Matrix:\n",
      "[[53 17]\n",
      " [ 9 29]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04-05-2025 01:32:21 Random Forest - {'accuracy': 0.7222222222222222, 'precision': 0.5833333333333334, 'recall': 0.7368421052631579, 'f1': 0.6511627906976745}\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "04-05-2025 01:32:22 XGBoost - {'accuracy': 0.7592592592592593, 'precision': 0.6363636363636364, 'recall': 0.7368421052631579, 'f1': 0.6829268292682927}\n",
      "[I 2025-05-04 01:32:22,064] A new study created in memory with name: no-name-2c373510-5e08-40b4-bfa4-0f08dd639e37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77        70\n",
      "           1       0.58      0.74      0.65        38\n",
      "\n",
      "    accuracy                           0.72       108\n",
      "   macro avg       0.71      0.73      0.71       108\n",
      "weighted avg       0.75      0.72      0.73       108\n",
      "\n",
      "Confusion Matrix:\n",
      "[[50 20]\n",
      " [10 28]]\n",
      "\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.81        70\n",
      "           1       0.64      0.74      0.68        38\n",
      "\n",
      "    accuracy                           0.76       108\n",
      "   macro avg       0.74      0.75      0.74       108\n",
      "weighted avg       0.77      0.76      0.76       108\n",
      "\n",
      "Confusion Matrix:\n",
      "[[54 16]\n",
      " [10 28]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:22,469] Trial 0 finished with value: 0.8036148965940239 and parameters: {'n_estimators': 240, 'max_depth': 6, 'learning_rate': 0.04533708597845657, 'subsample': 0.7416473093401365, 'colsample_bytree': 0.8756308415904429, 'gamma': 3.788204738444315, 'min_child_weight': 5}. Best is trial 0 with value: 0.8036148965940239.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:22,745] Trial 1 finished with value: 0.801803614896594 and parameters: {'n_estimators': 156, 'max_depth': 3, 'learning_rate': 0.22956573608142528, 'subsample': 0.6804308352788577, 'colsample_bytree': 0.9920440945022269, 'gamma': 2.4647823537662035, 'min_child_weight': 2}. Best is trial 0 with value: 0.8036148965940239.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:23,340] Trial 2 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 288, 'max_depth': 8, 'learning_rate': 0.02370756212953873, 'subsample': 0.7773370320663158, 'colsample_bytree': 0.9464580290369907, 'gamma': 1.9072623518712044, 'min_child_weight': 3}. Best is trial 2 with value: 0.8125658865696818.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:23,626] Trial 3 finished with value: 0.7768385946754067 and parameters: {'n_estimators': 194, 'max_depth': 7, 'learning_rate': 0.29159651305541, 'subsample': 0.6580215333757008, 'colsample_bytree': 0.9221534813644003, 'gamma': 4.248508688401731, 'min_child_weight': 10}. Best is trial 2 with value: 0.8125658865696818.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:23,936] Trial 4 finished with value: 0.8018802829049508 and parameters: {'n_estimators': 209, 'max_depth': 10, 'learning_rate': 0.08955243205355512, 'subsample': 0.9927385279625587, 'colsample_bytree': 0.8157134695399794, 'gamma': 1.775655534277651, 'min_child_weight': 6}. Best is trial 2 with value: 0.8125658865696818.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:24,257] Trial 5 finished with value: 0.7929101259272038 and parameters: {'n_estimators': 221, 'max_depth': 6, 'learning_rate': 0.09480315920195932, 'subsample': 0.6737694872514742, 'colsample_bytree': 0.7994814394895174, 'gamma': 4.4437482710715095, 'min_child_weight': 8}. Best is trial 2 with value: 0.8125658865696818.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:24,529] Trial 6 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 156, 'max_depth': 7, 'learning_rate': 0.16648945011838573, 'subsample': 0.8980512265338936, 'colsample_bytree': 0.7527863753598839, 'gamma': 2.7042775522892977, 'min_child_weight': 1}. Best is trial 2 with value: 0.8125658865696818.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:25,412] Trial 7 finished with value: 0.7875337818411822 and parameters: {'n_estimators': 150, 'max_depth': 8, 'learning_rate': 0.29546117128682203, 'subsample': 0.8054468557112152, 'colsample_bytree': 0.6231160965886575, 'gamma': 2.8637583311707475, 'min_child_weight': 9}. Best is trial 2 with value: 0.8125658865696818.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:26,372] Trial 8 finished with value: 0.7786498763728366 and parameters: {'n_estimators': 239, 'max_depth': 8, 'learning_rate': 0.23404685845033982, 'subsample': 0.819330133900509, 'colsample_bytree': 0.7200518634915177, 'gamma': 0.41799382511109706, 'min_child_weight': 7}. Best is trial 2 with value: 0.8125658865696818.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:26,794] Trial 9 finished with value: 0.7946830736204551 and parameters: {'n_estimators': 135, 'max_depth': 6, 'learning_rate': 0.054201886399918714, 'subsample': 0.9796069650866882, 'colsample_bytree': 0.7147667389243366, 'gamma': 2.7103130003951588, 'min_child_weight': 10}. Best is trial 2 with value: 0.8125658865696818.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:35,939] Trial 10 finished with value: 0.7929101259272038 and parameters: {'n_estimators': 299, 'max_depth': 10, 'learning_rate': 0.1447523821259831, 'subsample': 0.8647568071236991, 'colsample_bytree': 0.9847635107012067, 'gamma': 0.6984418674762904, 'min_child_weight': 4}. Best is trial 2 with value: 0.8125658865696818.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:36,479] Trial 11 finished with value: 0.8036436470971576 and parameters: {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.1725407955665299, 'subsample': 0.9094391510515276, 'colsample_bytree': 0.752760665297916, 'gamma': 1.5143217563967064, 'min_child_weight': 1}. Best is trial 2 with value: 0.8125658865696818.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:37,821] Trial 12 finished with value: 0.8108312728806087 and parameters: {'n_estimators': 287, 'max_depth': 8, 'learning_rate': 0.012884614255462556, 'subsample': 0.9116486589215874, 'colsample_bytree': 0.8693165340231757, 'gamma': 1.6390369527808204, 'min_child_weight': 3}. Best is trial 2 with value: 0.8125658865696818.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:42,119] Trial 13 finished with value: 0.8250915224349759 and parameters: {'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.011380127318201833, 'subsample': 0.7446844002960997, 'colsample_bytree': 0.9099627182567733, 'gamma': 1.3558647062645282, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:43,782] Trial 14 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 267, 'max_depth': 9, 'learning_rate': 0.010454666839901153, 'subsample': 0.7439412121562738, 'colsample_bytree': 0.9339122411434544, 'gamma': 0.9887992018075209, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:45,312] Trial 15 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 262, 'max_depth': 9, 'learning_rate': 0.10241678753326151, 'subsample': 0.7290361320803346, 'colsample_bytree': 0.8956767853291123, 'gamma': 0.9542856366573654, 'min_child_weight': 4}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:46,336] Trial 16 finished with value: 0.7946926571214997 and parameters: {'n_estimators': 265, 'max_depth': 9, 'learning_rate': 0.06721398264353934, 'subsample': 0.6103107564438183, 'colsample_bytree': 0.8281340647740361, 'gamma': 0.13175335876703742, 'min_child_weight': 5}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:47,661] Trial 17 finished with value: 0.7839687194525903 and parameters: {'n_estimators': 262, 'max_depth': 9, 'learning_rate': 0.1345569202731509, 'subsample': 0.7580567525647499, 'colsample_bytree': 0.9459227275723832, 'gamma': 0.9804399827738348, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:49,248] Trial 18 finished with value: 0.8215072930442949 and parameters: {'n_estimators': 279, 'max_depth': 10, 'learning_rate': 0.02956001627877081, 'subsample': 0.7119287095267403, 'colsample_bytree': 0.8592795814294867, 'gamma': 1.2279026946534777, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:55,201] Trial 19 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 191, 'max_depth': 10, 'learning_rate': 0.042149276451298026, 'subsample': 0.7045581204177818, 'colsample_bytree': 0.84689537076711, 'gamma': 3.2561620341500834, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:57,489] Trial 20 finished with value: 0.7982960535142699 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.11940641039826252, 'subsample': 0.6405465417880689, 'colsample_bytree': 0.6045323376388472, 'gamma': 2.23058522483601, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:32:58,976] Trial 21 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 275, 'max_depth': 9, 'learning_rate': 0.012831755695189948, 'subsample': 0.7115008919420559, 'colsample_bytree': 0.9119866605782024, 'gamma': 1.2640602149380276, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:32:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:00,568] Trial 22 finished with value: 0.803634063596113 and parameters: {'n_estimators': 243, 'max_depth': 10, 'learning_rate': 0.06152416911398985, 'subsample': 0.8352614076903312, 'colsample_bytree': 0.95166893329266, 'gamma': 0.03701435172472323, 'min_child_weight': 4}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:01,879] Trial 23 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 278, 'max_depth': 9, 'learning_rate': 0.03331931434736308, 'subsample': 0.7660464291455242, 'colsample_bytree': 0.861142562142946, 'gamma': 1.2453864670059347, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:02,782] Trial 24 finished with value: 0.7911563452360416 and parameters: {'n_estimators': 256, 'max_depth': 10, 'learning_rate': 0.07455305030733705, 'subsample': 0.7020778918590556, 'colsample_bytree': 0.899277280035497, 'gamma': 0.6473322598620131, 'min_child_weight': 6}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:03,793] Trial 25 finished with value: 0.8054453452935427 and parameters: {'n_estimators': 224, 'max_depth': 7, 'learning_rate': 0.010419404055101507, 'subsample': 0.7883051062697594, 'colsample_bytree': 0.7893667866443004, 'gamma': 2.123229261626981, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:04,770] Trial 26 finished with value: 0.8018706994039063 and parameters: {'n_estimators': 284, 'max_depth': 9, 'learning_rate': 0.03667633756274046, 'subsample': 0.7417433884192386, 'colsample_bytree': 0.9624959656178512, 'gamma': 1.2877736095721617, 'min_child_weight': 4}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:05,396] Trial 27 finished with value: 0.8036053130929792 and parameters: {'n_estimators': 252, 'max_depth': 8, 'learning_rate': 0.20911176464463102, 'subsample': 0.6254393847836237, 'colsample_bytree': 0.9239375130231146, 'gamma': 4.939480888422814, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:09,006] Trial 28 finished with value: 0.8036628140992468 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.0780853880312028, 'subsample': 0.8463546253631316, 'colsample_bytree': 0.880541473167334, 'gamma': 0.44890345715656177, 'min_child_weight': 5}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:09,859] Trial 29 finished with value: 0.810802522377475 and parameters: {'n_estimators': 236, 'max_depth': 9, 'learning_rate': 0.04478326098259397, 'subsample': 0.7410055541087811, 'colsample_bytree': 0.8419536515678058, 'gamma': 1.0512391996466315, 'min_child_weight': 5}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:10,541] Trial 30 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 273, 'max_depth': 5, 'learning_rate': 0.10911286941595574, 'subsample': 0.7181317996845412, 'colsample_bytree': 0.9716580580636581, 'gamma': 3.2858915493791567, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:12,083] Trial 31 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 274, 'max_depth': 9, 'learning_rate': 0.012518644136453096, 'subsample': 0.688718744441199, 'colsample_bytree': 0.911448524593238, 'gamma': 1.4196927261409844, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:13,695] Trial 32 finished with value: 0.8036436470971576 and parameters: {'n_estimators': 287, 'max_depth': 10, 'learning_rate': 0.026265156513684135, 'subsample': 0.6698998291360758, 'colsample_bytree': 0.8909801969679157, 'gamma': 0.78164893382214, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:14,498] Trial 33 finished with value: 0.8126138040749047 and parameters: {'n_estimators': 271, 'max_depth': 8, 'learning_rate': 0.05625046883460573, 'subsample': 0.7570210770424182, 'colsample_bytree': 0.9989374011970524, 'gamma': 1.9828058270063105, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:15,845] Trial 34 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 252, 'max_depth': 9, 'learning_rate': 0.021825754407726446, 'subsample': 0.72259690884291, 'colsample_bytree': 0.9360384770064124, 'gamma': 1.1771642883236204, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:17,082] Trial 35 finished with value: 0.8161788664634965 and parameters: {'n_estimators': 290, 'max_depth': 7, 'learning_rate': 0.03336360430525172, 'subsample': 0.7916506002108614, 'colsample_bytree': 0.9279596757886309, 'gamma': 1.7293716532875871, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:17,922] Trial 36 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 291, 'max_depth': 3, 'learning_rate': 0.0387418773134395, 'subsample': 0.7867265161357699, 'colsample_bytree': 0.8656257910132575, 'gamma': 1.7828551261586068, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:18,575] Trial 37 finished with value: 0.8126042205738601 and parameters: {'n_estimators': 184, 'max_depth': 7, 'learning_rate': 0.054263989863923605, 'subsample': 0.8072155320978779, 'colsample_bytree': 0.9284031696764499, 'gamma': 2.2954923430908236, 'min_child_weight': 4}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:19,296] Trial 38 finished with value: 0.8018515324018171 and parameters: {'n_estimators': 211, 'max_depth': 7, 'learning_rate': 0.0824074191797816, 'subsample': 0.6529948340961556, 'colsample_bytree': 0.976601376575766, 'gamma': 1.6353298362055715, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:20,104] Trial 39 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 228, 'max_depth': 6, 'learning_rate': 0.027629796935289774, 'subsample': 0.7682898336472389, 'colsample_bytree': 0.8175202008925295, 'gamma': 1.9254545207232767, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:20,601] Trial 40 finished with value: 0.8000785847085657 and parameters: {'n_estimators': 174, 'max_depth': 8, 'learning_rate': 0.23967023459644954, 'subsample': 0.8789574500713074, 'colsample_bytree': 0.7782089005752015, 'gamma': 2.4536158128394985, 'min_child_weight': 7}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:22,599] Trial 41 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 281, 'max_depth': 10, 'learning_rate': 0.010172520965231323, 'subsample': 0.6968374461257258, 'colsample_bytree': 0.9269992144362258, 'gamma': 1.4059161920880086, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:23,725] Trial 42 finished with value: 0.8197151783489544 and parameters: {'n_estimators': 292, 'max_depth': 10, 'learning_rate': 0.02627446940212308, 'subsample': 0.6942740233371506, 'colsample_bytree': 0.9520830645260465, 'gamma': 1.464606916740765, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:26,798] Trial 43 finished with value: 0.7911371782339525 and parameters: {'n_estimators': 282, 'max_depth': 10, 'learning_rate': 0.049846032499957664, 'subsample': 0.6918498567318849, 'colsample_bytree': 0.9581321200869154, 'gamma': 0.4205455696423662, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:30,436] Trial 44 finished with value: 0.8107737718743412 and parameters: {'n_estimators': 294, 'max_depth': 10, 'learning_rate': 0.025948620367581547, 'subsample': 0.6708685423621689, 'colsample_bytree': 0.9102568680749429, 'gamma': 0.8630949350130535, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:32,757] Trial 45 finished with value: 0.810802522377475 and parameters: {'n_estimators': 267, 'max_depth': 10, 'learning_rate': 0.010029122191596724, 'subsample': 0.7367386098408084, 'colsample_bytree': 0.8839682662565109, 'gamma': 1.4825173606325306, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:34,021] Trial 46 finished with value: 0.7786211258697028 and parameters: {'n_estimators': 242, 'max_depth': 10, 'learning_rate': 0.26875190288799544, 'subsample': 0.645146910766147, 'colsample_bytree': 0.988637402917251, 'gamma': 0.5969115461950092, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:35,616] Trial 47 finished with value: 0.8000785847085657 and parameters: {'n_estimators': 284, 'max_depth': 9, 'learning_rate': 0.1966756492771405, 'subsample': 0.6751704997913628, 'colsample_bytree': 0.9410229235892964, 'gamma': 1.0371131609081228, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:37,808] Trial 48 finished with value: 0.7732831157878596 and parameters: {'n_estimators': 263, 'max_depth': 10, 'learning_rate': 0.06295897714265528, 'subsample': 0.6019017363016353, 'colsample_bytree': 0.850361048775593, 'gamma': 0.16626909991257532, 'min_child_weight': 9}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:39,404] Trial 49 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 293, 'max_depth': 9, 'learning_rate': 0.021575854362100348, 'subsample': 0.7527104256602342, 'colsample_bytree': 0.6535684009331995, 'gamma': 1.4432425499875898, 'min_child_weight': 4}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:40,395] Trial 50 finished with value: 0.7947214076246335 and parameters: {'n_estimators': 253, 'max_depth': 8, 'learning_rate': 0.09563730991488165, 'subsample': 0.6989407669160158, 'colsample_bytree': 0.9011109995802093, 'gamma': 1.9961354847256922, 'min_child_weight': 6}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:41,794] Trial 51 finished with value: 0.8036628140992468 and parameters: {'n_estimators': 293, 'max_depth': 10, 'learning_rate': 0.04070463167053111, 'subsample': 0.7792113519387627, 'colsample_bytree': 0.9297006236389719, 'gamma': 1.70569613293881, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:33:44,108] Trial 52 finished with value: 0.8054453452935427 and parameters: {'n_estimators': 280, 'max_depth': 5, 'learning_rate': 0.03074546811117873, 'subsample': 0.8197776674415655, 'colsample_bytree': 0.9573222731162817, 'gamma': 1.797927099841492, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:33:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:34:33,431] Trial 53 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 107, 'max_depth': 9, 'learning_rate': 0.04715516762899814, 'subsample': 0.7173867300030625, 'colsample_bytree': 0.9174431317175019, 'gamma': 1.1064333402265623, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:34:39,246] Trial 54 finished with value: 0.8036628140992468 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.02378401947762656, 'subsample': 0.9523759985322084, 'colsample_bytree': 0.944245479724701, 'gamma': 1.379348638012052, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:34:40,122] Trial 55 finished with value: 0.807218292986794 and parameters: {'n_estimators': 280, 'max_depth': 10, 'learning_rate': 0.0728910370151772, 'subsample': 0.7485234716677502, 'colsample_bytree': 0.9697097853260308, 'gamma': 1.5826314611907604, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:34:41,466] Trial 56 finished with value: 0.8072374599888832 and parameters: {'n_estimators': 290, 'max_depth': 9, 'learning_rate': 0.019085155803427567, 'subsample': 0.8023560624720771, 'colsample_bytree': 0.8797173195833004, 'gamma': 0.8760930137001917, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:34:42,054] Trial 57 finished with value: 0.803634063596113 and parameters: {'n_estimators': 269, 'max_depth': 8, 'learning_rate': 0.03416279528011953, 'subsample': 0.7310352566250078, 'colsample_bytree': 0.9300665914527864, 'gamma': 2.7857466984454273, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:34:42,576] Trial 58 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 259, 'max_depth': 9, 'learning_rate': 0.0651215853405056, 'subsample': 0.6871803332684794, 'colsample_bytree': 0.9036248202704298, 'gamma': 2.5337504401797304, 'min_child_weight': 4}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:34:43,516] Trial 59 finished with value: 0.7929197094282484 and parameters: {'n_estimators': 276, 'max_depth': 10, 'learning_rate': 0.1528199735446698, 'subsample': 0.6308716288740128, 'colsample_bytree': 0.9810655682417871, 'gamma': 1.2188066093932328, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:34:44,284] Trial 60 finished with value: 0.8000785847085657 and parameters: {'n_estimators': 286, 'max_depth': 4, 'learning_rate': 0.04768690841913423, 'subsample': 0.7696411353288264, 'colsample_bytree': 0.8306825495591261, 'gamma': 0.5956965325666133, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:34:45,267] Trial 61 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 275, 'max_depth': 9, 'learning_rate': 0.015704037702102557, 'subsample': 0.7119920771855397, 'colsample_bytree': 0.9497386849402768, 'gamma': 1.319573054930532, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:34:47,252] Trial 62 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 295, 'max_depth': 10, 'learning_rate': 0.0114305783313508, 'subsample': 0.7061939352321474, 'colsample_bytree': 0.915625242678937, 'gamma': 1.152574816205941, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:34:48,492] Trial 63 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 268, 'max_depth': 9, 'learning_rate': 0.030877028935224624, 'subsample': 0.7280709443109687, 'colsample_bytree': 0.8928251913575982, 'gamma': 1.5594088110215545, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:34:54,440] Trial 64 finished with value: 0.7982768865121807 and parameters: {'n_estimators': 247, 'max_depth': 8, 'learning_rate': 0.038200033873169004, 'subsample': 0.6611080145211602, 'colsample_bytree': 0.8672781037552625, 'gamma': 0.7386185201955751, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:34:58,333] Trial 65 finished with value: 0.816169282962452 and parameters: {'n_estimators': 287, 'max_depth': 7, 'learning_rate': 0.019200114064795354, 'subsample': 0.6824366996791453, 'colsample_bytree': 0.9217566491175502, 'gamma': 0.9468497042568963, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:34:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:03,530] Trial 66 finished with value: 0.8036244800950684 and parameters: {'n_estimators': 284, 'max_depth': 7, 'learning_rate': 0.02175370405133935, 'subsample': 0.6837303940094582, 'colsample_bytree': 0.9627040698187013, 'gamma': 3.8827691514598497, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:06,802] Trial 67 finished with value: 0.8018419489007725 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.05654531527424814, 'subsample': 0.6618202664959545, 'colsample_bytree': 0.9388996967004792, 'gamma': 0.27164284116945914, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:07,946] Trial 68 finished with value: 0.8179326471546585 and parameters: {'n_estimators': 290, 'max_depth': 6, 'learning_rate': 0.03479319520989267, 'subsample': 0.6986427216750455, 'colsample_bytree': 0.8543124539116695, 'gamma': 0.9786982445224849, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:08,931] Trial 69 finished with value: 0.8054453452935427 and parameters: {'n_estimators': 294, 'max_depth': 6, 'learning_rate': 0.12393024152293426, 'subsample': 0.699316581989878, 'colsample_bytree': 0.8537368013100647, 'gamma': 2.0993411384634237, 'min_child_weight': 4}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:09,568] Trial 70 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 259, 'max_depth': 5, 'learning_rate': 0.042366357036499144, 'subsample': 0.744579568692002, 'colsample_bytree': 0.8057444544207717, 'gamma': 1.8515794493446502, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:13,395] Trial 71 finished with value: 0.803634063596113 and parameters: {'n_estimators': 289, 'max_depth': 6, 'learning_rate': 0.03207947321997334, 'subsample': 0.7214896280444483, 'colsample_bytree': 0.9239266023106814, 'gamma': 0.9527671089309918, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:17,841] Trial 72 finished with value: 0.817923063653614 and parameters: {'n_estimators': 279, 'max_depth': 6, 'learning_rate': 0.01963942665513055, 'subsample': 0.6928796375374286, 'colsample_bytree': 0.8359049833184179, 'gamma': 1.0449141152706494, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:21,034] Trial 73 finished with value: 0.8179518141567478 and parameters: {'n_estimators': 280, 'max_depth': 6, 'learning_rate': 0.03569468866040655, 'subsample': 0.6960662507855987, 'colsample_bytree': 0.8368283180990618, 'gamma': 1.3577731310114978, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:22,976] Trial 74 finished with value: 0.8197151783489544 and parameters: {'n_estimators': 278, 'max_depth': 6, 'learning_rate': 0.017109538168696335, 'subsample': 0.6924144666481306, 'colsample_bytree': 0.8355918512449131, 'gamma': 0.777234906909384, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:27,695] Trial 75 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 273, 'max_depth': 5, 'learning_rate': 0.010615038891922734, 'subsample': 0.702558807375435, 'colsample_bytree': 0.8167530324954458, 'gamma': 0.789480012677521, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:30,675] Trial 76 finished with value: 0.8072087094857494 and parameters: {'n_estimators': 266, 'max_depth': 6, 'learning_rate': 0.05084622891536851, 'subsample': 0.7117690445720798, 'colsample_bytree': 0.787924835807944, 'gamma': 0.5686575681773997, 'min_child_weight': 5}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:31,517] Trial 77 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 279, 'max_depth': 6, 'learning_rate': 0.028225348443427084, 'subsample': 0.6697508652134397, 'colsample_bytree': 0.8610426718436113, 'gamma': 0.31448763518894807, 'min_child_weight': 4}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:32,334] Trial 78 finished with value: 0.8018515324018171 and parameters: {'n_estimators': 211, 'max_depth': 5, 'learning_rate': 0.08857024806391198, 'subsample': 0.729733804743213, 'colsample_bytree': 0.8425102141592438, 'gamma': 1.3172512722992666, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:33,216] Trial 79 finished with value: 0.7947022406225442 and parameters: {'n_estimators': 138, 'max_depth': 6, 'learning_rate': 0.17348750563982734, 'subsample': 0.6522940971326369, 'colsample_bytree': 0.7702322133580253, 'gamma': 1.1443312198163529, 'min_child_weight': 4}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:35,732] Trial 80 finished with value: 0.8125563030686371 and parameters: {'n_estimators': 296, 'max_depth': 10, 'learning_rate': 0.03840064569645748, 'subsample': 0.6785674258852215, 'colsample_bytree': 0.8195088775355083, 'gamma': 3.0237273855801603, 'min_child_weight': 4}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:41,108] Trial 81 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 279, 'max_depth': 6, 'learning_rate': 0.019603441691058557, 'subsample': 0.6995066864158094, 'colsample_bytree': 0.8314152415158734, 'gamma': 1.0350502839822089, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:46,373] Trial 82 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 272, 'max_depth': 6, 'learning_rate': 0.016508512214959345, 'subsample': 0.6872306334657021, 'colsample_bytree': 0.8021179426730236, 'gamma': 1.473355274504283, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:47,099] Trial 83 finished with value: 0.8197055948479098 and parameters: {'n_estimators': 234, 'max_depth': 6, 'learning_rate': 0.026473099385319106, 'subsample': 0.6375195539087214, 'colsample_bytree': 0.8076602530583604, 'gamma': 1.4898502541915053, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:47,820] Trial 84 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 204, 'max_depth': 5, 'learning_rate': 0.010416937428829223, 'subsample': 0.6195918445092581, 'colsample_bytree': 0.7521992136243063, 'gamma': 1.5186288642081769, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:48,580] Trial 85 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 261, 'max_depth': 6, 'learning_rate': 0.02522031908841034, 'subsample': 0.6342687364264569, 'colsample_bytree': 0.7655498290314358, 'gamma': 1.4047846788903269, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:49,332] Trial 86 finished with value: 0.8197151783489546 and parameters: {'n_estimators': 235, 'max_depth': 7, 'learning_rate': 0.01700754178635767, 'subsample': 0.6474181038582084, 'colsample_bytree': 0.8048294247427485, 'gamma': 1.2587073588784652, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:50,008] Trial 87 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 235, 'max_depth': 10, 'learning_rate': 0.028610048975471685, 'subsample': 0.6508880524950341, 'colsample_bytree': 0.8098759727520067, 'gamma': 1.262000705063135, 'min_child_weight': 4}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:50,589] Trial 88 finished with value: 0.8125563030686371 and parameters: {'n_estimators': 219, 'max_depth': 7, 'learning_rate': 0.04447894623946112, 'subsample': 0.6624619928528666, 'colsample_bytree': 0.8736051982928508, 'gamma': 1.6108390916542856, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:51,479] Trial 89 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 233, 'max_depth': 4, 'learning_rate': 0.05924846132550282, 'subsample': 0.6421582128324953, 'colsample_bytree': 0.7966890974759896, 'gamma': 1.6961279278262116, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:52,223] Trial 90 finished with value: 0.8071991259847048 and parameters: {'n_estimators': 193, 'max_depth': 10, 'learning_rate': 0.01749111989318907, 'subsample': 0.6049376538159716, 'colsample_bytree': 0.7867703310041125, 'gamma': 0.6892631744211665, 'min_child_weight': 5}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:53,015] Trial 91 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 271, 'max_depth': 6, 'learning_rate': 0.017655748668771086, 'subsample': 0.622977192734857, 'colsample_bytree': 0.8033000533042828, 'gamma': 1.3725096110781927, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:54,439] Trial 92 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 245, 'max_depth': 7, 'learning_rate': 0.027656493963541303, 'subsample': 0.6735200952305442, 'colsample_bytree': 0.8220790940832273, 'gamma': 1.5067046957484884, 'min_child_weight': 4}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:55,459] Trial 93 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 251, 'max_depth': 6, 'learning_rate': 0.01572273290487347, 'subsample': 0.7396021900815228, 'colsample_bytree': 0.7326470575006658, 'gamma': 1.1972981940907894, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:56,943] Trial 94 finished with value: 0.8089912406800454 and parameters: {'n_estimators': 255, 'max_depth': 10, 'learning_rate': 0.03771241764503576, 'subsample': 0.7375711058985454, 'colsample_bytree': 0.7322432283323029, 'gamma': 0.8160620768162339, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:35:58,171] Trial 95 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 229, 'max_depth': 5, 'learning_rate': 0.025761797675561218, 'subsample': 0.7587340217178199, 'colsample_bytree': 0.6706813395292258, 'gamma': 1.134192331682422, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:35:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:02,112] Trial 96 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 249, 'max_depth': 10, 'learning_rate': 0.01004615294902646, 'subsample': 0.7191576553169982, 'colsample_bytree': 0.6994628463011796, 'gamma': 1.2258133691227093, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:07,501] Trial 97 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 239, 'max_depth': 9, 'learning_rate': 0.06879605481387441, 'subsample': 0.6147793297649011, 'colsample_bytree': 0.8894584337585283, 'gamma': 0.9057688466063947, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:08,499] Trial 98 finished with value: 0.7982768865121807 and parameters: {'n_estimators': 263, 'max_depth': 7, 'learning_rate': 0.04370804913638513, 'subsample': 0.7772792662456319, 'colsample_bytree': 0.8376891744225092, 'gamma': 0.5009342325872326, 'min_child_weight': 7}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:09,343] Trial 99 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 250, 'max_depth': 9, 'learning_rate': 0.033609584088486855, 'subsample': 0.7589812040936781, 'colsample_bytree': 0.7803176960252908, 'gamma': 1.9185578912939727, 'min_child_weight': 4}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:10,259] Trial 100 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 257, 'max_depth': 6, 'learning_rate': 0.050590902490930796, 'subsample': 0.7355491855462112, 'colsample_bytree': 0.8268182984288485, 'gamma': 1.6742400041970495, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:11,454] Trial 101 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 283, 'max_depth': 6, 'learning_rate': 0.014579853155999106, 'subsample': 0.6884683275241089, 'colsample_bytree': 0.7992851320421115, 'gamma': 1.3932799693185056, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:12,692] Trial 102 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 270, 'max_depth': 6, 'learning_rate': 0.016618112782807504, 'subsample': 0.7087023348070118, 'colsample_bytree': 0.8112518255231151, 'gamma': 1.2648575556735433, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:13,631] Trial 103 finished with value: 0.8215072930442949 and parameters: {'n_estimators': 217, 'max_depth': 6, 'learning_rate': 0.023934714977652552, 'subsample': 0.7072680526696761, 'colsample_bytree': 0.810784207451934, 'gamma': 1.2932385630297212, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:14,648] Trial 104 finished with value: 0.810802522377475 and parameters: {'n_estimators': 241, 'max_depth': 6, 'learning_rate': 0.022493970491574936, 'subsample': 0.7275327661850494, 'colsample_bytree': 0.742088410136086, 'gamma': 1.0926764076193143, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:15,747] Trial 105 finished with value: 0.816169282962452 and parameters: {'n_estimators': 220, 'max_depth': 5, 'learning_rate': 0.02378687642839046, 'subsample': 0.7468511150527779, 'colsample_bytree': 0.9057754940697164, 'gamma': 1.7947133078792894, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:16,733] Trial 106 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 215, 'max_depth': 8, 'learning_rate': 0.03455547019966386, 'subsample': 0.7186214137717926, 'colsample_bytree': 0.8435053125148386, 'gamma': 1.1916162946912439, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:17,470] Trial 107 finished with value: 0.7929197094282484 and parameters: {'n_estimators': 227, 'max_depth': 10, 'learning_rate': 0.2872374981964119, 'subsample': 0.6670917526692567, 'colsample_bytree': 0.96867246491721, 'gamma': 1.573709600031544, 'min_child_weight': 4}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:18,287] Trial 108 finished with value: 0.7964751883157956 and parameters: {'n_estimators': 224, 'max_depth': 6, 'learning_rate': 0.041900203175946504, 'subsample': 0.694248667437199, 'colsample_bytree': 0.9510295864317725, 'gamma': 1.3269740144099926, 'min_child_weight': 8}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:19,936] Trial 109 finished with value: 0.8107737718743412 and parameters: {'n_estimators': 297, 'max_depth': 9, 'learning_rate': 0.02980304179360731, 'subsample': 0.7078163817782045, 'colsample_bytree': 0.7690979607987711, 'gamma': 0.7089244546998299, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:20,824] Trial 110 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 204, 'max_depth': 6, 'learning_rate': 0.05388873925712039, 'subsample': 0.7120102824630186, 'colsample_bytree': 0.7061510356579825, 'gamma': 0.9056483551062653, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:21,985] Trial 111 finished with value: 0.8197151783489546 and parameters: {'n_estimators': 267, 'max_depth': 6, 'learning_rate': 0.01532613495421056, 'subsample': 0.6775277080108677, 'colsample_bytree': 0.7908576188515904, 'gamma': 1.2643424981502296, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:23,280] Trial 112 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 275, 'max_depth': 7, 'learning_rate': 0.01543379173473443, 'subsample': 0.63628741635799, 'colsample_bytree': 0.8243974317994843, 'gamma': 1.0943357888275425, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:24,363] Trial 113 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 265, 'max_depth': 6, 'learning_rate': 0.023071818031815374, 'subsample': 0.6789501804027479, 'colsample_bytree': 0.9334955498207377, 'gamma': 1.4318161159774645, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:25,584] Trial 114 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 283, 'max_depth': 6, 'learning_rate': 0.010469493582326943, 'subsample': 0.6504025547138076, 'colsample_bytree': 0.7946257135592987, 'gamma': 1.2144852188848394, 'min_child_weight': 4}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:27,155] Trial 115 finished with value: 0.8125563030686371 and parameters: {'n_estimators': 277, 'max_depth': 10, 'learning_rate': 0.03136684752605373, 'subsample': 0.6817726672411204, 'colsample_bytree': 0.8557758680522135, 'gamma': 0.9719448366452299, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:28,197] Trial 116 finished with value: 0.8197055948479098 and parameters: {'n_estimators': 232, 'max_depth': 7, 'learning_rate': 0.021460678578901868, 'subsample': 0.6557712672880212, 'colsample_bytree': 0.8350068018027333, 'gamma': 1.2968557540074173, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:28,955] Trial 117 finished with value: 0.8036053130929792 and parameters: {'n_estimators': 290, 'max_depth': 7, 'learning_rate': 0.02304459420892617, 'subsample': 0.6442000564115616, 'colsample_bytree': 0.8102807746133452, 'gamma': 4.936576579279742, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:29,865] Trial 118 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 233, 'max_depth': 8, 'learning_rate': 0.03992877618272739, 'subsample': 0.6603793538240471, 'colsample_bytree': 0.7794835493771557, 'gamma': 2.0616335333414426, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:30,730] Trial 119 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 184, 'max_depth': 7, 'learning_rate': 0.02807992307562525, 'subsample': 0.6706657503398048, 'colsample_bytree': 0.8488579821841579, 'gamma': 1.4926174196203588, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:31,818] Trial 120 finished with value: 0.8089816571790007 and parameters: {'n_estimators': 287, 'max_depth': 7, 'learning_rate': 0.04612739092972672, 'subsample': 0.694211621270595, 'colsample_bytree': 0.8340267434795545, 'gamma': 1.3265171243107876, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:32,964] Trial 121 finished with value: 0.8179230636536139 and parameters: {'n_estimators': 237, 'max_depth': 6, 'learning_rate': 0.016187061532733492, 'subsample': 0.7226835987384429, 'colsample_bytree': 0.8169127003217663, 'gamma': 1.0447692526077426, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:33,839] Trial 122 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 245, 'max_depth': 6, 'learning_rate': 0.020010502562544705, 'subsample': 0.7028682690691159, 'colsample_bytree': 0.686273972406585, 'gamma': 1.6261643664239125, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:34,786] Trial 123 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 232, 'max_depth': 6, 'learning_rate': 0.03440294199242181, 'subsample': 0.6785226305924812, 'colsample_bytree': 0.7596009613692201, 'gamma': 0.7982407007098908, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:36,312] Trial 124 finished with value: 0.7786498763728366 and parameters: {'n_estimators': 216, 'max_depth': 7, 'learning_rate': 0.015287487643776451, 'subsample': 0.6535846387757548, 'colsample_bytree': 0.6446820765711492, 'gamma': 1.2102454333079655, 'min_child_weight': 10}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:37,326] Trial 125 finished with value: 0.8197151783489544 and parameters: {'n_estimators': 267, 'max_depth': 10, 'learning_rate': 0.02632665148500957, 'subsample': 0.690022701569224, 'colsample_bytree': 0.7247081333945666, 'gamma': 1.3311105751342083, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:38,219] Trial 126 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 224, 'max_depth': 10, 'learning_rate': 0.025137595358893223, 'subsample': 0.6878562692045708, 'colsample_bytree': 0.8630452433056874, 'gamma': 1.3631370317204565, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:39,125] Trial 127 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 225, 'max_depth': 10, 'learning_rate': 0.03705816001837434, 'subsample': 0.629433651916954, 'colsample_bytree': 0.8619887188719539, 'gamma': 1.3782827693853985, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:39,896] Trial 128 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 207, 'max_depth': 10, 'learning_rate': 0.026905464516291444, 'subsample': 0.6660947482134093, 'colsample_bytree': 0.873412912439211, 'gamma': 1.7495293509838743, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:40,582] Trial 129 finished with value: 0.7857416671458418 and parameters: {'n_estimators': 268, 'max_depth': 10, 'learning_rate': 0.24542099657442967, 'subsample': 0.6905121237014407, 'colsample_bytree': 0.8439380346771264, 'gamma': 1.532503505066693, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:41,666] Trial 130 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 218, 'max_depth': 10, 'learning_rate': 0.022829682643292507, 'subsample': 0.6562662664427791, 'colsample_bytree': 0.8305583241392058, 'gamma': 1.014298207067501, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:42,974] Trial 131 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 222, 'max_depth': 10, 'learning_rate': 0.010369189751560174, 'subsample': 0.6849358154389473, 'colsample_bytree': 0.8838550124902218, 'gamma': 1.4301136534450307, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:43,969] Trial 132 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 229, 'max_depth': 10, 'learning_rate': 0.0292775604189044, 'subsample': 0.6752552107977955, 'colsample_bytree': 0.9395565002521262, 'gamma': 1.316320123727813, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:45,160] Trial 133 finished with value: 0.8143388342629331 and parameters: {'n_estimators': 281, 'max_depth': 10, 'learning_rate': 0.021321540358290564, 'subsample': 0.7017251139389803, 'colsample_bytree': 0.7918649006681162, 'gamma': 1.1258588968203558, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:46,032] Trial 134 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.034016746358968605, 'subsample': 0.6937232997045092, 'colsample_bytree': 0.9128841771781683, 'gamma': 1.6410918867534297, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:47,323] Trial 135 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 292, 'max_depth': 10, 'learning_rate': 0.017802912914842428, 'subsample': 0.7131198392491296, 'colsample_bytree': 0.8399011231191351, 'gamma': 1.3003894843796704, 'min_child_weight': 1}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:48,553] Trial 136 finished with value: 0.817923063653614 and parameters: {'n_estimators': 286, 'max_depth': 10, 'learning_rate': 0.027005064620796774, 'subsample': 0.6408454868298956, 'colsample_bytree': 0.8249482964043312, 'gamma': 0.8542867442019232, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:49,562] Trial 137 finished with value: 0.7839591359515458 and parameters: {'n_estimators': 213, 'max_depth': 9, 'learning_rate': 0.20767030969303268, 'subsample': 0.6727025177238091, 'colsample_bytree': 0.8681845491584158, 'gamma': 1.4472779165396332, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:50,180] Trial 138 finished with value: 0.7911467617349971 and parameters: {'n_estimators': 161, 'max_depth': 8, 'learning_rate': 0.04000363348353567, 'subsample': 0.9832977759399627, 'colsample_bytree': 0.813156387386114, 'gamma': 3.5762089219560025, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:51,472] Trial 139 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 275, 'max_depth': 10, 'learning_rate': 0.01047436673462581, 'subsample': 0.6817491430432757, 'colsample_bytree': 0.9593121080119014, 'gamma': 1.870507152429289, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:52,738] Trial 140 finished with value: 0.816169282962452 and parameters: {'n_estimators': 297, 'max_depth': 10, 'learning_rate': 0.020748845707859752, 'subsample': 0.7056780661119904, 'colsample_bytree': 0.8984997468209883, 'gamma': 1.099836209425559, 'min_child_weight': 2}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:53,811] Trial 141 finished with value: 0.8215072930442949 and parameters: {'n_estimators': 260, 'max_depth': 6, 'learning_rate': 0.01529989679136786, 'subsample': 0.7355187387234025, 'colsample_bytree': 0.7406044557175049, 'gamma': 1.2257916043642578, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:54,927] Trial 142 finished with value: 0.819724761849999 and parameters: {'n_estimators': 259, 'max_depth': 6, 'learning_rate': 0.01585625945902908, 'subsample': 0.7319292995429315, 'colsample_bytree': 0.7186270356097912, 'gamma': 1.284038002124129, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:55,878] Trial 143 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 260, 'max_depth': 6, 'learning_rate': 0.029686864143677428, 'subsample': 0.7297525824768711, 'colsample_bytree': 0.7203037183226718, 'gamma': 1.2836068835031929, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:57,080] Trial 144 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 267, 'max_depth': 6, 'learning_rate': 0.015377683709540218, 'subsample': 0.7504618017866197, 'colsample_bytree': 0.7187204112637108, 'gamma': 1.5536377993197572, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:58,031] Trial 145 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 255, 'max_depth': 6, 'learning_rate': 0.024645149154528607, 'subsample': 0.7213120754990726, 'colsample_bytree': 0.7440611665265857, 'gamma': 1.1856348271965471, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:58,913] Trial 146 finished with value: 0.8143484177639776 and parameters: {'n_estimators': 243, 'max_depth': 6, 'learning_rate': 0.02429335473894927, 'subsample': 0.7221384193361144, 'colsample_bytree': 0.7329786644514904, 'gamma': 1.176087861763318, 'min_child_weight': 4}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:36:59,706] Trial 147 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 257, 'max_depth': 6, 'learning_rate': 0.046088546656446405, 'subsample': 0.7145488657226028, 'colsample_bytree': 0.7108483296832719, 'gamma': 1.3509472692286748, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:36:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:00,568] Trial 148 finished with value: 0.82330899124068 and parameters: {'n_estimators': 252, 'max_depth': 5, 'learning_rate': 0.0473890094718451, 'subsample': 0.7152613023214164, 'colsample_bytree': 0.7459671980749705, 'gamma': 1.4927249031342031, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:01,419] Trial 149 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 256, 'max_depth': 4, 'learning_rate': 0.05117623560874435, 'subsample': 0.7322921485037486, 'colsample_bytree': 0.745159676858981, 'gamma': 1.4943411132981004, 'min_child_weight': 4}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:02,248] Trial 150 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 262, 'max_depth': 5, 'learning_rate': 0.04664710823134782, 'subsample': 0.7164838451622112, 'colsample_bytree': 0.7031136811534471, 'gamma': 1.703656991397358, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:03,088] Trial 151 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 254, 'max_depth': 5, 'learning_rate': 0.044390684516477256, 'subsample': 0.7175684230819728, 'colsample_bytree': 0.7056703714022777, 'gamma': 1.699496763811465, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:03,941] Trial 152 finished with value: 0.8143484177639776 and parameters: {'n_estimators': 247, 'max_depth': 5, 'learning_rate': 0.06028949462939421, 'subsample': 0.7121633848582734, 'colsample_bytree': 0.7259084062513811, 'gamma': 1.5567607741854375, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:04,788] Trial 153 finished with value: 0.8215072930442949 and parameters: {'n_estimators': 262, 'max_depth': 5, 'learning_rate': 0.037915947584897434, 'subsample': 0.7266667602266451, 'colsample_bytree': 0.6866503891076849, 'gamma': 1.402221942861059, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:05,756] Trial 154 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 263, 'max_depth': 5, 'learning_rate': 0.04570845747200877, 'subsample': 0.7416215108236907, 'colsample_bytree': 0.6789293141801522, 'gamma': 1.394977647162373, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:06,494] Trial 155 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 259, 'max_depth': 5, 'learning_rate': 0.11251226069295993, 'subsample': 0.7256540460682849, 'colsample_bytree': 0.6923697631900321, 'gamma': 2.234397201662196, 'min_child_weight': 3}. Best is trial 13 with value: 0.8250915224349759.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:07,452] Trial 156 finished with value: 0.8250915224349761 and parameters: {'n_estimators': 254, 'max_depth': 4, 'learning_rate': 0.03827215586433702, 'subsample': 0.7150146856590879, 'colsample_bytree': 0.7130927773342925, 'gamma': 1.2424620409915597, 'min_child_weight': 3}. Best is trial 156 with value: 0.8250915224349761.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:08,311] Trial 157 finished with value: 0.7982864700132253 and parameters: {'n_estimators': 257, 'max_depth': 4, 'learning_rate': 0.13689658216691244, 'subsample': 0.7348337847433201, 'colsample_bytree': 0.7110958120160007, 'gamma': 1.2192650183275813, 'min_child_weight': 3}. Best is trial 156 with value: 0.8250915224349761.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:09,115] Trial 158 finished with value: 0.8179326471546585 and parameters: {'n_estimators': 252, 'max_depth': 3, 'learning_rate': 0.03835144598919305, 'subsample': 0.7142943536233088, 'colsample_bytree': 0.6961034459757576, 'gamma': 1.0157124356421983, 'min_child_weight': 3}. Best is trial 156 with value: 0.8250915224349761.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:10,351] Trial 159 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 262, 'max_depth': 3, 'learning_rate': 0.04729145669889567, 'subsample': 0.7070803343566722, 'colsample_bytree': 0.7122836482070708, 'gamma': 1.12210785461161, 'min_child_weight': 4}. Best is trial 156 with value: 0.8250915224349761.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:11,421] Trial 160 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 255, 'max_depth': 4, 'learning_rate': 0.0671225904531981, 'subsample': 0.7242898087480562, 'colsample_bytree': 0.7406793290244208, 'gamma': 1.6430272807804713, 'min_child_weight': 3}. Best is trial 156 with value: 0.8250915224349761.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:12,433] Trial 161 finished with value: 0.8268644701282272 and parameters: {'n_estimators': 264, 'max_depth': 5, 'learning_rate': 0.03201072353176407, 'subsample': 0.7011282619659922, 'colsample_bytree': 0.7226422004784405, 'gamma': 1.273170705727838, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:13,677] Trial 162 finished with value: 0.816140532459318 and parameters: {'n_estimators': 261, 'max_depth': 5, 'learning_rate': 0.034549744274645786, 'subsample': 0.7168133607646884, 'colsample_bytree': 0.7570791341381097, 'gamma': 1.2320501876921017, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:14,790] Trial 163 finished with value: 0.817923063653614 and parameters: {'n_estimators': 249, 'max_depth': 5, 'learning_rate': 0.05576725419818874, 'subsample': 0.7030949206031827, 'colsample_bytree': 0.6821381723583452, 'gamma': 1.4312342126435453, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:15,686] Trial 164 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 271, 'max_depth': 5, 'learning_rate': 0.03945142432032417, 'subsample': 0.734053015166714, 'colsample_bytree': 0.670041447756671, 'gamma': 1.1808451008491345, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:16,740] Trial 165 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 263, 'max_depth': 5, 'learning_rate': 0.041334902313154065, 'subsample': 0.7379179194704815, 'colsample_bytree': 0.7013655441737662, 'gamma': 1.1340300643594619, 'min_child_weight': 4}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:17,685] Trial 166 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 270, 'max_depth': 5, 'learning_rate': 0.04859044291211538, 'subsample': 0.7628704481093743, 'colsample_bytree': 0.6671851144082984, 'gamma': 1.2425404285465136, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:18,514] Trial 167 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 253, 'max_depth': 4, 'learning_rate': 0.03193604505323743, 'subsample': 0.729277478612466, 'colsample_bytree': 0.6923467939281192, 'gamma': 1.3809699329113936, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:19,621] Trial 168 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 259, 'max_depth': 5, 'learning_rate': 0.03995509921238097, 'subsample': 0.748237522375027, 'colsample_bytree': 0.6667836202138832, 'gamma': 0.942162561520144, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:20,471] Trial 169 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 265, 'max_depth': 5, 'learning_rate': 0.05498668349241361, 'subsample': 0.7207304253849216, 'colsample_bytree': 0.7485237592230807, 'gamma': 1.04888853251227, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:21,336] Trial 170 finished with value: 0.8036436470971576 and parameters: {'n_estimators': 273, 'max_depth': 5, 'learning_rate': 0.17454455364590074, 'subsample': 0.7439953341881195, 'colsample_bytree': 0.7374523072299246, 'gamma': 1.292589028455864, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:22,246] Trial 171 finished with value: 0.8196960113468652 and parameters: {'n_estimators': 265, 'max_depth': 5, 'learning_rate': 0.031564934021555996, 'subsample': 0.7094260673780463, 'colsample_bytree': 0.7283345162131523, 'gamma': 1.452898643628654, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:23,274] Trial 172 finished with value: 0.8179518141567478 and parameters: {'n_estimators': 256, 'max_depth': 6, 'learning_rate': 0.01903193508881316, 'subsample': 0.7256139571971236, 'colsample_bytree': 0.7175917617692301, 'gamma': 1.1991446422980547, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:24,138] Trial 173 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 271, 'max_depth': 4, 'learning_rate': 0.035745746807103226, 'subsample': 0.6973682383813488, 'colsample_bytree': 0.708554505071323, 'gamma': 1.537536008587872, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:25,000] Trial 174 finished with value: 0.8179326471546585 and parameters: {'n_estimators': 249, 'max_depth': 6, 'learning_rate': 0.02729755115116572, 'subsample': 0.7149061111547016, 'colsample_bytree': 0.6486329223510089, 'gamma': 1.333453826360584, 'min_child_weight': 4}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:26,130] Trial 175 finished with value: 0.8179326471546585 and parameters: {'n_estimators': 259, 'max_depth': 5, 'learning_rate': 0.01531240876605907, 'subsample': 0.7043442404259237, 'colsample_bytree': 0.6596468725234387, 'gamma': 1.1093936317672233, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:27,063] Trial 176 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 241, 'max_depth': 6, 'learning_rate': 0.022694454977271742, 'subsample': 0.7319031930094239, 'colsample_bytree': 0.7200988017692288, 'gamma': 1.3863366815771065, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:28,080] Trial 177 finished with value: 0.8232802407375462 and parameters: {'n_estimators': 268, 'max_depth': 6, 'learning_rate': 0.03165760332699913, 'subsample': 0.7190256470664783, 'colsample_bytree': 0.67742635208477, 'gamma': 1.2524313219114764, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:28,980] Trial 178 finished with value: 0.817923063653614 and parameters: {'n_estimators': 267, 'max_depth': 5, 'learning_rate': 0.04174548917401895, 'subsample': 0.7392522750789282, 'colsample_bytree': 0.6778804944060572, 'gamma': 1.2616695045013746, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:29,962] Trial 179 finished with value: 0.8197151783489544 and parameters: {'n_estimators': 252, 'max_depth': 6, 'learning_rate': 0.031329247188438665, 'subsample': 0.7219795197740115, 'colsample_bytree': 0.7025818896923648, 'gamma': 1.1499912712893732, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:30,665] Trial 180 finished with value: 0.8036436470971576 and parameters: {'n_estimators': 270, 'max_depth': 6, 'learning_rate': 0.050221501882879396, 'subsample': 0.8545572374127842, 'colsample_bytree': 0.6917863113506222, 'gamma': 1.4681425565485815, 'min_child_weight': 6}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:31,935] Trial 181 finished with value: 0.8125563030686371 and parameters: {'n_estimators': 274, 'max_depth': 6, 'learning_rate': 0.019032738159673372, 'subsample': 0.6973004886851938, 'colsample_bytree': 0.6355315792136744, 'gamma': 0.9849430555143889, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:32,839] Trial 182 finished with value: 0.8250915224349759 and parameters: {'n_estimators': 263, 'max_depth': 6, 'learning_rate': 0.036301696100069156, 'subsample': 0.7092113933860509, 'colsample_bytree': 0.673941296170082, 'gamma': 1.3443934090951994, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:33,733] Trial 183 finished with value: 0.819724761849999 and parameters: {'n_estimators': 264, 'max_depth': 6, 'learning_rate': 0.037198417358425544, 'subsample': 0.7113421929412921, 'colsample_bytree': 0.6711346262134898, 'gamma': 1.3434818797344399, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:34,732] Trial 184 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 264, 'max_depth': 6, 'learning_rate': 0.03686775365671448, 'subsample': 0.7104167050127046, 'colsample_bytree': 0.6705492651963857, 'gamma': 1.3246865572885644, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:35,673] Trial 185 finished with value: 0.8215072930442949 and parameters: {'n_estimators': 260, 'max_depth': 6, 'learning_rate': 0.044255745209911254, 'subsample': 0.7174004381436069, 'colsample_bytree': 0.6765251632106545, 'gamma': 1.198102179476349, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:36,704] Trial 186 finished with value: 0.8197151783489544 and parameters: {'n_estimators': 260, 'max_depth': 6, 'learning_rate': 0.04279641250572311, 'subsample': 0.7525771817960152, 'colsample_bytree': 0.6618656687745169, 'gamma': 1.1861624493014382, 'min_child_weight': 3}. Best is trial 161 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:37,771] Trial 187 finished with value: 0.8286757518256569 and parameters: {'n_estimators': 256, 'max_depth': 6, 'learning_rate': 0.05075252994436706, 'subsample': 0.7189713790607359, 'colsample_bytree': 0.6851934297456209, 'gamma': 1.5783408996683757, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:39,681] Trial 188 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 256, 'max_depth': 6, 'learning_rate': 0.062487496246530806, 'subsample': 0.7168894415558539, 'colsample_bytree': 0.684842562460995, 'gamma': 1.7631370913004225, 'min_child_weight': 4}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:41,023] Trial 189 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 247, 'max_depth': 6, 'learning_rate': 0.05655119237748222, 'subsample': 0.7312010498600229, 'colsample_bytree': 0.6762009924980387, 'gamma': 1.6145948657429152, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:42,084] Trial 190 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 261, 'max_depth': 6, 'learning_rate': 0.049731824660878235, 'subsample': 0.7248912725093846, 'colsample_bytree': 0.6871712573193269, 'gamma': 1.5230064269868304, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:42,962] Trial 191 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 252, 'max_depth': 6, 'learning_rate': 0.0421621495814566, 'subsample': 0.7171464530099769, 'colsample_bytree': 0.6738488695425356, 'gamma': 1.396866785461995, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:43,985] Trial 192 finished with value: 0.8233089912406801 and parameters: {'n_estimators': 255, 'max_depth': 6, 'learning_rate': 0.046796360646665675, 'subsample': 0.7159305474626774, 'colsample_bytree': 0.6546264449657988, 'gamma': 1.3738840766558433, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:44,798] Trial 193 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 252, 'max_depth': 6, 'learning_rate': 0.04669022515183252, 'subsample': 0.7190926765436663, 'colsample_bytree': 0.655737714461607, 'gamma': 1.4227956567853641, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:45,624] Trial 194 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 254, 'max_depth': 6, 'learning_rate': 0.044872954425338354, 'subsample': 0.7366563303291421, 'colsample_bytree': 0.641417596678103, 'gamma': 1.5841887494033995, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:46,535] Trial 195 finished with value: 0.8108121058785196 and parameters: {'n_estimators': 258, 'max_depth': 6, 'learning_rate': 0.05523018209420352, 'subsample': 0.7053547792935425, 'colsample_bytree': 0.6762601966019893, 'gamma': 1.0588312692186126, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:47,363] Trial 196 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 250, 'max_depth': 6, 'learning_rate': 0.051912631302050025, 'subsample': 0.7284505012248343, 'colsample_bytree': 0.6289812152025352, 'gamma': 1.388299496111498, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:48,212] Trial 197 finished with value: 0.8089912406800454 and parameters: {'n_estimators': 257, 'max_depth': 5, 'learning_rate': 0.04151785237802147, 'subsample': 0.7160588311471555, 'colsample_bytree': 0.6075917584581119, 'gamma': 1.2136151115213198, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:49,156] Trial 198 finished with value: 0.8197151783489544 and parameters: {'n_estimators': 262, 'max_depth': 6, 'learning_rate': 0.03758207824074087, 'subsample': 0.7226868238451409, 'colsample_bytree': 0.6965039999344685, 'gamma': 1.4724997554328823, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:49,916] Trial 199 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 246, 'max_depth': 5, 'learning_rate': 0.060519394183362725, 'subsample': 0.7043934012029331, 'colsample_bytree': 0.6638977799499145, 'gamma': 1.1467665086669803, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:50,897] Trial 200 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 254, 'max_depth': 6, 'learning_rate': 0.032201276962274025, 'subsample': 0.7427828171984139, 'colsample_bytree': 0.6881429262452479, 'gamma': 1.305903721986949, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:51,737] Trial 201 finished with value: 0.817923063653614 and parameters: {'n_estimators': 268, 'max_depth': 6, 'learning_rate': 0.07502439570834617, 'subsample': 0.7137580059183969, 'colsample_bytree': 0.6734797506803216, 'gamma': 1.3597627834868629, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:52,758] Trial 202 finished with value: 0.8286565848235677 and parameters: {'n_estimators': 263, 'max_depth': 6, 'learning_rate': 0.03677926883139793, 'subsample': 0.7094578072120074, 'colsample_bytree': 0.6569420098696717, 'gamma': 1.2868620018335704, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:53,628] Trial 203 finished with value: 0.8232706572365016 and parameters: {'n_estimators': 259, 'max_depth': 6, 'learning_rate': 0.04557143005771416, 'subsample': 0.7078524795663136, 'colsample_bytree': 0.6562765164347129, 'gamma': 1.2584699059435036, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:54,609] Trial 204 finished with value: 0.8179613976577924 and parameters: {'n_estimators': 264, 'max_depth': 6, 'learning_rate': 0.04715762796076976, 'subsample': 0.6993730636173875, 'colsample_bytree': 0.6573632831613674, 'gamma': 1.1865331661272922, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:55,357] Trial 205 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 256, 'max_depth': 6, 'learning_rate': 0.04167785213906874, 'subsample': 0.7076835161592381, 'colsample_bytree': 0.6806115700623169, 'gamma': 2.4457460769012234, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:56,351] Trial 206 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 251, 'max_depth': 6, 'learning_rate': 0.05051890082665634, 'subsample': 0.7209128658087693, 'colsample_bytree': 0.6497704283215551, 'gamma': 1.0728185623757682, 'min_child_weight': 4}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:57,288] Trial 207 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 261, 'max_depth': 5, 'learning_rate': 0.03506341208123876, 'subsample': 0.7120289978395439, 'colsample_bytree': 0.6531998660818585, 'gamma': 1.4786981395845076, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:58,319] Trial 208 finished with value: 0.8197055948479098 and parameters: {'n_estimators': 270, 'max_depth': 6, 'learning_rate': 0.04452976091347592, 'subsample': 0.6975223019385166, 'colsample_bytree': 0.6629095229380019, 'gamma': 1.2529410476457317, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:59,003] Trial 209 finished with value: 0.8143484177639776 and parameters: {'n_estimators': 120, 'max_depth': 6, 'learning_rate': 0.03140982030963292, 'subsample': 0.7047831501564594, 'colsample_bytree': 0.6847008360663733, 'gamma': 1.594618230716402, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:37:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:37:59,900] Trial 210 finished with value: 0.816140532459318 and parameters: {'n_estimators': 243, 'max_depth': 5, 'learning_rate': 0.03895904712286459, 'subsample': 0.7265074174046363, 'colsample_bytree': 0.7004469888942114, 'gamma': 1.3814817669150172, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:00,867] Trial 211 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 260, 'max_depth': 6, 'learning_rate': 0.03013638749416296, 'subsample': 0.7308208848147905, 'colsample_bytree': 0.7098946847698236, 'gamma': 1.2491696893091666, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:01,783] Trial 212 finished with value: 0.8197439288520884 and parameters: {'n_estimators': 258, 'max_depth': 6, 'learning_rate': 0.05353198969855537, 'subsample': 0.7181859410929897, 'colsample_bytree': 0.7356326032195037, 'gamma': 1.3314809294921144, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:03,042] Trial 213 finished with value: 0.8197439288520884 and parameters: {'n_estimators': 265, 'max_depth': 6, 'learning_rate': 0.0499349765819294, 'subsample': 0.7158260068925916, 'colsample_bytree': 0.7371020341174641, 'gamma': 1.4055027958285866, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:04,003] Trial 214 finished with value: 0.816140532459318 and parameters: {'n_estimators': 266, 'max_depth': 6, 'learning_rate': 0.060259445973079445, 'subsample': 0.7126590892804024, 'colsample_bytree': 0.7282575604568261, 'gamma': 1.435486079535055, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:04,802] Trial 215 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 264, 'max_depth': 6, 'learning_rate': 0.06819459846724396, 'subsample': 0.7173172716368533, 'colsample_bytree': 0.7388722410556758, 'gamma': 1.535956994739677, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:05,944] Trial 216 finished with value: 0.8001169187127442 and parameters: {'n_estimators': 270, 'max_depth': 6, 'learning_rate': 0.05355070270495215, 'subsample': 0.9524843446286004, 'colsample_bytree': 0.6743621464601655, 'gamma': 1.3531769380891676, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:06,745] Trial 217 finished with value: 0.8179518141567478 and parameters: {'n_estimators': 258, 'max_depth': 5, 'learning_rate': 0.04833579933488042, 'subsample': 0.7030988252761833, 'colsample_bytree': 0.6662125960079803, 'gamma': 1.4528655269970066, 'min_child_weight': 4}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:07,678] Trial 218 finished with value: 0.8125563030686371 and parameters: {'n_estimators': 273, 'max_depth': 4, 'learning_rate': 0.05460318327761343, 'subsample': 0.6890298176325187, 'colsample_bytree': 0.6442278490002321, 'gamma': 1.6594167388963406, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:08,584] Trial 219 finished with value: 0.7964847718168402 and parameters: {'n_estimators': 267, 'max_depth': 6, 'learning_rate': 0.04445195290171038, 'subsample': 0.7081755429027415, 'colsample_bytree': 0.7546589776410471, 'gamma': 1.3101865513329292, 'min_child_weight': 7}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:09,675] Trial 220 finished with value: 0.82330899124068 and parameters: {'n_estimators': 262, 'max_depth': 6, 'learning_rate': 0.04047136403300706, 'subsample': 0.7212760806740395, 'colsample_bytree': 0.7359623778711923, 'gamma': 1.1096437257318206, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:10,640] Trial 221 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 262, 'max_depth': 6, 'learning_rate': 0.039898709515889474, 'subsample': 0.7190998623403319, 'colsample_bytree': 0.7293998059825925, 'gamma': 1.1544394864669338, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:11,662] Trial 222 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 262, 'max_depth': 6, 'learning_rate': 0.04156112597926286, 'subsample': 0.7233291638200078, 'colsample_bytree': 0.7358199048651278, 'gamma': 1.0714499821695282, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:12,619] Trial 223 finished with value: 0.8197439288520884 and parameters: {'n_estimators': 260, 'max_depth': 6, 'learning_rate': 0.040446914783246496, 'subsample': 0.7261055647558347, 'colsample_bytree': 0.7274238985474027, 'gamma': 1.0438403460455752, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:13,785] Trial 224 finished with value: 0.8197151783489546 and parameters: {'n_estimators': 254, 'max_depth': 6, 'learning_rate': 0.039021535817281156, 'subsample': 0.737521866135624, 'colsample_bytree': 0.7488316028400124, 'gamma': 0.9495198799645292, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:14,699] Trial 225 finished with value: 0.8250723554328867 and parameters: {'n_estimators': 262, 'max_depth': 6, 'learning_rate': 0.04672153622578608, 'subsample': 0.7208774735055626, 'colsample_bytree': 0.7135364783742472, 'gamma': 1.1306490524937733, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:15,731] Trial 226 finished with value: 0.816140532459318 and parameters: {'n_estimators': 262, 'max_depth': 6, 'learning_rate': 0.04633097332188452, 'subsample': 0.7332872630051581, 'colsample_bytree': 0.7137306658492639, 'gamma': 1.0982104474291654, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:16,716] Trial 227 finished with value: 0.816140532459318 and parameters: {'n_estimators': 268, 'max_depth': 6, 'learning_rate': 0.043667371375851555, 'subsample': 0.811860268514376, 'colsample_bytree': 0.7037332039379351, 'gamma': 1.1549206610428588, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:17,559] Trial 228 finished with value: 0.7929197094282484 and parameters: {'n_estimators': 263, 'max_depth': 6, 'learning_rate': 0.03439634983597946, 'subsample': 0.7248906389467532, 'colsample_bytree': 0.7220777672279328, 'gamma': 0.9065711159643776, 'min_child_weight': 9}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:18,645] Trial 229 finished with value: 0.8268836371303164 and parameters: {'n_estimators': 251, 'max_depth': 6, 'learning_rate': 0.03646310946092676, 'subsample': 0.7089935020707447, 'colsample_bytree': 0.6942008845105968, 'gamma': 1.04686232506839, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:19,656] Trial 230 finished with value: 0.8233089912406801 and parameters: {'n_estimators': 253, 'max_depth': 6, 'learning_rate': 0.03627880527499815, 'subsample': 0.709869508013966, 'colsample_bytree': 0.6928046001331541, 'gamma': 0.9876352090495146, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:20,634] Trial 231 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 250, 'max_depth': 6, 'learning_rate': 0.03659445120191977, 'subsample': 0.7066758080155708, 'colsample_bytree': 0.6904446753323628, 'gamma': 0.9803015633039958, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:21,639] Trial 232 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 254, 'max_depth': 6, 'learning_rate': 0.03635248315936179, 'subsample': 0.710406837652741, 'colsample_bytree': 0.6954445867989809, 'gamma': 1.0884145761940196, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:22,520] Trial 233 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 247, 'max_depth': 6, 'learning_rate': 0.03076854356136322, 'subsample': 0.6982686844200093, 'colsample_bytree': 0.7149984623666304, 'gamma': 1.0643031090982613, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:23,589] Trial 234 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 257, 'max_depth': 6, 'learning_rate': 0.04043373918988794, 'subsample': 0.7214771078717238, 'colsample_bytree': 0.7076167294308546, 'gamma': 0.9752931104765732, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:24,678] Trial 235 finished with value: 0.8179518141567478 and parameters: {'n_estimators': 256, 'max_depth': 6, 'learning_rate': 0.04285321782241853, 'subsample': 0.7117382079540648, 'colsample_bytree': 0.7020394429709589, 'gamma': 0.9227912030168837, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:25,586] Trial 236 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 251, 'max_depth': 6, 'learning_rate': 0.048235836510376405, 'subsample': 0.7195321984499274, 'colsample_bytree': 0.7095052337831623, 'gamma': 0.9996679474954581, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:26,989] Trial 237 finished with value: 0.7982481360090469 and parameters: {'n_estimators': 257, 'max_depth': 6, 'learning_rate': 0.16332134297494288, 'subsample': 0.7051120773880812, 'colsample_bytree': 0.7315175628052751, 'gamma': 0.8225256080924837, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:27,985] Trial 238 finished with value: 0.8179326471546585 and parameters: {'n_estimators': 253, 'max_depth': 6, 'learning_rate': 0.03313169384293926, 'subsample': 0.7230964285794725, 'colsample_bytree': 0.7204646812394487, 'gamma': 0.8851565017086689, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:28,945] Trial 239 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 247, 'max_depth': 6, 'learning_rate': 0.039967915842234816, 'subsample': 0.6982340895889876, 'colsample_bytree': 0.7082671742509596, 'gamma': 1.2144316669338382, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:30,051] Trial 240 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 276, 'max_depth': 6, 'learning_rate': 0.028784424719900045, 'subsample': 0.7130843597951133, 'colsample_bytree': 0.6579454296142568, 'gamma': 1.1460529820736087, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:30,947] Trial 241 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 262, 'max_depth': 5, 'learning_rate': 0.038496555698551496, 'subsample': 0.7273823679282532, 'colsample_bytree': 0.6934438441724738, 'gamma': 1.236897904848883, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:31,828] Trial 242 finished with value: 0.8179326471546585 and parameters: {'n_estimators': 186, 'max_depth': 6, 'learning_rate': 0.04312256043876331, 'subsample': 0.7373489334122425, 'colsample_bytree': 0.6817913588640409, 'gamma': 1.0513820649949241, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:32,739] Trial 243 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 258, 'max_depth': 6, 'learning_rate': 0.03566793168572461, 'subsample': 0.722801688693917, 'colsample_bytree': 0.6978503914522268, 'gamma': 1.1544638011769945, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:33,730] Trial 244 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 264, 'max_depth': 3, 'learning_rate': 0.048109805396915936, 'subsample': 0.7172701293603584, 'colsample_bytree': 0.6853597196840766, 'gamma': 1.2633329550472505, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:34,998] Trial 245 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 268, 'max_depth': 6, 'learning_rate': 0.04093418925555502, 'subsample': 0.7311559604264743, 'colsample_bytree': 0.6697187323694901, 'gamma': 1.1253613173791592, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:35,940] Trial 246 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 261, 'max_depth': 5, 'learning_rate': 0.03351687046461953, 'subsample': 0.7086820144625765, 'colsample_bytree': 0.713625902951922, 'gamma': 1.2719797547622822, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:37,022] Trial 247 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 255, 'max_depth': 6, 'learning_rate': 0.052420012771559575, 'subsample': 0.7262010844762502, 'colsample_bytree': 0.704413222929738, 'gamma': 1.0058645031702425, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:38,077] Trial 248 finished with value: 0.821507293044295 and parameters: {'n_estimators': 250, 'max_depth': 6, 'learning_rate': 0.02792438829627092, 'subsample': 0.7013334392043977, 'colsample_bytree': 0.7226899963837848, 'gamma': 1.1484897761491393, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:39,137] Trial 249 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 251, 'max_depth': 6, 'learning_rate': 0.027948504984286766, 'subsample': 0.6985012075408421, 'colsample_bytree': 0.7257193192250667, 'gamma': 0.8501214642597962, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:40,862] Trial 250 finished with value: 0.8214977095432504 and parameters: {'n_estimators': 245, 'max_depth': 6, 'learning_rate': 0.02794815728563972, 'subsample': 0.7055628573837214, 'colsample_bytree': 0.7192553648347146, 'gamma': 1.0920957901797925, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:41,672] Trial 251 finished with value: 0.8197151783489546 and parameters: {'n_estimators': 250, 'max_depth': 6, 'learning_rate': 0.0455461790068558, 'subsample': 0.7138422906151317, 'colsample_bytree': 0.7257232253458298, 'gamma': 2.942193238208251, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:43,001] Trial 252 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 257, 'max_depth': 6, 'learning_rate': 0.03398655739398772, 'subsample': 0.701442391615674, 'colsample_bytree': 0.7457606757137913, 'gamma': 1.1787201937529654, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:43,930] Trial 253 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 256, 'max_depth': 6, 'learning_rate': 0.03436149042550564, 'subsample': 0.6958846525781796, 'colsample_bytree': 0.747660908505244, 'gamma': 1.017410338217592, 'min_child_weight': 4}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:44,719] Trial 254 finished with value: 0.8089816571790007 and parameters: {'n_estimators': 253, 'max_depth': 6, 'learning_rate': 0.057634837031746905, 'subsample': 0.7028629595084817, 'colsample_bytree': 0.7344178005791538, 'gamma': 4.3365116978043545, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:45,669] Trial 255 finished with value: 0.8214785425411611 and parameters: {'n_estimators': 258, 'max_depth': 6, 'learning_rate': 0.039517486902099365, 'subsample': 0.6886367472055799, 'colsample_bytree': 0.7116920717599888, 'gamma': 1.1680331284754084, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:46,669] Trial 256 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 240, 'max_depth': 6, 'learning_rate': 0.04877173671586919, 'subsample': 0.7095785480750055, 'colsample_bytree': 0.7593897769066453, 'gamma': 0.750600809474034, 'min_child_weight': 5}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:47,659] Trial 257 finished with value: 0.8179230636536139 and parameters: {'n_estimators': 266, 'max_depth': 6, 'learning_rate': 0.03207603041240416, 'subsample': 0.7179042633592825, 'colsample_bytree': 0.6489764632969719, 'gamma': 0.9398192297695596, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:48,996] Trial 258 finished with value: 0.8215072930442949 and parameters: {'n_estimators': 252, 'max_depth': 6, 'learning_rate': 0.04127104482766744, 'subsample': 0.7021617413077054, 'colsample_bytree': 0.6659912795617634, 'gamma': 1.271639378250481, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:50,128] Trial 259 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 248, 'max_depth': 6, 'learning_rate': 0.025892894631899442, 'subsample': 0.7121903954332655, 'colsample_bytree': 0.7010027200926682, 'gamma': 1.1154392615074507, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:51,059] Trial 260 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 272, 'max_depth': 6, 'learning_rate': 0.03446746048096567, 'subsample': 0.693182014611828, 'colsample_bytree': 0.7168910206505139, 'gamma': 1.2922759833450177, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:52,060] Trial 261 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 272, 'max_depth': 4, 'learning_rate': 0.04465842149821166, 'subsample': 0.6935094738914709, 'colsample_bytree': 0.7188494291467481, 'gamma': 1.1924590176913692, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:53,061] Trial 262 finished with value: 0.8232802407375462 and parameters: {'n_estimators': 277, 'max_depth': 6, 'learning_rate': 0.03589171053147175, 'subsample': 0.6904977648264865, 'colsample_bytree': 0.7090556120795489, 'gamma': 0.9955198053378198, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:53,894] Trial 263 finished with value: 0.7947118241235889 and parameters: {'n_estimators': 271, 'max_depth': 6, 'learning_rate': 0.05043705578978897, 'subsample': 0.6874654165798169, 'colsample_bytree': 0.708266153040131, 'gamma': 0.9782858461314262, 'min_child_weight': 8}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:54,949] Trial 264 finished with value: 0.8232802407375462 and parameters: {'n_estimators': 277, 'max_depth': 6, 'learning_rate': 0.03742823903428367, 'subsample': 0.691840496523364, 'colsample_bytree': 0.7289158931030019, 'gamma': 1.0452151784834474, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:56,131] Trial 265 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 278, 'max_depth': 6, 'learning_rate': 0.03914081959155791, 'subsample': 0.6840049301114588, 'colsample_bytree': 0.7338799600459535, 'gamma': 1.0030963115449933, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:57,187] Trial 266 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 276, 'max_depth': 6, 'learning_rate': 0.057262606127654755, 'subsample': 0.6919609751918554, 'colsample_bytree': 0.6966295283130164, 'gamma': 1.0629744878055793, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:58,228] Trial 267 finished with value: 0.8125371360665478 and parameters: {'n_estimators': 269, 'max_depth': 7, 'learning_rate': 0.044551112120730804, 'subsample': 0.7191372832874114, 'colsample_bytree': 0.7283508218855719, 'gamma': 0.8056420648320903, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:38:59,436] Trial 268 finished with value: 0.810802522377475 and parameters: {'n_estimators': 273, 'max_depth': 6, 'learning_rate': 0.03676374183284402, 'subsample': 0.6960254606541975, 'colsample_bytree': 0.7141848010036626, 'gamma': 0.6911508894422471, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:38:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:00,631] Trial 269 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 266, 'max_depth': 6, 'learning_rate': 0.04695897686905946, 'subsample': 0.7087406723507468, 'colsample_bytree': 0.6355903507403418, 'gamma': 0.8987393022202426, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:01,528] Trial 270 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 261, 'max_depth': 6, 'learning_rate': 0.0535601047697291, 'subsample': 0.7211901854080186, 'colsample_bytree': 0.6556975836281745, 'gamma': 1.3449592225471407, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:02,619] Trial 271 finished with value: 0.8072470434899278 and parameters: {'n_estimators': 264, 'max_depth': 6, 'learning_rate': 0.036745987610127685, 'subsample': 0.6988915570605029, 'colsample_bytree': 0.6802001353801801, 'gamma': 0.8759067580819782, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:03,351] Trial 272 finished with value: 0.8089816571790007 and parameters: {'n_estimators': 279, 'max_depth': 6, 'learning_rate': 0.18184542904582007, 'subsample': 0.7169627115209071, 'colsample_bytree': 0.7077132568978769, 'gamma': 1.4880476150985757, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:04,432] Trial 273 finished with value: 0.8250723554328867 and parameters: {'n_estimators': 258, 'max_depth': 6, 'learning_rate': 0.04174833813478855, 'subsample': 0.6903050139694406, 'colsample_bytree': 0.7401884417821448, 'gamma': 1.057905666365976, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:05,463] Trial 274 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 268, 'max_depth': 6, 'learning_rate': 0.03251957341952085, 'subsample': 0.6832950062867666, 'colsample_bytree': 0.7413406071758064, 'gamma': 1.3180851124252473, 'min_child_weight': 4}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:06,456] Trial 275 finished with value: 0.8179326471546585 and parameters: {'n_estimators': 262, 'max_depth': 6, 'learning_rate': 0.05021770716795346, 'subsample': 0.6907828224963766, 'colsample_bytree': 0.7464037664702418, 'gamma': 1.1015534612127444, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:07,408] Trial 276 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 274, 'max_depth': 5, 'learning_rate': 0.061361533030752397, 'subsample': 0.6796638655621117, 'colsample_bytree': 0.7676770535451086, 'gamma': 1.2279462164259238, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:08,175] Trial 277 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 171, 'max_depth': 6, 'learning_rate': 0.04395003454564566, 'subsample': 0.7033324637758147, 'colsample_bytree': 0.7333065816205158, 'gamma': 1.3998804695265112, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:09,129] Trial 278 finished with value: 0.8250819389339313 and parameters: {'n_estimators': 284, 'max_depth': 6, 'learning_rate': 0.03592901139366968, 'subsample': 0.6916158658907703, 'colsample_bytree': 0.6738849662509053, 'gamma': 1.1841866856624736, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:10,220] Trial 279 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 286, 'max_depth': 6, 'learning_rate': 0.033012411447079615, 'subsample': 0.6911511961869692, 'colsample_bytree': 0.6716244850454332, 'gamma': 1.3124792319382084, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:11,272] Trial 280 finished with value: 0.8107641883732964 and parameters: {'n_estimators': 283, 'max_depth': 6, 'learning_rate': 0.04790596125812471, 'subsample': 0.6846683988161619, 'colsample_bytree': 0.6923616532907894, 'gamma': 1.5346043890658927, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:12,683] Trial 281 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 278, 'max_depth': 7, 'learning_rate': 0.0905948234140698, 'subsample': 0.6948269366890704, 'colsample_bytree': 0.661756489896889, 'gamma': 1.223074755796877, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:13,787] Trial 282 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 271, 'max_depth': 5, 'learning_rate': 0.034993559464416915, 'subsample': 0.7028624098274884, 'colsample_bytree': 0.6785329175921855, 'gamma': 1.0580870954152237, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:14,650] Trial 283 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 280, 'max_depth': 6, 'learning_rate': 0.042469922387237125, 'subsample': 0.6774542097577093, 'colsample_bytree': 0.6737607962519743, 'gamma': 1.3636556806441988, 'min_child_weight': 4}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:15,689] Trial 284 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 275, 'max_depth': 6, 'learning_rate': 0.052012021842579706, 'subsample': 0.7096254403068176, 'colsample_bytree': 0.6653169516547218, 'gamma': 1.1707415548399245, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:16,769] Trial 285 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 257, 'max_depth': 6, 'learning_rate': 0.03199781126465843, 'subsample': 0.6933468045252569, 'colsample_bytree': 0.6899625043856041, 'gamma': 1.0389090007328352, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:17,804] Trial 286 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 266, 'max_depth': 5, 'learning_rate': 0.039956611707177195, 'subsample': 0.6894118730714622, 'colsample_bytree': 0.6854625700614047, 'gamma': 0.9393759268901677, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:18,725] Trial 287 finished with value: 0.814386751768156 and parameters: {'n_estimators': 283, 'max_depth': 4, 'learning_rate': 0.029038038208884197, 'subsample': 0.8304128597802517, 'colsample_bytree': 0.6908672587830705, 'gamma': 1.072049714721376, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:19,413] Trial 288 finished with value: 0.805416594790409 and parameters: {'n_estimators': 258, 'max_depth': 6, 'learning_rate': 0.045068583991686575, 'subsample': 0.6955107630440852, 'colsample_bytree': 0.6981091530885161, 'gamma': 4.814078360433673, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:20,257] Trial 289 finished with value: 0.8179038966515247 and parameters: {'n_estimators': 271, 'max_depth': 7, 'learning_rate': 0.06465886223121528, 'subsample': 0.7088308960426294, 'colsample_bytree': 0.6809479471618102, 'gamma': 1.4676966453323765, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:21,320] Trial 290 finished with value: 0.816140532459318 and parameters: {'n_estimators': 253, 'max_depth': 6, 'learning_rate': 0.05445816444092482, 'subsample': 0.6839418445059027, 'colsample_bytree': 0.656479776879826, 'gamma': 1.0073148207167877, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:22,310] Trial 291 finished with value: 0.8179518141567478 and parameters: {'n_estimators': 264, 'max_depth': 6, 'learning_rate': 0.03671813125039521, 'subsample': 0.7326213193410214, 'colsample_bytree': 0.6729245571541838, 'gamma': 1.2602899394814673, 'min_child_weight': 4}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:23,131] Trial 292 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 255, 'max_depth': 6, 'learning_rate': 0.09989610078042509, 'subsample': 0.6737627161786893, 'colsample_bytree': 0.6912830532212839, 'gamma': 0.8476616217562907, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:24,074] Trial 293 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 268, 'max_depth': 6, 'learning_rate': 0.029364877560532285, 'subsample': 0.7120763993950574, 'colsample_bytree': 0.7020845855290129, 'gamma': 1.6573157059335624, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:24,822] Trial 294 finished with value: 0.8036915646023806 and parameters: {'n_estimators': 260, 'max_depth': 5, 'learning_rate': 0.0463293224339252, 'subsample': 0.9176567380504882, 'colsample_bytree': 0.640713407071266, 'gamma': 1.3930045151363941, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:25,915] Trial 295 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 299, 'max_depth': 6, 'learning_rate': 0.04045042423885542, 'subsample': 0.7001052904012927, 'colsample_bytree': 0.7219297277144966, 'gamma': 1.1074638764519205, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:26,900] Trial 296 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 244, 'max_depth': 6, 'learning_rate': 0.033701716701281664, 'subsample': 0.7455492904830033, 'colsample_bytree': 0.7147992843073114, 'gamma': 1.2877709349458424, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:28,017] Trial 297 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 275, 'max_depth': 6, 'learning_rate': 0.057961011738460605, 'subsample': 0.7290880594448497, 'colsample_bytree': 0.6859343171095896, 'gamma': 1.5761632430487165, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:29,959] Trial 298 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 264, 'max_depth': 5, 'learning_rate': 0.02483474791513178, 'subsample': 0.6925190925461161, 'colsample_bytree': 0.6607259553950462, 'gamma': 1.0044207723172045, 'min_child_weight': 2}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:31,054] Trial 299 finished with value: 0.7839974699557243 and parameters: {'n_estimators': 292, 'max_depth': 6, 'learning_rate': 0.2552482208130092, 'subsample': 0.7137861713823902, 'colsample_bytree': 0.6698267182688402, 'gamma': 1.443702439895181, 'min_child_weight': 6}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:32,391] Trial 300 finished with value: 0.8215072930442949 and parameters: {'n_estimators': 258, 'max_depth': 6, 'learning_rate': 0.04851924825984246, 'subsample': 0.7038656883000847, 'colsample_bytree': 0.6520958283146427, 'gamma': 1.2619607462327795, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:33,431] Trial 301 finished with value: 0.8107737718743412 and parameters: {'n_estimators': 254, 'max_depth': 6, 'learning_rate': 0.03773306921251852, 'subsample': 0.7263430306029615, 'colsample_bytree': 0.701212715910889, 'gamma': 2.6101227373392764, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:34,489] Trial 302 finished with value: 0.8089816571790007 and parameters: {'n_estimators': 269, 'max_depth': 5, 'learning_rate': 0.04294133610021453, 'subsample': 0.7876058795038589, 'colsample_bytree': 0.6792502362969093, 'gamma': 3.3535992350294137, 'min_child_weight': 4}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:35,577] Trial 303 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 248, 'max_depth': 6, 'learning_rate': 0.030931874601895358, 'subsample': 0.7120631225722976, 'colsample_bytree': 0.7170573184356973, 'gamma': 1.106548942966442, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:36,504] Trial 304 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 260, 'max_depth': 6, 'learning_rate': 0.12847738069459982, 'subsample': 0.6837749616973137, 'colsample_bytree': 0.695304234074733, 'gamma': 1.7391301158553092, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:37,240] Trial 305 finished with value: 0.7982864700132253 and parameters: {'n_estimators': 265, 'max_depth': 6, 'learning_rate': 0.05149417208470244, 'subsample': 0.8801988428886747, 'colsample_bytree': 0.6890305376768944, 'gamma': 3.859403984272859, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:38,563] Trial 306 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 273, 'max_depth': 6, 'learning_rate': 0.03619968184446869, 'subsample': 0.6971844191763528, 'colsample_bytree': 0.995717320171698, 'gamma': 0.8906537763497218, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:39,511] Trial 307 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 254, 'max_depth': 3, 'learning_rate': 0.02366757724376608, 'subsample': 0.7397665317623219, 'colsample_bytree': 0.6681381232613764, 'gamma': 1.3596598183590907, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:40,559] Trial 308 finished with value: 0.8250819389339313 and parameters: {'n_estimators': 259, 'max_depth': 6, 'learning_rate': 0.04220226382368581, 'subsample': 0.7217884455058179, 'colsample_bytree': 0.7052404814505007, 'gamma': 1.1898227720837558, 'min_child_weight': 3}. Best is trial 187 with value: 0.8286757518256569.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:41,494] Trial 309 finished with value: 0.8339850114043662 and parameters: {'n_estimators': 258, 'max_depth': 5, 'learning_rate': 0.04546030953338528, 'subsample': 0.7090012846023769, 'colsample_bytree': 0.7065613653637751, 'gamma': 1.1942623206710457, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:42,591] Trial 310 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 252, 'max_depth': 4, 'learning_rate': 0.0307183938730514, 'subsample': 0.7060084179269503, 'colsample_bytree': 0.712590880297267, 'gamma': 1.230638082383233, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:43,612] Trial 311 finished with value: 0.8268740536292718 and parameters: {'n_estimators': 256, 'max_depth': 6, 'learning_rate': 0.04329505846400737, 'subsample': 0.6881571375517174, 'colsample_bytree': 0.7065243344403611, 'gamma': 1.1875192395557406, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:44,593] Trial 312 finished with value: 0.8179326471546585 and parameters: {'n_estimators': 248, 'max_depth': 6, 'learning_rate': 0.037697863722390146, 'subsample': 0.6716220338248106, 'colsample_bytree': 0.7039612149241151, 'gamma': 1.1584091010755593, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:45,648] Trial 313 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 257, 'max_depth': 7, 'learning_rate': 0.0260630713545774, 'subsample': 0.6804927836883012, 'colsample_bytree': 0.7078768980612952, 'gamma': 0.9985788255254285, 'min_child_weight': 4}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:46,813] Trial 314 finished with value: 0.810754604872252 and parameters: {'n_estimators': 250, 'max_depth': 5, 'learning_rate': 0.05281282950818286, 'subsample': 0.6914959679962367, 'colsample_bytree': 0.6947497383479481, 'gamma': 0.0003121477328318356, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:47,867] Trial 315 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 255, 'max_depth': 6, 'learning_rate': 0.04108405363905929, 'subsample': 0.6875600009801175, 'colsample_bytree': 0.7227357523005857, 'gamma': 1.1555789889868096, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:48,746] Trial 316 finished with value: 0.82330899124068 and parameters: {'n_estimators': 253, 'max_depth': 6, 'learning_rate': 0.0427527925893532, 'subsample': 0.6857831740409193, 'colsample_bytree': 0.715618421942985, 'gamma': 1.333688130123016, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:49,678] Trial 317 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 253, 'max_depth': 6, 'learning_rate': 0.04403962565956123, 'subsample': 0.6779739830956852, 'colsample_bytree': 0.7190033228484812, 'gamma': 1.3304736687553325, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:50,643] Trial 318 finished with value: 0.8071991259847048 and parameters: {'n_estimators': 247, 'max_depth': 6, 'learning_rate': 0.08122182734180516, 'subsample': 0.6682932329677826, 'colsample_bytree': 0.7175717384871368, 'gamma': 1.1951901331429617, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:51,427] Trial 319 finished with value: 0.8197151783489544 and parameters: {'n_estimators': 142, 'max_depth': 6, 'learning_rate': 0.0582985752273109, 'subsample': 0.699887353621572, 'colsample_bytree': 0.6848371744956067, 'gamma': 1.4329895883230321, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:52,306] Trial 320 finished with value: 0.8072374599888832 and parameters: {'n_estimators': 243, 'max_depth': 5, 'learning_rate': 0.049961611204293245, 'subsample': 0.7977201682849274, 'colsample_bytree': 0.7238735518630321, 'gamma': 1.3352650129553711, 'min_child_weight': 4}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:53,726] Trial 321 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 253, 'max_depth': 6, 'learning_rate': 0.04402802109798289, 'subsample': 0.6857569027774983, 'colsample_bytree': 0.7004796815650511, 'gamma': 1.2590014846964714, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:54,703] Trial 322 finished with value: 0.8126042205738601 and parameters: {'n_estimators': 256, 'max_depth': 6, 'learning_rate': 0.04746016283121974, 'subsample': 0.7195805382804012, 'colsample_bytree': 0.7119778832835663, 'gamma': 1.1503577466282877, 'min_child_weight': 4}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:55,697] Trial 323 finished with value: 0.8143484177639775 and parameters: {'n_estimators': 257, 'max_depth': 6, 'learning_rate': 0.04112670248305968, 'subsample': 0.7332632302423323, 'colsample_bytree': 0.6775083711333635, 'gamma': 1.471229818085637, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:56,477] Trial 324 finished with value: 0.7965039388189293 and parameters: {'n_estimators': 250, 'max_depth': 7, 'learning_rate': 0.2959328450071246, 'subsample': 0.7143036127243123, 'colsample_bytree': 0.6964187887429599, 'gamma': 1.3180873639020756, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:57,543] Trial 325 finished with value: 0.8215072930442949 and parameters: {'n_estimators': 259, 'max_depth': 6, 'learning_rate': 0.03197879872860296, 'subsample': 0.702434537390727, 'colsample_bytree': 0.6883221283665354, 'gamma': 1.1953828326619966, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:58,467] Trial 326 finished with value: 0.816140532459318 and parameters: {'n_estimators': 255, 'max_depth': 5, 'learning_rate': 0.055405078584537686, 'subsample': 0.7253162153611622, 'colsample_bytree': 0.7070083487662712, 'gamma': 1.3907069862053605, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:39:59,189] Trial 327 finished with value: 0.803634063596113 and parameters: {'n_estimators': 250, 'max_depth': 6, 'learning_rate': 0.15228311470971773, 'subsample': 0.708303729114559, 'colsample_bytree': 0.7265502492217265, 'gamma': 1.5184762403352416, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:39:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:00,199] Trial 328 finished with value: 0.8232802407375462 and parameters: {'n_estimators': 260, 'max_depth': 6, 'learning_rate': 0.03949474282975106, 'subsample': 0.6967211644558959, 'colsample_bytree': 0.7147618061219834, 'gamma': 1.214264891510238, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:01,061] Trial 329 finished with value: 0.7964751883157956 and parameters: {'n_estimators': 247, 'max_depth': 6, 'learning_rate': 0.21249085479965246, 'subsample': 0.678494618262997, 'colsample_bytree': 0.6808971439279634, 'gamma': 1.131061187484871, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:02,117] Trial 330 finished with value: 0.8250723554328867 and parameters: {'n_estimators': 255, 'max_depth': 6, 'learning_rate': 0.05107527305962896, 'subsample': 0.7171170019152568, 'colsample_bytree': 0.7000369631654043, 'gamma': 1.2981775207467905, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:02,980] Trial 331 finished with value: 0.8161309489582734 and parameters: {'n_estimators': 253, 'max_depth': 5, 'learning_rate': 0.058428274176002604, 'subsample': 0.6889984387291045, 'colsample_bytree': 0.7036006614653684, 'gamma': 1.380418530397179, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:03,834] Trial 332 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 244, 'max_depth': 4, 'learning_rate': 0.06478433406009158, 'subsample': 0.7124551837383056, 'colsample_bytree': 0.6956863034819925, 'gamma': 1.2928112665249112, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:04,678] Trial 333 finished with value: 0.8179518141567478 and parameters: {'n_estimators': 238, 'max_depth': 6, 'learning_rate': 0.05115165174840349, 'subsample': 0.6644895624541753, 'colsample_bytree': 0.7199685477837992, 'gamma': 1.093367368079654, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:05,541] Trial 334 finished with value: 0.814386751768156 and parameters: {'n_estimators': 257, 'max_depth': 6, 'learning_rate': 0.04801921911101105, 'subsample': 0.7031876993355876, 'colsample_bytree': 0.7080582775271477, 'gamma': 1.4775778154782062, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:06,387] Trial 335 finished with value: 0.7875529488432714 and parameters: {'n_estimators': 251, 'max_depth': 6, 'learning_rate': 0.05303559191536851, 'subsample': 0.7788296641530743, 'colsample_bytree': 0.6985609610915907, 'gamma': 1.317905365254946, 'min_child_weight': 10}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:07,814] Trial 336 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 256, 'max_depth': 6, 'learning_rate': 0.044282221489758786, 'subsample': 0.7296611500659025, 'colsample_bytree': 0.7248837579864476, 'gamma': 1.1889923586182225, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:09,156] Trial 337 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 261, 'max_depth': 5, 'learning_rate': 0.04180515613752981, 'subsample': 0.718486443765043, 'colsample_bytree': 0.7148193943015155, 'gamma': 1.3979165619210876, 'min_child_weight': 4}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:11,774] Trial 338 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 255, 'max_depth': 6, 'learning_rate': 0.04767536215209337, 'subsample': 0.7070936770695255, 'colsample_bytree': 0.6895913987746016, 'gamma': 1.5452842642186446, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:13,094] Trial 339 finished with value: 0.8304486995189082 and parameters: {'n_estimators': 263, 'max_depth': 6, 'learning_rate': 0.035559142507163535, 'subsample': 0.7553174461473982, 'colsample_bytree': 0.7046700718722059, 'gamma': 1.0897635650748112, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:14,140] Trial 340 finished with value: 0.8233089912406801 and parameters: {'n_estimators': 264, 'max_depth': 7, 'learning_rate': 0.032377910575023025, 'subsample': 0.7579008793008356, 'colsample_bytree': 0.7032226932695667, 'gamma': 1.0420724343165395, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:15,310] Trial 341 finished with value: 0.8143484177639775 and parameters: {'n_estimators': 265, 'max_depth': 8, 'learning_rate': 0.021839464773693057, 'subsample': 0.7634247935348926, 'colsample_bytree': 0.7057235523421943, 'gamma': 0.9152197172662734, 'min_child_weight': 4}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:16,308] Trial 342 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 264, 'max_depth': 7, 'learning_rate': 0.06342318157037127, 'subsample': 0.7542125673734923, 'colsample_bytree': 0.7012563750429457, 'gamma': 1.2694402812830181, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:17,425] Trial 343 finished with value: 0.7982673030111361 and parameters: {'n_estimators': 262, 'max_depth': 8, 'learning_rate': 0.07256957534959504, 'subsample': 0.7572169417785155, 'colsample_bytree': 0.7111921707551977, 'gamma': 0.7588114907603724, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:18,265] Trial 344 finished with value: 0.8108121058785196 and parameters: {'n_estimators': 261, 'max_depth': 3, 'learning_rate': 0.03486319002609344, 'subsample': 0.7710779444493705, 'colsample_bytree': 0.6968337053904987, 'gamma': 1.0708093313560971, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:19,195] Trial 345 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 266, 'max_depth': 4, 'learning_rate': 0.05172847996784843, 'subsample': 0.7489627034106804, 'colsample_bytree': 0.705928429643191, 'gamma': 1.4184615204644488, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:20,236] Trial 346 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 260, 'max_depth': 7, 'learning_rate': 0.026203486690698906, 'subsample': 0.7414252324734221, 'colsample_bytree': 0.7161494479365761, 'gamma': 1.2345822322811086, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:21,288] Trial 347 finished with value: 0.814386751768156 and parameters: {'n_estimators': 295, 'max_depth': 5, 'learning_rate': 0.03711243512334272, 'subsample': 0.7502310477123423, 'colsample_bytree': 0.6983031236802392, 'gamma': 1.325624804427173, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:22,310] Trial 348 finished with value: 0.8197055948479098 and parameters: {'n_estimators': 266, 'max_depth': 5, 'learning_rate': 0.045762332129710266, 'subsample': 0.7705837425831423, 'colsample_bytree': 0.6660777958498866, 'gamma': 1.104285397878627, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:23,103] Trial 349 finished with value: 0.814386751768156 and parameters: {'n_estimators': 247, 'max_depth': 6, 'learning_rate': 0.05805653315309006, 'subsample': 0.7576638626991303, 'colsample_bytree': 0.7088757396952494, 'gamma': 2.3685302479290344, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:24,232] Trial 350 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 289, 'max_depth': 6, 'learning_rate': 0.030356901566970955, 'subsample': 0.7436757994835846, 'colsample_bytree': 0.6885332548051181, 'gamma': 1.1875618955396927, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:25,292] Trial 351 finished with value: 0.8197151783489544 and parameters: {'n_estimators': 260, 'max_depth': 6, 'learning_rate': 0.04021374630598488, 'subsample': 0.7368332204631132, 'colsample_bytree': 0.7166701328382256, 'gamma': 0.9112733408367454, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:26,214] Trial 352 finished with value: 0.8107737718743412 and parameters: {'n_estimators': 253, 'max_depth': 5, 'learning_rate': 0.036373649144484245, 'subsample': 0.7333068218546344, 'colsample_bytree': 0.7385960714826837, 'gamma': 1.5273521830309682, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:26,949] Trial 353 finished with value: 0.8179326471546585 and parameters: {'n_estimators': 111, 'max_depth': 7, 'learning_rate': 0.047256213109561185, 'subsample': 0.7260631504548267, 'colsample_bytree': 0.6472354132133369, 'gamma': 1.2924076735719725, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:27,942] Trial 354 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 264, 'max_depth': 6, 'learning_rate': 0.055914265753036096, 'subsample': 0.7398265049635219, 'colsample_bytree': 0.6753131089823724, 'gamma': 1.007456940496611, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:29,340] Trial 355 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 269, 'max_depth': 6, 'learning_rate': 0.042243872266860175, 'subsample': 0.7211155860626322, 'colsample_bytree': 0.7037037076500543, 'gamma': 0.6334252439915892, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:30,296] Trial 356 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 250, 'max_depth': 6, 'learning_rate': 0.02844055644735259, 'subsample': 0.7473464683563958, 'colsample_bytree': 0.7298808179174167, 'gamma': 1.373912436269617, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:31,925] Trial 357 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 258, 'max_depth': 5, 'learning_rate': 0.034976237668818196, 'subsample': 0.7267102885256539, 'colsample_bytree': 0.6832372652761831, 'gamma': 1.1087419720282967, 'min_child_weight': 5}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:32,997] Trial 358 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 241, 'max_depth': 6, 'learning_rate': 0.050978797560347205, 'subsample': 0.717499343966945, 'colsample_bytree': 0.6935156753856225, 'gamma': 1.2266026450791383, 'min_child_weight': 4}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:34,224] Trial 359 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 263, 'max_depth': 6, 'learning_rate': 0.02152151074072948, 'subsample': 0.7132777591861104, 'colsample_bytree': 0.7100111784882369, 'gamma': 1.6210859120077825, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:35,296] Trial 360 finished with value: 0.816140532459318 and parameters: {'n_estimators': 258, 'max_depth': 6, 'learning_rate': 0.04175438634124159, 'subsample': 0.733674870462275, 'colsample_bytree': 0.7220058792780385, 'gamma': 1.44450460684221, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:36,344] Trial 361 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 253, 'max_depth': 4, 'learning_rate': 0.03225307834449604, 'subsample': 0.7073835141597293, 'colsample_bytree': 0.6623688169360925, 'gamma': 0.9686791960253334, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:37,415] Trial 362 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 262, 'max_depth': 6, 'learning_rate': 0.04730943706461174, 'subsample': 0.7634796866455824, 'colsample_bytree': 0.6998983914240405, 'gamma': 1.1656096574176076, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:38,519] Trial 363 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 269, 'max_depth': 6, 'learning_rate': 0.03842610331378774, 'subsample': 0.7224586620367717, 'colsample_bytree': 0.7517386696368553, 'gamma': 1.2799422966698795, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:39,305] Trial 364 finished with value: 0.7875625323443161 and parameters: {'n_estimators': 244, 'max_depth': 8, 'learning_rate': 0.028157570838649032, 'subsample': 0.7149847432095603, 'colsample_bytree': 0.6716038062797506, 'gamma': 1.1095356712079023, 'min_child_weight': 9}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:40,202] Trial 365 finished with value: 0.8197151783489544 and parameters: {'n_estimators': 249, 'max_depth': 5, 'learning_rate': 0.052208740009068194, 'subsample': 0.6986330077733063, 'colsample_bytree': 0.713983744397315, 'gamma': 1.3754124539153698, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:41,134] Trial 366 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 256, 'max_depth': 6, 'learning_rate': 0.04110530165580799, 'subsample': 0.728487208059187, 'colsample_bytree': 0.684596727283421, 'gamma': 1.4713525705688402, 'min_child_weight': 4}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:42,172] Trial 367 finished with value: 0.8143388342629329 and parameters: {'n_estimators': 197, 'max_depth': 6, 'learning_rate': 0.03467616090404077, 'subsample': 0.7091258678629458, 'colsample_bytree': 0.7317664881089581, 'gamma': 1.037894609919407, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:43,128] Trial 368 finished with value: 0.819724761849999 and parameters: {'n_estimators': 267, 'max_depth': 6, 'learning_rate': 0.04444421248152262, 'subsample': 0.7419736354512473, 'colsample_bytree': 0.7025175782046041, 'gamma': 1.258365006854296, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:44,387] Trial 369 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 259, 'max_depth': 7, 'learning_rate': 0.0230577476589029, 'subsample': 0.7206264566090014, 'colsample_bytree': 0.6941606951212387, 'gamma': 0.8371454990941846, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:45,334] Trial 370 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 253, 'max_depth': 6, 'learning_rate': 0.06100598131048217, 'subsample': 0.7024039051963789, 'colsample_bytree': 0.7112376048015225, 'gamma': 1.1728946987665558, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:46,777] Trial 371 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 263, 'max_depth': 6, 'learning_rate': 0.04784312006298029, 'subsample': 0.7124300749436608, 'colsample_bytree': 0.6208114448132506, 'gamma': 0.9559835955649374, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:47,799] Trial 372 finished with value: 0.8250723554328867 and parameters: {'n_estimators': 259, 'max_depth': 5, 'learning_rate': 0.0372826461366631, 'subsample': 0.7330377788630412, 'colsample_bytree': 0.7237308620622076, 'gamma': 1.3047693750496092, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:48,744] Trial 373 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 251, 'max_depth': 5, 'learning_rate': 0.054778788030451546, 'subsample': 0.7372384225682643, 'colsample_bytree': 0.6542451217199033, 'gamma': 1.5764991994649638, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:49,635] Trial 374 finished with value: 0.8197055948479098 and parameters: {'n_estimators': 258, 'max_depth': 5, 'learning_rate': 0.03993599230521666, 'subsample': 0.7320419364754439, 'colsample_bytree': 0.735506095852881, 'gamma': 1.373660562997024, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:50,441] Trial 375 finished with value: 0.7929101259272038 and parameters: {'n_estimators': 255, 'max_depth': 5, 'learning_rate': 0.27635114983366244, 'subsample': 0.7499894454395403, 'colsample_bytree': 0.6737998466092705, 'gamma': 1.0754603855344165, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:51,606] Trial 376 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 260, 'max_depth': 5, 'learning_rate': 0.045281379637645044, 'subsample': 0.7253950225498765, 'colsample_bytree': 0.7232886893744591, 'gamma': 1.200061559361545, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:52,436] Trial 377 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 247, 'max_depth': 5, 'learning_rate': 0.03035216570785605, 'subsample': 0.7557214936538864, 'colsample_bytree': 0.6819760557554488, 'gamma': 2.1698645034098014, 'min_child_weight': 4}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:53,432] Trial 378 finished with value: 0.8197055948479098 and parameters: {'n_estimators': 255, 'max_depth': 5, 'learning_rate': 0.06886269858985296, 'subsample': 0.7334235939594834, 'colsample_bytree': 0.7422640839972183, 'gamma': 1.3277524970513188, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:54,285] Trial 379 finished with value: 0.803634063596113 and parameters: {'n_estimators': 263, 'max_depth': 4, 'learning_rate': 0.11363823629827992, 'subsample': 0.7426734453000315, 'colsample_bytree': 0.6906334666046872, 'gamma': 1.4695939302940708, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:55,288] Trial 380 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 251, 'max_depth': 5, 'learning_rate': 0.03821900021162135, 'subsample': 0.721132017152648, 'colsample_bytree': 0.7271107881758739, 'gamma': 1.137276825041592, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:56,239] Trial 381 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 259, 'max_depth': 5, 'learning_rate': 0.05148663684212706, 'subsample': 0.7270662479200042, 'colsample_bytree': 0.7038343049669967, 'gamma': 1.2533762185063466, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:57,374] Trial 382 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 266, 'max_depth': 6, 'learning_rate': 0.04341718466629215, 'subsample': 0.7147438939136902, 'colsample_bytree': 0.6660081797905473, 'gamma': 1.0216534959780068, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:58,316] Trial 383 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 255, 'max_depth': 6, 'learning_rate': 0.034056920356987805, 'subsample': 0.7071851894220056, 'colsample_bytree': 0.7633752875292217, 'gamma': 1.3943279977417535, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:40:59,223] Trial 384 finished with value: 0.7946926571214997 and parameters: {'n_estimators': 247, 'max_depth': 5, 'learning_rate': 0.024561069140113388, 'subsample': 0.7157435569012056, 'colsample_bytree': 0.6980495716765351, 'gamma': 1.187057494331486, 'min_child_weight': 8}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:40:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:00,274] Trial 385 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.04611293984665956, 'subsample': 0.7241429462829796, 'colsample_bytree': 0.6415931071748205, 'gamma': 1.5694487193887712, 'min_child_weight': 4}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:01,007] Trial 386 finished with value: 0.794730991125678 and parameters: {'n_estimators': 261, 'max_depth': 9, 'learning_rate': 0.2250850687532644, 'subsample': 0.7366568066126543, 'colsample_bytree': 0.7742048659331002, 'gamma': 1.3209339305147345, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:02,005] Trial 387 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 252, 'max_depth': 6, 'learning_rate': 0.057818320071042394, 'subsample': 0.7005530495323906, 'colsample_bytree': 0.712262924793879, 'gamma': 0.9550698347805345, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:03,079] Trial 388 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 257, 'max_depth': 6, 'learning_rate': 0.037294881347119606, 'subsample': 0.7483868192098768, 'colsample_bytree': 0.6619892345865722, 'gamma': 1.1012619131692811, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:04,382] Trial 389 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 264, 'max_depth': 7, 'learning_rate': 0.03040243755799766, 'subsample': 0.7169843600200521, 'colsample_bytree': 0.7199275236630872, 'gamma': 0.7738261113755759, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:05,433] Trial 390 finished with value: 0.8179326471546585 and parameters: {'n_estimators': 259, 'max_depth': 5, 'learning_rate': 0.049068025176664316, 'subsample': 0.7079398167895441, 'colsample_bytree': 0.6911729729414271, 'gamma': 1.4168422081917766, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:06,321] Trial 391 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 250, 'max_depth': 4, 'learning_rate': 0.04093652107205133, 'subsample': 0.7296666159035965, 'colsample_bytree': 0.6796715168218282, 'gamma': 1.964165688211843, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:07,317] Trial 392 finished with value: 0.810802522377475 and parameters: {'n_estimators': 267, 'max_depth': 6, 'learning_rate': 0.05355816917362042, 'subsample': 0.7215226764932035, 'colsample_bytree': 0.7323011794593481, 'gamma': 1.2886060911318433, 'min_child_weight': 5}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:08,614] Trial 393 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 158, 'max_depth': 6, 'learning_rate': 0.03448570105683605, 'subsample': 0.7111221108898202, 'colsample_bytree': 0.7028658197765922, 'gamma': 1.1807732284281691, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:09,472] Trial 394 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 254, 'max_depth': 5, 'learning_rate': 0.04260739149906657, 'subsample': 0.6999440331587707, 'colsample_bytree': 0.7089359048706867, 'gamma': 1.5139800259322396, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:10,484] Trial 395 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 244, 'max_depth': 6, 'learning_rate': 0.02738730721069188, 'subsample': 0.7265422334526221, 'colsample_bytree': 0.6751336186809201, 'gamma': 1.0541513850286903, 'min_child_weight': 4}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:11,627] Trial 396 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 261, 'max_depth': 6, 'learning_rate': 0.020292453649207, 'subsample': 0.7383984731372195, 'colsample_bytree': 0.7224634572777151, 'gamma': 0.9109042688042615, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:12,388] Trial 397 finished with value: 0.8071895424836603 and parameters: {'n_estimators': 257, 'max_depth': 3, 'learning_rate': 0.04881154124915245, 'subsample': 0.7730639707394799, 'colsample_bytree': 0.9859098636539149, 'gamma': 4.114354303153344, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:13,416] Trial 398 finished with value: 0.8036436470971576 and parameters: {'n_estimators': 295, 'max_depth': 6, 'learning_rate': 0.03808315385294803, 'subsample': 0.7622362360513943, 'colsample_bytree': 0.6880462700417176, 'gamma': 1.2515370302650144, 'min_child_weight': 7}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:14,430] Trial 399 finished with value: 0.82330899124068 and parameters: {'n_estimators': 264, 'max_depth': 6, 'learning_rate': 0.04433701752734953, 'subsample': 0.7061201496740647, 'colsample_bytree': 0.6973536558756013, 'gamma': 1.3472995513624895, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:15,538] Trial 400 finished with value: 0.8143484177639776 and parameters: {'n_estimators': 269, 'max_depth': 5, 'learning_rate': 0.05831653004537807, 'subsample': 0.704630881622945, 'colsample_bytree': 0.6991904658689626, 'gamma': 3.190577885074708, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:16,444] Trial 401 finished with value: 0.8000402507043874 and parameters: {'n_estimators': 265, 'max_depth': 6, 'learning_rate': 0.13813810606984686, 'subsample': 0.6939239473372973, 'colsample_bytree': 0.7133781834516104, 'gamma': 1.1415880574190116, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:17,554] Trial 402 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 270, 'max_depth': 6, 'learning_rate': 0.04563656239661812, 'subsample': 0.6824249726419257, 'colsample_bytree': 0.70497213807331, 'gamma': 1.3228790315534005, 'min_child_weight': 1}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:18,761] Trial 403 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 263, 'max_depth': 6, 'learning_rate': 0.03303647068253873, 'subsample': 0.6987647937607614, 'colsample_bytree': 0.6923479917135708, 'gamma': 1.0521636893530133, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:19,760] Trial 404 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 261, 'max_depth': 5, 'learning_rate': 0.05194715682268799, 'subsample': 0.7082559603436737, 'colsample_bytree': 0.7142089626044352, 'gamma': 1.2216021661127747, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:20,668] Trial 405 finished with value: 0.817923063653614 and parameters: {'n_estimators': 288, 'max_depth': 7, 'learning_rate': 0.039696935831950164, 'subsample': 0.7137095665494189, 'colsample_bytree': 0.6971750799655295, 'gamma': 1.845336359516924, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:21,435] Trial 406 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 174, 'max_depth': 6, 'learning_rate': 0.026836715976124238, 'subsample': 0.7456558613174428, 'colsample_bytree': 0.7551266920903211, 'gamma': 1.4556623983129093, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:22,371] Trial 407 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 265, 'max_depth': 6, 'learning_rate': 0.06165379589850863, 'subsample': 0.7037485003865357, 'colsample_bytree': 0.7397158460429067, 'gamma': 1.3472146394074573, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:23,512] Trial 408 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 272, 'max_depth': 6, 'learning_rate': 0.046442300603120545, 'subsample': 0.687002678758907, 'colsample_bytree': 0.726378242009358, 'gamma': 0.9860330146748163, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:24,627] Trial 409 finished with value: 0.8268644701282272 and parameters: {'n_estimators': 259, 'max_depth': 5, 'learning_rate': 0.03415594361799753, 'subsample': 0.7193536568420951, 'colsample_bytree': 0.7083884763047846, 'gamma': 1.1238686295041616, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:25,518] Trial 410 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 257, 'max_depth': 6, 'learning_rate': 0.1826772220939431, 'subsample': 0.717347957955977, 'colsample_bytree': 0.7048408662763239, 'gamma': 1.1187651523226045, 'min_child_weight': 4}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:26,635] Trial 411 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 259, 'max_depth': 5, 'learning_rate': 0.031229821995575693, 'subsample': 0.6977211677857896, 'colsample_bytree': 0.7182577379688125, 'gamma': 0.8218318156314798, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:27,744] Trial 412 finished with value: 0.8143484177639776 and parameters: {'n_estimators': 254, 'max_depth': 8, 'learning_rate': 0.019985060288005552, 'subsample': 0.7094702331209406, 'colsample_bytree': 0.7088846898830001, 'gamma': 1.237715153123529, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:28,832] Trial 413 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 249, 'max_depth': 6, 'learning_rate': 0.0357837347344833, 'subsample': 0.7213219074633325, 'colsample_bytree': 0.6958063906562317, 'gamma': 0.9301664478931971, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:30,015] Trial 414 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 262, 'max_depth': 6, 'learning_rate': 0.0267610850756052, 'subsample': 0.7127984892263372, 'colsample_bytree': 0.7089587434634967, 'gamma': 1.0613089355949437, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:30,869] Trial 415 finished with value: 0.8214881260422057 and parameters: {'n_estimators': 255, 'max_depth': 6, 'learning_rate': 0.05432773692190994, 'subsample': 0.6972528468195208, 'colsample_bytree': 0.7196073226432915, 'gamma': 1.3869718404529814, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:32,245] Trial 416 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 259, 'max_depth': 5, 'learning_rate': 0.04231075352826978, 'subsample': 0.7061837175415905, 'colsample_bytree': 0.7003562576681508, 'gamma': 1.633758766234945, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:33,444] Trial 417 finished with value: 0.8215168765453394 and parameters: {'n_estimators': 252, 'max_depth': 6, 'learning_rate': 0.0346640979664003, 'subsample': 0.7277469635162405, 'colsample_bytree': 0.7299016664793772, 'gamma': 1.1581450769155812, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:34,902] Trial 418 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 240, 'max_depth': 4, 'learning_rate': 0.04892907184615704, 'subsample': 0.6745982989746085, 'colsample_bytree': 0.7139691045005262, 'gamma': 0.17990630113400963, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:36,177] Trial 419 finished with value: 0.8215072930442949 and parameters: {'n_estimators': 267, 'max_depth': 6, 'learning_rate': 0.03734423786425847, 'subsample': 0.7205989716386636, 'colsample_bytree': 0.7032197920170543, 'gamma': 1.2772058820589134, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:37,460] Trial 420 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 246, 'max_depth': 6, 'learning_rate': 0.029123073275377238, 'subsample': 0.6896220704280628, 'colsample_bytree': 0.6903332480122487, 'gamma': 0.3789803746439069, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:38,348] Trial 421 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 257, 'max_depth': 6, 'learning_rate': 0.04371429609912533, 'subsample': 0.7160459846463898, 'colsample_bytree': 0.7471407360657094, 'gamma': 2.732644349401237, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:39,932] Trial 422 finished with value: 0.8197151783489546 and parameters: {'n_estimators': 263, 'max_depth': 5, 'learning_rate': 0.024151069003530926, 'subsample': 0.7041974665410913, 'colsample_bytree': 0.7227298968402512, 'gamma': 1.452029919884024, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:41,428] Trial 423 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 250, 'max_depth': 7, 'learning_rate': 0.03906346216413732, 'subsample': 0.7301840557668687, 'colsample_bytree': 0.633791114895688, 'gamma': 0.5181615501412562, 'min_child_weight': 4}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:42,684] Trial 424 finished with value: 0.808972073677956 and parameters: {'n_estimators': 260, 'max_depth': 6, 'learning_rate': 0.052365512781164025, 'subsample': 0.7094694196928435, 'colsample_bytree': 0.7097340786554281, 'gamma': 1.0438641006307892, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:43,776] Trial 425 finished with value: 0.821507293044295 and parameters: {'n_estimators': 255, 'max_depth': 5, 'learning_rate': 0.06528210753780778, 'subsample': 0.6972509711295011, 'colsample_bytree': 0.7352415715582619, 'gamma': 1.2008631640350385, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:44,936] Trial 426 finished with value: 0.8196960113468652 and parameters: {'n_estimators': 264, 'max_depth': 6, 'learning_rate': 0.03215535583236321, 'subsample': 0.7189965407199456, 'colsample_bytree': 0.6990941284357286, 'gamma': 0.8689908249659308, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:45,698] Trial 427 finished with value: 0.8054261782914535 and parameters: {'n_estimators': 131, 'max_depth': 6, 'learning_rate': 0.04461485065083706, 'subsample': 0.6825596615229106, 'colsample_bytree': 0.6859714907661595, 'gamma': 1.3109392549957721, 'min_child_weight': 6}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:46,442] Trial 428 finished with value: 0.8090391581852683 and parameters: {'n_estimators': 259, 'max_depth': 6, 'learning_rate': 0.04866912479281403, 'subsample': 0.8207416810254192, 'colsample_bytree': 0.7166059771263867, 'gamma': 1.5393197229102114, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:47,511] Trial 429 finished with value: 0.8215072930442949 and parameters: {'n_estimators': 253, 'max_depth': 6, 'learning_rate': 0.03756192920990258, 'subsample': 0.7245007916303894, 'colsample_bytree': 0.7271404868288136, 'gamma': 1.1029375216304897, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:48,822] Trial 430 finished with value: 0.8090391581852683 and parameters: {'n_estimators': 267, 'max_depth': 9, 'learning_rate': 0.01716568048695624, 'subsample': 0.9493277663056194, 'colsample_bytree': 0.7053277080228735, 'gamma': 0.9878100386852937, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:49,779] Trial 431 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 257, 'max_depth': 6, 'learning_rate': 0.05721918480533367, 'subsample': 0.7114764992703714, 'colsample_bytree': 0.69581135352327, 'gamma': 1.3842938960756797, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:50,625] Trial 432 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 245, 'max_depth': 4, 'learning_rate': 0.03203444221872716, 'subsample': 0.6934574673130128, 'colsample_bytree': 0.713349634069675, 'gamma': 1.2303452701147695, 'min_child_weight': 4}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:51,615] Trial 433 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 263, 'max_depth': 5, 'learning_rate': 0.04351921815218535, 'subsample': 0.733314959503748, 'colsample_bytree': 0.6860743652134917, 'gamma': 1.1183827115711191, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:52,657] Trial 434 finished with value: 0.8126138040749047 and parameters: {'n_estimators': 251, 'max_depth': 6, 'learning_rate': 0.02681563927450637, 'subsample': 0.7819828071519515, 'colsample_bytree': 0.7403205668994366, 'gamma': 1.3160379008614267, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:53,677] Trial 435 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 292, 'max_depth': 6, 'learning_rate': 0.04000578334939058, 'subsample': 0.71380641838681, 'colsample_bytree': 0.7058344749301722, 'gamma': 1.1984793019411557, 'min_child_weight': 4}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:54,683] Trial 436 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 261, 'max_depth': 6, 'learning_rate': 0.04941006320720184, 'subsample': 0.7013908156890952, 'colsample_bytree': 0.9724971424258827, 'gamma': 1.471927345160765, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:55,949] Trial 437 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 268, 'max_depth': 5, 'learning_rate': 0.0361804638757396, 'subsample': 0.7211683667962895, 'colsample_bytree': 0.7222827598119894, 'gamma': 0.9703154057552951, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:56,997] Trial 438 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 255, 'max_depth': 7, 'learning_rate': 0.021039634638962787, 'subsample': 0.7041752614723155, 'colsample_bytree': 0.691912335827317, 'gamma': 1.3454478782323969, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:58,131] Trial 439 finished with value: 0.8196864278458206 and parameters: {'n_estimators': 258, 'max_depth': 6, 'learning_rate': 0.043342037150613806, 'subsample': 0.7558429757912428, 'colsample_bytree': 0.700738319015175, 'gamma': 0.6858763332466907, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:41:59,084] Trial 440 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 249, 'max_depth': 8, 'learning_rate': 0.05363923904355494, 'subsample': 0.7403472302351279, 'colsample_bytree': 0.7296776693769462, 'gamma': 1.1108346915633622, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:41:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:00,229] Trial 441 finished with value: 0.8250723554328867 and parameters: {'n_estimators': 266, 'max_depth': 6, 'learning_rate': 0.029874608721651777, 'subsample': 0.6911675943485293, 'colsample_bytree': 0.6942950411716448, 'gamma': 1.2457027985426712, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:01,593] Trial 442 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 270, 'max_depth': 6, 'learning_rate': 0.012593177215096008, 'subsample': 0.6795026110723268, 'colsample_bytree': 0.6823745161214394, 'gamma': 1.2344399389896148, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:03,312] Trial 443 finished with value: 0.8268740536292718 and parameters: {'n_estimators': 264, 'max_depth': 5, 'learning_rate': 0.0288894118269721, 'subsample': 0.6901487164804612, 'colsample_bytree': 0.689164918448831, 'gamma': 1.0672188682191828, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:04,514] Trial 444 finished with value: 0.8215072930442949 and parameters: {'n_estimators': 284, 'max_depth': 5, 'learning_rate': 0.022435462552923457, 'subsample': 0.6848007584836074, 'colsample_bytree': 0.6806958239128256, 'gamma': 0.8781536630392434, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:05,734] Trial 445 finished with value: 0.8215072930442949 and parameters: {'n_estimators': 274, 'max_depth': 5, 'learning_rate': 0.018800879711139324, 'subsample': 0.6697143356503652, 'colsample_bytree': 0.6878724231781495, 'gamma': 1.0502837053321445, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:06,880] Trial 446 finished with value: 0.8179230636536139 and parameters: {'n_estimators': 265, 'max_depth': 5, 'learning_rate': 0.02877801286319526, 'subsample': 0.6764300899146987, 'colsample_bytree': 0.6506327754009469, 'gamma': 0.9210897484798635, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:07,967] Trial 447 finished with value: 0.8197151783489546 and parameters: {'n_estimators': 268, 'max_depth': 5, 'learning_rate': 0.028812664391448507, 'subsample': 0.6895318344477814, 'colsample_bytree': 0.6899255758627495, 'gamma': 1.0064286826852107, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:09,001] Trial 448 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 261, 'max_depth': 5, 'learning_rate': 0.03189112527903833, 'subsample': 0.687719453731672, 'colsample_bytree': 0.6962776294889362, 'gamma': 1.1636601095350847, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:10,066] Trial 449 finished with value: 0.8125467195675925 and parameters: {'n_estimators': 261, 'max_depth': 5, 'learning_rate': 0.02448317658639961, 'subsample': 0.6920310777402287, 'colsample_bytree': 0.622847042499558, 'gamma': 1.0639616548689228, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:11,238] Trial 450 finished with value: 0.8125563030686371 and parameters: {'n_estimators': 271, 'max_depth': 5, 'learning_rate': 0.03316530091523029, 'subsample': 0.6667640101715412, 'colsample_bytree': 0.6823559211289892, 'gamma': 1.1264425817095527, 'min_child_weight': 1}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:12,380] Trial 451 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 266, 'max_depth': 5, 'learning_rate': 0.012686612108491088, 'subsample': 0.6976071286229258, 'colsample_bytree': 0.7042972056878517, 'gamma': 0.8113999365272482, 'min_child_weight': 4}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:13,467] Trial 452 finished with value: 0.8197151783489544 and parameters: {'n_estimators': 255, 'max_depth': 5, 'learning_rate': 0.027587127801669494, 'subsample': 0.6833656438365336, 'colsample_bytree': 0.7154179253833057, 'gamma': 0.9881725889920088, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:14,512] Trial 453 finished with value: 0.8179326471546585 and parameters: {'n_estimators': 259, 'max_depth': 5, 'learning_rate': 0.03478962891940178, 'subsample': 0.6780315929119767, 'colsample_bytree': 0.7522976805339313, 'gamma': 1.1879813167502609, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:15,571] Trial 454 finished with value: 0.8143484177639776 and parameters: {'n_estimators': 253, 'max_depth': 3, 'learning_rate': 0.022611858827904795, 'subsample': 0.6966518466332399, 'colsample_bytree': 0.6746573208911558, 'gamma': 1.0531698737865742, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:16,630] Trial 455 finished with value: 0.8214977095432504 and parameters: {'n_estimators': 264, 'max_depth': 4, 'learning_rate': 0.035877332518032656, 'subsample': 0.6926091444338737, 'colsample_bytree': 0.6890338559084066, 'gamma': 1.260810129380729, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:18,277] Trial 456 finished with value: 0.8179326471546585 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.018063025108892173, 'subsample': 0.7328836508077833, 'colsample_bytree': 0.7061356915285395, 'gamma': 1.134674268358361, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:19,284] Trial 457 finished with value: 0.8161309489582734 and parameters: {'n_estimators': 248, 'max_depth': 6, 'learning_rate': 0.028413092966123425, 'subsample': 0.7028992344207542, 'colsample_bytree': 0.6958387826733707, 'gamma': 0.9057662213369755, 'min_child_weight': 5}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:20,303] Trial 458 finished with value: 0.8197151783489546 and parameters: {'n_estimators': 187, 'max_depth': 7, 'learning_rate': 0.03576622984214767, 'subsample': 0.685444430397559, 'colsample_bytree': 0.7200764718831575, 'gamma': 1.2375912494061176, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:21,492] Trial 459 finished with value: 0.8071991259847048 and parameters: {'n_estimators': 257, 'max_depth': 6, 'learning_rate': 0.03963440930559807, 'subsample': 0.7262468960763259, 'colsample_bytree': 0.7341642780997113, 'gamma': 0.997565360662247, 'min_child_weight': 2}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:22,687] Trial 460 finished with value: 0.8250723554328867 and parameters: {'n_estimators': 262, 'max_depth': 5, 'learning_rate': 0.030582203471630133, 'subsample': 0.6718415124611643, 'colsample_bytree': 0.7108659383152942, 'gamma': 1.128646010896254, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:23,814] Trial 461 finished with value: 0.8250723554328867 and parameters: {'n_estimators': 272, 'max_depth': 5, 'learning_rate': 0.025221563229451453, 'subsample': 0.6693658805388961, 'colsample_bytree': 0.6823162650196941, 'gamma': 1.0955788462838947, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:25,045] Trial 462 finished with value: 0.8197151783489546 and parameters: {'n_estimators': 273, 'max_depth': 5, 'learning_rate': 0.011149136919135662, 'subsample': 0.6526306484936656, 'colsample_bytree': 0.680003398692327, 'gamma': 0.8342258392886794, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:26,333] Trial 463 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 270, 'max_depth': 5, 'learning_rate': 0.017187668220374142, 'subsample': 0.6697048197955656, 'colsample_bytree': 0.783625355459806, 'gamma': 0.9526612510135687, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:27,557] Trial 464 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 281, 'max_depth': 5, 'learning_rate': 0.023575604364746917, 'subsample': 0.6755026769260206, 'colsample_bytree': 0.6697172874406211, 'gamma': 0.7346618927881857, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:28,712] Trial 465 finished with value: 0.8250627719318421 and parameters: {'n_estimators': 275, 'max_depth': 5, 'learning_rate': 0.021750241621848607, 'subsample': 0.6632448359783312, 'colsample_bytree': 0.6922524487692437, 'gamma': 1.083969190718773, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:29,874] Trial 466 finished with value: 0.8197151783489544 and parameters: {'n_estimators': 278, 'max_depth': 5, 'learning_rate': 0.0156308130179888, 'subsample': 0.6610129079346101, 'colsample_bytree': 0.6860440524429725, 'gamma': 1.102146824482719, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:31,160] Trial 467 finished with value: 0.8179134801525693 and parameters: {'n_estimators': 273, 'max_depth': 5, 'learning_rate': 0.01655955082196308, 'subsample': 0.644554125467558, 'colsample_bytree': 0.6927511062463975, 'gamma': 1.0541262830147657, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:32,403] Trial 468 finished with value: 0.8250627719318421 and parameters: {'n_estimators': 278, 'max_depth': 5, 'learning_rate': 0.022129326439090293, 'subsample': 0.6601737491820042, 'colsample_bytree': 0.6783755978683865, 'gamma': 0.9114545049119844, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:33,269] Trial 469 finished with value: 0.8018323653997279 and parameters: {'n_estimators': 280, 'max_depth': 5, 'learning_rate': 0.020200738589542515, 'subsample': 0.6500158165053229, 'colsample_bytree': 0.675649279985502, 'gamma': 4.639380143077621, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:34,581] Trial 470 finished with value: 0.8268644701282272 and parameters: {'n_estimators': 286, 'max_depth': 5, 'learning_rate': 0.022299253189625397, 'subsample': 0.6586887017403416, 'colsample_bytree': 0.6624121281262882, 'gamma': 0.8023772765817219, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:35,985] Trial 471 finished with value: 0.8179230636536139 and parameters: {'n_estimators': 284, 'max_depth': 5, 'learning_rate': 0.014356721223070454, 'subsample': 0.6606205790515594, 'colsample_bytree': 0.6591828879597512, 'gamma': 0.925864902143324, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:37,284] Trial 472 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 287, 'max_depth': 5, 'learning_rate': 0.021832923861281012, 'subsample': 0.6524799577020082, 'colsample_bytree': 0.6619040592673024, 'gamma': 0.6421165502876066, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:38,470] Trial 473 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 276, 'max_depth': 5, 'learning_rate': 0.016429680238166055, 'subsample': 0.6590384515643191, 'colsample_bytree': 0.6682841050706878, 'gamma': 0.7147050555653899, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:40,092] Trial 474 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 280, 'max_depth': 5, 'learning_rate': 0.022511938876646043, 'subsample': 0.6660636938267923, 'colsample_bytree': 0.6427784710612207, 'gamma': 0.778982858682882, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:41,588] Trial 475 finished with value: 0.8197055948479098 and parameters: {'n_estimators': 286, 'max_depth': 5, 'learning_rate': 0.024902247704232976, 'subsample': 0.6628406359005773, 'colsample_bytree': 0.6540054225340735, 'gamma': 0.774512881843608, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:43,284] Trial 476 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 276, 'max_depth': 5, 'learning_rate': 0.010593272731365618, 'subsample': 0.6560840832031751, 'colsample_bytree': 0.6672653248186615, 'gamma': 0.5910415193327025, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:44,720] Trial 477 finished with value: 0.8179134801525693 and parameters: {'n_estimators': 289, 'max_depth': 5, 'learning_rate': 0.026059980114602914, 'subsample': 0.6341752808112051, 'colsample_bytree': 0.6750091750706301, 'gamma': 0.8600722632027231, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:45,923] Trial 478 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 283, 'max_depth': 5, 'learning_rate': 0.019939091736808957, 'subsample': 0.6608088106806335, 'colsample_bytree': 0.6571309989851761, 'gamma': 1.161184033972677, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:47,210] Trial 479 finished with value: 0.8179134801525693 and parameters: {'n_estimators': 292, 'max_depth': 5, 'learning_rate': 0.018956049406560094, 'subsample': 0.6784184923415978, 'colsample_bytree': 0.6818858794977047, 'gamma': 0.9094347159917954, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:48,290] Trial 480 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 275, 'max_depth': 5, 'learning_rate': 0.022669035394858636, 'subsample': 0.6712479592034978, 'colsample_bytree': 0.6678237878661402, 'gamma': 1.2189361911159189, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:49,394] Trial 481 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 279, 'max_depth': 5, 'learning_rate': 0.027803567387188803, 'subsample': 0.6391402687496082, 'colsample_bytree': 0.676995503680803, 'gamma': 1.1321711846751827, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:50,523] Trial 482 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 273, 'max_depth': 5, 'learning_rate': 0.014125558928498934, 'subsample': 0.6481757045244826, 'colsample_bytree': 0.6495481086655576, 'gamma': 1.0599381143837951, 'min_child_weight': 4}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:51,740] Trial 483 finished with value: 0.8250819389339313 and parameters: {'n_estimators': 279, 'max_depth': 5, 'learning_rate': 0.0254389295803019, 'subsample': 0.668615990935107, 'colsample_bytree': 0.6635416121672871, 'gamma': 0.965077379706791, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:53,032] Trial 484 finished with value: 0.816140532459318 and parameters: {'n_estimators': 282, 'max_depth': 5, 'learning_rate': 0.010733490309426393, 'subsample': 0.6689717402410156, 'colsample_bytree': 0.6679544122678454, 'gamma': 0.8934572479335487, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:54,258] Trial 485 finished with value: 0.8250723554328867 and parameters: {'n_estimators': 284, 'max_depth': 5, 'learning_rate': 0.02451454904069588, 'subsample': 0.6583064408505724, 'colsample_bytree': 0.6744828702790581, 'gamma': 0.7614591673618909, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:55,431] Trial 486 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 286, 'max_depth': 5, 'learning_rate': 0.026534598337530062, 'subsample': 0.6557158986530398, 'colsample_bytree': 0.6626794914847469, 'gamma': 0.6036055294167725, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:56,731] Trial 487 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 296, 'max_depth': 5, 'learning_rate': 0.027751228076958477, 'subsample': 0.6698386888104796, 'colsample_bytree': 0.6837220165428175, 'gamma': 0.700701571737741, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:58,036] Trial 488 finished with value: 0.8197055948479098 and parameters: {'n_estimators': 284, 'max_depth': 5, 'learning_rate': 0.018476844936732746, 'subsample': 0.6678019905530495, 'colsample_bytree': 0.6740427131480241, 'gamma': 0.7798427009908954, 'min_child_weight': 4}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:42:59,159] Trial 489 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 281, 'max_depth': 5, 'learning_rate': 0.028523052039150953, 'subsample': 0.6530231267033368, 'colsample_bytree': 0.6902251708486327, 'gamma': 0.9882689628774578, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:42:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:43:00,813] Trial 490 finished with value: 0.8179230636536139 and parameters: {'n_estimators': 292, 'max_depth': 5, 'learning_rate': 0.024083304132350977, 'subsample': 0.6659059375359532, 'colsample_bytree': 0.6631431121272993, 'gamma': 0.4962128853579507, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:43:02,198] Trial 491 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 286, 'max_depth': 5, 'learning_rate': 0.018033543681719683, 'subsample': 0.6738312321194191, 'colsample_bytree': 0.6839515840722065, 'gamma': 0.7814368738424041, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:43:03,489] Trial 492 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 277, 'max_depth': 5, 'learning_rate': 0.01020233122594849, 'subsample': 0.6436801731744464, 'colsample_bytree': 0.6721769599796683, 'gamma': 0.840119872887324, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:43:04,618] Trial 493 finished with value: 0.8232802407375462 and parameters: {'n_estimators': 288, 'max_depth': 4, 'learning_rate': 0.03024861877598936, 'subsample': 0.6729388772018584, 'colsample_bytree': 0.6915259810981275, 'gamma': 0.9765711749298817, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:43:05,532] Trial 494 finished with value: 0.8018323653997279 and parameters: {'n_estimators': 282, 'max_depth': 5, 'learning_rate': 0.02988791343400942, 'subsample': 0.6586927391986487, 'colsample_bytree': 0.6980797132161697, 'gamma': 1.09233978962013, 'min_child_weight': 7}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:43:06,691] Trial 495 finished with value: 0.8250915224349761 and parameters: {'n_estimators': 272, 'max_depth': 5, 'learning_rate': 0.023446690920046823, 'subsample': 0.6643100770616175, 'colsample_bytree': 0.6584521838708024, 'gamma': 1.1573188653818534, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:43:07,792] Trial 496 finished with value: 0.8304391160178636 and parameters: {'n_estimators': 272, 'max_depth': 5, 'learning_rate': 0.029501056373320567, 'subsample': 0.6734242013980792, 'colsample_bytree': 0.6523047026836799, 'gamma': 1.208016571005918, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:43:08,821] Trial 497 finished with value: 0.8304199490157744 and parameters: {'n_estimators': 270, 'max_depth': 5, 'learning_rate': 0.03098314360635576, 'subsample': 0.6784754332082696, 'colsample_bytree': 0.6470956609965217, 'gamma': 1.2278787632197479, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:43:10,211] Trial 498 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 268, 'max_depth': 5, 'learning_rate': 0.03251972166086836, 'subsample': 0.6836665043769631, 'colsample_bytree': 0.6340928075591571, 'gamma': 1.2772836362915192, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:43:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-04 01:43:11,546] Trial 499 finished with value: 0.8179518141567478 and parameters: {'n_estimators': 272, 'max_depth': 4, 'learning_rate': 0.03075799743944113, 'subsample': 0.6798695916564094, 'colsample_bytree': 0.6539842147437914, 'gamma': 1.2674151343304825, 'min_child_weight': 3}. Best is trial 309 with value: 0.8339850114043662.\n",
      "04-05-2025 01:43:11 Best XGBoost params: {'n_estimators': 258, 'max_depth': 5, 'learning_rate': 0.04546030953338528, 'subsample': 0.7090012846023769, 'colsample_bytree': 0.7065613653637751, 'gamma': 1.1942623206710457, 'min_child_weight': 3}\n",
      "[I 2025-05-04 01:43:11,557] A new study created in memory with name: no-name-49304225-7284-4ec7-9836-ec7ad7d6bfb3\n",
      "[I 2025-05-04 01:43:13,461] Trial 0 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 138, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8125850535717709.\n",
      "[I 2025-05-04 01:43:14,409] Trial 1 finished with value: 0.8108216893795642 and parameters: {'n_estimators': 75, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8125850535717709.\n",
      "[I 2025-05-04 01:43:16,868] Trial 2 finished with value: 0.8071895424836603 and parameters: {'n_estimators': 199, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8125850535717709.\n",
      "[I 2025-05-04 01:43:18,695] Trial 3 finished with value: 0.8036148965940239 and parameters: {'n_estimators': 158, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.8125850535717709.\n",
      "[I 2025-05-04 01:43:19,891] Trial 4 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 93, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8125850535717709.\n",
      "[I 2025-05-04 01:43:20,602] Trial 5 finished with value: 0.7839591359515458 and parameters: {'n_estimators': 63, 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.8125850535717709.\n",
      "[I 2025-05-04 01:43:21,226] Trial 6 finished with value: 0.8090295746842237 and parameters: {'n_estimators': 54, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.8125850535717709.\n",
      "[I 2025-05-04 01:43:23,743] Trial 7 finished with value: 0.8036244800950684 and parameters: {'n_estimators': 161, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8125850535717709.\n",
      "[I 2025-05-04 01:43:26,276] Trial 8 finished with value: 0.8018419489007725 and parameters: {'n_estimators': 186, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8125850535717709.\n",
      "[I 2025-05-04 01:43:28,480] Trial 9 finished with value: 0.7893067295344336 and parameters: {'n_estimators': 168, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.8125850535717709.\n",
      "[I 2025-05-04 01:43:30,490] Trial 10 finished with value: 0.810802522377475 and parameters: {'n_estimators': 120, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8125850535717709.\n",
      "[I 2025-05-04 01:43:32,190] Trial 11 finished with value: 0.7983152205163591 and parameters: {'n_estimators': 123, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8125850535717709.\n",
      "[I 2025-05-04 01:43:33,597] Trial 12 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 91, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8125850535717709.\n",
      "[I 2025-05-04 01:43:35,453] Trial 13 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 95, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:43:37,078] Trial 14 finished with value: 0.803634063596113 and parameters: {'n_estimators': 106, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:43:38,782] Trial 15 finished with value: 0.8054549287945872 and parameters: {'n_estimators': 140, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:43:40,518] Trial 16 finished with value: 0.8036819811013359 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:43:42,068] Trial 17 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 107, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:43:43,799] Trial 18 finished with value: 0.8072374599888832 and parameters: {'n_estimators': 137, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:43:44,790] Trial 19 finished with value: 0.8054549287945872 and parameters: {'n_estimators': 79, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:43:46,060] Trial 20 finished with value: 0.8018419489007725 and parameters: {'n_estimators': 114, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:43:47,214] Trial 21 finished with value: 0.8089912406800454 and parameters: {'n_estimators': 98, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:43:48,930] Trial 22 finished with value: 0.8054261782914535 and parameters: {'n_estimators': 107, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:43:49,849] Trial 23 finished with value: 0.8054453452935427 and parameters: {'n_estimators': 79, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:43:51,328] Trial 24 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 133, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:43:53,620] Trial 25 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 153, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:43:55,714] Trial 26 finished with value: 0.807218292986794 and parameters: {'n_estimators': 128, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:43:57,164] Trial 27 finished with value: 0.8108121058785196 and parameters: {'n_estimators': 103, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:43:58,739] Trial 28 finished with value: 0.8018419489007725 and parameters: {'n_estimators': 114, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:43:59,761] Trial 29 finished with value: 0.8108216893795642 and parameters: {'n_estimators': 86, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:44:00,958] Trial 30 finished with value: 0.7964560213137064 and parameters: {'n_estimators': 67, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8125946370728155.\n",
      "[I 2025-05-04 01:44:02,589] Trial 31 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 131, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 31 with value: 0.8143580012650222.\n",
      "[I 2025-05-04 01:44:05,015] Trial 32 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 174, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8143580012650222.\n",
      "[I 2025-05-04 01:44:06,681] Trial 33 finished with value: 0.807218292986794 and parameters: {'n_estimators': 146, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 31 with value: 0.8143580012650222.\n",
      "[I 2025-05-04 01:44:08,267] Trial 34 finished with value: 0.8108121058785196 and parameters: {'n_estimators': 127, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 31 with value: 0.8143580012650222.\n",
      "[I 2025-05-04 01:44:09,682] Trial 35 finished with value: 0.8000402507043874 and parameters: {'n_estimators': 114, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8143580012650222.\n",
      "[I 2025-05-04 01:44:11,708] Trial 36 finished with value: 0.7982577195100915 and parameters: {'n_estimators': 152, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 31 with value: 0.8143580012650222.\n",
      "[I 2025-05-04 01:44:12,960] Trial 37 finished with value: 0.8108121058785196 and parameters: {'n_estimators': 91, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 31 with value: 0.8143580012650222.\n",
      "[I 2025-05-04 01:44:14,508] Trial 38 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 119, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:16,072] Trial 39 finished with value: 0.8000402507043874 and parameters: {'n_estimators': 133, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:18,310] Trial 40 finished with value: 0.7910892607287293 and parameters: {'n_estimators': 161, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:19,741] Trial 41 finished with value: 0.805416594790409 and parameters: {'n_estimators': 119, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:20,990] Trial 42 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:22,804] Trial 43 finished with value: 0.7982768865121807 and parameters: {'n_estimators': 111, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:24,277] Trial 44 finished with value: 0.8054549287945872 and parameters: {'n_estimators': 124, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:25,404] Trial 45 finished with value: 0.7964847718168402 and parameters: {'n_estimators': 97, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:26,655] Trial 46 finished with value: 0.8036532305982022 and parameters: {'n_estimators': 85, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:27,824] Trial 47 finished with value: 0.7964943553178848 and parameters: {'n_estimators': 68, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:29,740] Trial 48 finished with value: 0.8036628140992468 and parameters: {'n_estimators': 137, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:32,001] Trial 49 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 198, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:34,569] Trial 50 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 198, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:36,939] Trial 51 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 183, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:39,165] Trial 52 finished with value: 0.810802522377475 and parameters: {'n_estimators': 187, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:41,909] Trial 53 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 199, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:44,345] Trial 54 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 194, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:45,083] Trial 55 finished with value: 0.8089912406800454 and parameters: {'n_estimators': 53, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:47,069] Trial 56 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 180, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:49,311] Trial 57 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 194, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:51,396] Trial 58 finished with value: 0.8036532305982022 and parameters: {'n_estimators': 167, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:53,646] Trial 59 finished with value: 0.8108121058785196 and parameters: {'n_estimators': 190, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:55,718] Trial 60 finished with value: 0.8000594177064766 and parameters: {'n_estimators': 176, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:44:58,036] Trial 61 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 196, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:45:00,700] Trial 62 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 193, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:45:02,961] Trial 63 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 198, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 38 with value: 0.8161501159603627.\n",
      "[I 2025-05-04 01:45:05,443] Trial 64 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 189, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:07,318] Trial 65 finished with value: 0.8072374599888832 and parameters: {'n_estimators': 167, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:09,435] Trial 66 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 144, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:11,590] Trial 67 finished with value: 0.8072470434899278 and parameters: {'n_estimators': 173, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:13,741] Trial 68 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 186, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:15,930] Trial 69 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 182, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:18,155] Trial 70 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 160, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:20,375] Trial 71 finished with value: 0.8018802829049508 and parameters: {'n_estimators': 187, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:22,763] Trial 72 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 191, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:25,162] Trial 73 finished with value: 0.8108121058785196 and parameters: {'n_estimators': 199, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:26,703] Trial 74 finished with value: 0.814386751768156 and parameters: {'n_estimators': 131, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:28,414] Trial 75 finished with value: 0.8054453452935427 and parameters: {'n_estimators': 119, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:30,221] Trial 76 finished with value: 0.814386751768156 and parameters: {'n_estimators': 131, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:31,890] Trial 77 finished with value: 0.8108121058785196 and parameters: {'n_estimators': 132, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:33,545] Trial 78 finished with value: 0.8090487416863129 and parameters: {'n_estimators': 128, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:35,987] Trial 79 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 153, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:37,727] Trial 80 finished with value: 0.8090295746842237 and parameters: {'n_estimators': 148, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:39,376] Trial 81 finished with value: 0.8018802829049508 and parameters: {'n_estimators': 138, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:41,386] Trial 82 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 130, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:42,719] Trial 83 finished with value: 0.776809844172273 and parameters: {'n_estimators': 124, 'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:44,513] Trial 84 finished with value: 0.8108121058785196 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:47,090] Trial 85 finished with value: 0.8072566269909723 and parameters: {'n_estimators': 110, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:47,828] Trial 86 finished with value: 0.807218292986794 and parameters: {'n_estimators': 59, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:49,749] Trial 87 finished with value: 0.8108216893795642 and parameters: {'n_estimators': 134, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:51,542] Trial 88 finished with value: 0.803634063596113 and parameters: {'n_estimators': 117, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:53,429] Trial 89 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 121, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:55,058] Trial 90 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 104, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:57,817] Trial 91 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 188, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:45:59,916] Trial 92 finished with value: 0.810802522377475 and parameters: {'n_estimators': 184, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:46:01,661] Trial 93 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 140, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:46:03,524] Trial 94 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 125, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:46:05,120] Trial 95 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 126, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:46:06,708] Trial 96 finished with value: 0.8036244800950684 and parameters: {'n_estimators': 135, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:46:08,506] Trial 97 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 149, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:46:10,278] Trial 98 finished with value: 0.803634063596113 and parameters: {'n_estimators': 116, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:46:11,981] Trial 99 finished with value: 0.7964943553178848 and parameters: {'n_estimators': 110, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:46:12,989] Trial 100 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 74, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:46:14,005] Trial 101 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 71, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:46:15,123] Trial 102 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 85, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 64 with value: 0.8179326471546586.\n",
      "[I 2025-05-04 01:46:16,743] Trial 103 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 103 with value: 0.8179422306557033.\n",
      "[I 2025-05-04 01:46:17,752] Trial 104 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 103 with value: 0.8179422306557033.\n",
      "[I 2025-05-04 01:46:18,664] Trial 105 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 73, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 103 with value: 0.8179422306557033.\n",
      "[I 2025-05-04 01:46:19,832] Trial 106 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 103 with value: 0.8179422306557033.\n",
      "[I 2025-05-04 01:46:20,889] Trial 107 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 80, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 103 with value: 0.8179422306557033.\n",
      "[I 2025-05-04 01:46:22,284] Trial 108 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 80, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 103 with value: 0.8179422306557033.\n",
      "[I 2025-05-04 01:46:23,512] Trial 109 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 103 with value: 0.8179422306557033.\n",
      "[I 2025-05-04 01:46:24,603] Trial 110 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 103 with value: 0.8179422306557033.\n",
      "[I 2025-05-04 01:46:26,220] Trial 111 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 103 with value: 0.8179422306557033.\n",
      "[I 2025-05-04 01:46:27,441] Trial 112 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 103 with value: 0.8179422306557033.\n",
      "[I 2025-05-04 01:46:28,604] Trial 113 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 103 with value: 0.8179422306557033.\n",
      "[I 2025-05-04 01:46:29,756] Trial 114 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:31,294] Trial 115 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:32,546] Trial 116 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:34,003] Trial 117 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:35,803] Trial 118 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:37,037] Trial 119 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:38,226] Trial 120 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:39,816] Trial 121 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:41,099] Trial 122 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:42,358] Trial 123 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:44,269] Trial 124 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 99, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:45,810] Trial 125 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:47,115] Trial 126 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:48,749] Trial 127 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:50,024] Trial 128 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:51,724] Trial 129 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 101, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:52,986] Trial 130 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:54,294] Trial 131 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:55,646] Trial 132 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:57,239] Trial 133 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 105, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:58,361] Trial 134 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 94, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:46:59,547] Trial 135 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 98, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:01,288] Trial 136 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 102, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:02,517] Trial 137 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 99, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:03,549] Trial 138 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 83, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:05,315] Trial 139 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 106, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:06,499] Trial 140 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:07,762] Trial 141 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 98, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:09,396] Trial 142 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 99, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:10,438] Trial 143 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:11,739] Trial 144 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:13,096] Trial 145 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 102, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:14,757] Trial 146 finished with value: 0.814386751768156 and parameters: {'n_estimators': 108, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:15,778] Trial 147 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 83, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:17,193] Trial 148 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 99, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:18,362] Trial 149 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 94, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:19,625] Trial 150 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 103, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:20,885] Trial 151 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:22,458] Trial 152 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:23,581] Trial 153 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:24,862] Trial 154 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:26,122] Trial 155 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:27,481] Trial 156 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 105, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:29,091] Trial 157 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:30,158] Trial 158 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 83, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:31,344] Trial 159 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:32,678] Trial 160 finished with value: 0.810802522377475 and parameters: {'n_estimators': 92, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:34,441] Trial 161 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:36,075] Trial 162 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 99, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:37,588] Trial 163 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 102, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:38,871] Trial 164 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:40,522] Trial 165 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 109, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:42,050] Trial 166 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:43,554] Trial 167 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 98, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:44,662] Trial 168 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 88, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:46,416] Trial 169 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 104, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:47,425] Trial 170 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 77, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:48,724] Trial 171 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 99, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:50,021] Trial 172 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 101, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:51,271] Trial 173 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:52,738] Trial 174 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:54,239] Trial 175 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 113, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:55,408] Trial 176 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 98, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:56,474] Trial 177 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 89, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:58,323] Trial 178 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 107, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:47:59,514] Trial 179 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:00,564] Trial 180 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 85, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:02,178] Trial 181 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:03,399] Trial 182 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:04,763] Trial 183 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:06,317] Trial 184 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:07,587] Trial 185 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 102, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:08,860] Trial 186 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 98, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:10,447] Trial 187 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:11,728] Trial 188 finished with value: 0.807218292986794 and parameters: {'n_estimators': 105, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:12,889] Trial 189 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:14,253] Trial 190 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:15,774] Trial 191 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 99, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:17,027] Trial 192 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:18,338] Trial 193 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:19,836] Trial 194 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:20,901] Trial 195 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 85, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:22,964] Trial 196 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:24,062] Trial 197 finished with value: 0.7857416671458418 and parameters: {'n_estimators': 93, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:25,526] Trial 198 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:26,776] Trial 199 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 90, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:27,974] Trial 200 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 82, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:29,534] Trial 201 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:30,719] Trial 202 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:31,874] Trial 203 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:33,748] Trial 204 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 102, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:35,207] Trial 205 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:36,352] Trial 206 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:37,848] Trial 207 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:39,186] Trial 208 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:40,401] Trial 209 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:41,902] Trial 210 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:43,138] Trial 211 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:44,374] Trial 212 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:45,860] Trial 213 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:47,072] Trial 214 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:48,134] Trial 215 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 85, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:49,664] Trial 216 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:50,877] Trial 217 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:52,169] Trial 218 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:53,500] Trial 219 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:54,745] Trial 220 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 87, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:55,882] Trial 221 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:57,097] Trial 222 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:58,382] Trial 223 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:48:59,771] Trial 224 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:01,058] Trial 225 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:02,286] Trial 226 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:03,344] Trial 227 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 85, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:04,494] Trial 228 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 50, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:05,788] Trial 229 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:07,069] Trial 230 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:08,361] Trial 231 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:09,677] Trial 232 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:11,420] Trial 233 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:12,720] Trial 234 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:14,451] Trial 235 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:15,699] Trial 236 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:16,732] Trial 237 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 81, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:18,174] Trial 238 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:19,485] Trial 239 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:20,707] Trial 240 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:22,268] Trial 241 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:23,423] Trial 242 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:24,598] Trial 243 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 84, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:25,877] Trial 244 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:26,980] Trial 245 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:28,510] Trial 246 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:29,935] Trial 247 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:31,089] Trial 248 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:32,549] Trial 249 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:33,981] Trial 250 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:35,291] Trial 251 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:36,475] Trial 252 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:37,992] Trial 253 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:39,205] Trial 254 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:40,683] Trial 255 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:42,164] Trial 256 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 85, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:43,404] Trial 257 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:45,128] Trial 258 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:46,405] Trial 259 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:47,562] Trial 260 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:48,725] Trial 261 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:50,292] Trial 262 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 83, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:51,597] Trial 263 finished with value: 0.810802522377475 and parameters: {'n_estimators': 96, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:52,389] Trial 264 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 63, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:53,570] Trial 265 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:55,128] Trial 266 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:56,256] Trial 267 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:57,642] Trial 268 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:58,962] Trial 269 finished with value: 0.8018802829049508 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:49:59,947] Trial 270 finished with value: 0.7964560213137064 and parameters: {'n_estimators': 79, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:01,221] Trial 271 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 93, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:02,403] Trial 272 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:03,917] Trial 273 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:05,646] Trial 274 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:06,777] Trial 275 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 83, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:07,951] Trial 276 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 90, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:09,594] Trial 277 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:10,764] Trial 278 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:11,960] Trial 279 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:13,659] Trial 280 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:14,799] Trial 281 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:16,347] Trial 282 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:17,673] Trial 283 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:18,891] Trial 284 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 97, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:20,474] Trial 285 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:21,758] Trial 286 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:22,829] Trial 287 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 84, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:24,179] Trial 288 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 92, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:25,573] Trial 289 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:26,822] Trial 290 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:28,231] Trial 291 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:30,070] Trial 292 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:31,229] Trial 293 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:32,472] Trial 294 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:34,019] Trial 295 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 81, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:35,396] Trial 296 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:36,687] Trial 297 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 98, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:37,917] Trial 298 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:39,256] Trial 299 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:41,105] Trial 300 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:42,518] Trial 301 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:43,924] Trial 302 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 97, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:45,479] Trial 303 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:46,735] Trial 304 finished with value: 0.7803844900619094 and parameters: {'n_estimators': 84, 'max_depth': 2, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:47,892] Trial 305 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:49,267] Trial 306 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:50,698] Trial 307 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 99, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:51,887] Trial 308 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:53,067] Trial 309 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:54,268] Trial 310 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:55,426] Trial 311 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:56,694] Trial 312 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:57,867] Trial 313 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 78, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:50:59,133] Trial 314 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 101, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:00,166] Trial 315 finished with value: 0.7839495524505011 and parameters: {'n_estimators': 85, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:01,813] Trial 316 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:03,189] Trial 317 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:04,713] Trial 318 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 98, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:06,412] Trial 319 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:08,004] Trial 320 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:09,007] Trial 321 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 82, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:10,224] Trial 322 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:11,579] Trial 323 finished with value: 0.810802522377475 and parameters: {'n_estimators': 86, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:12,968] Trial 324 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:14,250] Trial 325 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:15,333] Trial 326 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:16,887] Trial 327 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:18,241] Trial 328 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 99, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:19,392] Trial 329 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:20,449] Trial 330 finished with value: 0.8018706994039063 and parameters: {'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:21,827] Trial 331 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:22,972] Trial 332 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 84, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:24,525] Trial 333 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:25,840] Trial 334 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 97, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:27,189] Trial 335 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 102, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:28,333] Trial 336 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:29,946] Trial 337 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:31,007] Trial 338 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:32,613] Trial 339 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:34,434] Trial 340 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 99, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:36,367] Trial 341 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 156, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:37,516] Trial 342 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:39,114] Trial 343 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:40,245] Trial 344 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:41,620] Trial 345 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 94, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:42,971] Trial 346 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:44,078] Trial 347 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 83, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:45,797] Trial 348 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:47,481] Trial 349 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 87, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:49,167] Trial 350 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:50,371] Trial 351 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:51,279] Trial 352 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 59, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:52,876] Trial 353 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:54,143] Trial 354 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:55,374] Trial 355 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:56,545] Trial 356 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:57,927] Trial 357 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:51:59,475] Trial 358 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:00,719] Trial 359 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 94, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:01,900] Trial 360 finished with value: 0.8019090334080846 and parameters: {'n_estimators': 84, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:03,517] Trial 361 finished with value: 0.8036628140992468 and parameters: {'n_estimators': 90, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:04,892] Trial 362 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 102, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:06,025] Trial 363 finished with value: 0.8018131983976388 and parameters: {'n_estimators': 96, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:07,660] Trial 364 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:08,712] Trial 365 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 81, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:09,926] Trial 366 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:12,034] Trial 367 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 98, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:13,394] Trial 368 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:14,862] Trial 369 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:16,154] Trial 370 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:17,233] Trial 371 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 85, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:18,796] Trial 372 finished with value: 0.8090295746842237 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:20,164] Trial 373 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:21,290] Trial 374 finished with value: 0.8108121058785196 and parameters: {'n_estimators': 91, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:22,616] Trial 375 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:24,061] Trial 376 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:25,270] Trial 377 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:26,673] Trial 378 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:27,957] Trial 379 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:29,189] Trial 380 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:30,327] Trial 381 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:32,045] Trial 382 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 104, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:33,353] Trial 383 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:34,551] Trial 384 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 70, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:36,121] Trial 385 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:37,079] Trial 386 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 75, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:38,136] Trial 387 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 81, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:39,587] Trial 388 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 85, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:41,087] Trial 389 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 99, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:42,285] Trial 390 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:43,917] Trial 391 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:45,132] Trial 392 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:46,271] Trial 393 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:47,574] Trial 394 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:48,837] Trial 395 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 92, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:50,461] Trial 396 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:51,850] Trial 397 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 99, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:53,431] Trial 398 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:54,564] Trial 399 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 83, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:55,868] Trial 400 finished with value: 0.810802522377475 and parameters: {'n_estimators': 92, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:58,119] Trial 401 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 164, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:52:59,249] Trial 402 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:00,680] Trial 403 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 102, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:02,285] Trial 404 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:03,442] Trial 405 finished with value: 0.810802522377475 and parameters: {'n_estimators': 91, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:04,831] Trial 406 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:05,974] Trial 407 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:07,521] Trial 408 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 98, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:09,041] Trial 409 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 85, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:10,314] Trial 410 finished with value: 0.810802522377475 and parameters: {'n_estimators': 92, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:11,475] Trial 411 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:12,905] Trial 412 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:14,252] Trial 413 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:15,535] Trial 414 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:16,952] Trial 415 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:18,222] Trial 416 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:19,437] Trial 417 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:20,595] Trial 418 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 79, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:22,063] Trial 419 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:23,202] Trial 420 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:24,854] Trial 421 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 98, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:25,879] Trial 422 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 83, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:27,051] Trial 423 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:28,309] Trial 424 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:29,804] Trial 425 finished with value: 0.803634063596113 and parameters: {'n_estimators': 93, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:31,912] Trial 426 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 172, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:33,152] Trial 427 finished with value: 0.807266210492017 and parameters: {'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:34,977] Trial 428 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:36,101] Trial 429 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 85, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:37,924] Trial 430 finished with value: 0.8090295746842237 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:39,450] Trial 431 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 99, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:41,186] Trial 432 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:42,709] Trial 433 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 103, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:44,466] Trial 434 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 94, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:45,635] Trial 435 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:46,942] Trial 436 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:48,488] Trial 437 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:49,714] Trial 438 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:51,392] Trial 439 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 94, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:52,408] Trial 440 finished with value: 0.8018706994039063 and parameters: {'n_estimators': 83, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:53,747] Trial 441 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:55,042] Trial 442 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:56,472] Trial 443 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:57,754] Trial 444 finished with value: 0.8126233875759493 and parameters: {'n_estimators': 96, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:53:59,003] Trial 445 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:00,424] Trial 446 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:01,640] Trial 447 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:02,948] Trial 448 finished with value: 0.8072757939930616 and parameters: {'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:04,167] Trial 449 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:05,407] Trial 450 finished with value: 0.778592375366569 and parameters: {'n_estimators': 89, 'max_depth': 2, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:06,990] Trial 451 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 95, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:08,381] Trial 452 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 101, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:09,745] Trial 453 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:11,262] Trial 454 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:12,438] Trial 455 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:13,315] Trial 456 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 66, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:14,936] Trial 457 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:16,023] Trial 458 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 81, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:17,168] Trial 459 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:18,459] Trial 460 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 98, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:19,868] Trial 461 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:21,361] Trial 462 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 105, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:22,586] Trial 463 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 85, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:24,019] Trial 464 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:25,343] Trial 465 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:26,802] Trial 466 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 98, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:28,184] Trial 467 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:29,531] Trial 468 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:30,885] Trial 469 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:32,538] Trial 470 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 101, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:33,794] Trial 471 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 84, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:35,386] Trial 472 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:36,641] Trial 473 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:37,563] Trial 474 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 57, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:38,765] Trial 475 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:40,376] Trial 476 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 97, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:41,658] Trial 477 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:43,242] Trial 478 finished with value: 0.800097751710655 and parameters: {'n_estimators': 121, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:44,480] Trial 479 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:46,162] Trial 480 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 98, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:47,403] Trial 481 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 85, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:48,583] Trial 482 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:49,775] Trial 483 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 88, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:51,460] Trial 484 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:52,612] Trial 485 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:53,872] Trial 486 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:55,162] Trial 487 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 82, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:56,503] Trial 488 finished with value: 0.7839495524505011 and parameters: {'n_estimators': 94, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:57,981] Trial 489 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:54:59,418] Trial 490 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:55:00,423] Trial 491 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 78, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:55:01,989] Trial 492 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:55:03,414] Trial 493 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:55:04,781] Trial 494 finished with value: 0.8143963352692006 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:55:06,095] Trial 495 finished with value: 0.8018802829049508 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:55:07,612] Trial 496 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:55:09,011] Trial 497 finished with value: 0.803634063596113 and parameters: {'n_estimators': 102, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:55:10,637] Trial 498 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "[I 2025-05-04 01:55:12,371] Trial 499 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 88, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 114 with value: 0.8215168765453397.\n",
      "04-05-2025 01:55:12 Best RF params: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2}\n",
      "04-05-2025 01:55:13 Best model F1: 0.7592592592592593\n",
      "04-05-2025 01:55:13 Đã lưu mô hình và scaler vào W&B: final_model.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pious-dust-105</strong> at: <a href='https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes/runs/mvf6bi6e' target=\"_blank\">https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes/runs/mvf6bi6e</a><br> View project at: <a href='https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes' target=\"_blank\">https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250504_013211-mvf6bi6e\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === RUN PIPELINE ===\n",
    "df, run = load_data()\n",
    "X_train, X_val, y_train, y_val, scaler = prepare_data(df)\n",
    "train_base_models(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Tune models\n",
    "xgb_model = tune_xgboost(X_train, y_train)\n",
    "rf_model = tune_random_forest(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "xgb_auc = accuracy_score(y_val, xgb_model.predict(X_val))\n",
    "rf_auc = accuracy_score(y_val, rf_model.predict(X_val))\n",
    "\n",
    "best_model = xgb_model if xgb_auc >= rf_auc else rf_model\n",
    "logger.info(f\"Best model accuracy: {max(xgb_auc, rf_auc)}\")\n",
    "save_and_log_model(best_model, scaler, run)\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
