{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae786992",
   "metadata": {},
   "source": [
    "# Step 6: Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d3d866b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import wandb\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import optuna\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s', datefmt='%d-%m-%Y %H:%M:%S')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd3a0d1",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c54f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    wandb.login()\n",
    "    run = wandb.init(project=\"diabetes\",entity=\"ngocnhi-p4work-national-economics-university\", job_type=\"train\")\n",
    "    artifact = run.use_artifact(\"train.csv:latest\")\n",
    "    artifact_dir = artifact.download()\n",
    "    df = pd.read_csv(os.path.join(artifact_dir, \"train.csv\"))\n",
    "    logger.info(f\"Tập dữ liệu đã load với shape: {df.shape}\")\n",
    "    return df, run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbbd600",
   "metadata": {},
   "source": [
    "## 2. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4a6d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    # Split data into training and validation sets\n",
    "    X = df.drop(columns=[\"OUTCOME\"])\n",
    "    y = df[\"OUTCOME\"]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    logger.info(f\"Train shape: {X_train.shape}, Validation shape: {X_val.shape}\") # log train and validation shapes\n",
    "    # Handle class imbalance using SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    logger.info(f\"After SMOTE - Counts: {y_train_res.value_counts().to_dict()}\") # log class counts after SMOTE\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    return X_train_scaled, X_val_scaled, y_train_res, y_val, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551eff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base_models(X_train, y_train, X_val, y_val):\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=500),\n",
    "        'Random Forest': RandomForestClassifier(random_state=42),\n",
    "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    }\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_val, preds),\n",
    "            'precision': precision_score(y_val, preds),\n",
    "            'recall': recall_score(y_val, preds),\n",
    "            'f1': f1_score(y_val, preds)\n",
    "        }\n",
    "        logger.info(f\"{name} - {metrics}\")\n",
    "        print(f\"\\n{name} Classification Report:\\n\", classification_report(y_val, preds))\n",
    "        print(f\"Confusion Matrix:\\n{confusion_matrix(y_val, preds)}\")\n",
    "        results[name] = model\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf45c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_random_forest(X_train, y_train):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'random_state': 42,\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        }\n",
    "\n",
    "        model = RandomForestClassifier(**params)\n",
    "        return cross_val_score(model, X_train, y_train, scoring='accuracy', cv=3).mean()\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=500)\n",
    "    logger.info(f\"Best RF params: {study.best_params}\")\n",
    "    return RandomForestClassifier(**study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c904937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_xgboost(X_train, y_train):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'random_state': 42,\n",
    "            'eval_metric': 'logloss',\n",
    "            'use_label_encoder': False\n",
    "        }\n",
    "        model = XGBClassifier(**params)\n",
    "        return cross_val_score(model, X_train, y_train, scoring='accuracy', cv=3).mean()\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=500)\n",
    "    logger.info(f\"Best XGBoost params: {study.best_params}\")\n",
    "    return XGBClassifier(**study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "450af27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_log_model(model, scaler, run, filename='final_model.pkl'):\n",
    "    joblib.dump((model, scaler), filename)\n",
    "    artifact = wandb.Artifact(name=filename, type='model')\n",
    "    artifact.add_file(filename)\n",
    "    run.log_artifact(artifact)\n",
    "    logger.info(f\"Đã lưu mô hình và scaler vào W&B: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d51be735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmlcolongmay\u001b[0m (\u001b[33mmlcolongmay-neu\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\FINAL\\diabetes-prediction-main\\diabetes-prediction-main\\notebooks\\wandb\\run-20250507_224717-d8i6hc0d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes/runs/d8i6hc0d' target=\"_blank\">polar-wildflower-198</a></strong> to <a href='https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes' target=\"_blank\">https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes/runs/d8i6hc0d' target=\"_blank\">https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes/runs/d8i6hc0d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "07-05-2025 22:47:22 Tập dữ liệu đã load với shape: (537, 9)\n",
      "07-05-2025 22:47:22 Train shape: (429, 8), Validation shape: (108, 8)\n",
      "07-05-2025 22:47:22 After SMOTE - Counts: {0: 280, 1: 280}\n",
      "07-05-2025 22:47:22 Logistic Regression - {'accuracy': 0.7592592592592593, 'precision': 0.6304347826086957, 'recall': 0.7631578947368421, 'f1': 0.6904761904761905}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80        70\n",
      "           1       0.63      0.76      0.69        38\n",
      "\n",
      "    accuracy                           0.76       108\n",
      "   macro avg       0.74      0.76      0.75       108\n",
      "weighted avg       0.78      0.76      0.76       108\n",
      "\n",
      "Confusion Matrix:\n",
      "[[53 17]\n",
      " [ 9 29]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-05-2025 22:47:22 Random Forest - {'accuracy': 0.7222222222222222, 'precision': 0.5833333333333334, 'recall': 0.7368421052631579, 'f1': 0.6511627906976745}\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "07-05-2025 22:47:23 XGBoost - {'accuracy': 0.7592592592592593, 'precision': 0.6363636363636364, 'recall': 0.7368421052631579, 'f1': 0.6829268292682926}\n",
      "[I 2025-05-07 22:47:23,179] A new study created in memory with name: no-name-8728c157-d6ad-4470-81cc-6cf0346c9da3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77        70\n",
      "           1       0.58      0.74      0.65        38\n",
      "\n",
      "    accuracy                           0.72       108\n",
      "   macro avg       0.71      0.73      0.71       108\n",
      "weighted avg       0.75      0.72      0.73       108\n",
      "\n",
      "Confusion Matrix:\n",
      "[[50 20]\n",
      " [10 28]]\n",
      "\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.81        70\n",
      "           1       0.64      0.74      0.68        38\n",
      "\n",
      "    accuracy                           0.76       108\n",
      "   macro avg       0.74      0.75      0.74       108\n",
      "weighted avg       0.77      0.76      0.76       108\n",
      "\n",
      "Confusion Matrix:\n",
      "[[54 16]\n",
      " [10 28]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:23,542] Trial 0 finished with value: 0.7875721158453607 and parameters: {'n_estimators': 252, 'max_depth': 9, 'learning_rate': 0.2508906823072129, 'subsample': 0.6941207239532933, 'colsample_bytree': 0.923603638160894, 'gamma': 1.7649795532059276, 'min_child_weight': 7}. Best is trial 0 with value: 0.7875721158453607.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:23,795] Trial 1 finished with value: 0.7857512506468863 and parameters: {'n_estimators': 163, 'max_depth': 9, 'learning_rate': 0.2461451468041417, 'subsample': 0.6758817514963823, 'colsample_bytree': 0.8060582099151451, 'gamma': 2.02082376549876, 'min_child_weight': 8}. Best is trial 0 with value: 0.7875721158453607.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:24,212] Trial 2 finished with value: 0.7839495524505011 and parameters: {'n_estimators': 296, 'max_depth': 7, 'learning_rate': 0.291409728304617, 'subsample': 0.6859155480688905, 'colsample_bytree': 0.8588500337942468, 'gamma': 1.6145420615435175, 'min_child_weight': 2}. Best is trial 0 with value: 0.7875721158453607.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:24,749] Trial 3 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 213, 'max_depth': 6, 'learning_rate': 0.026576206161754705, 'subsample': 0.7808797240234608, 'colsample_bytree': 0.6325458965214122, 'gamma': 1.1515097912857968, 'min_child_weight': 6}. Best is trial 3 with value: 0.8090104076821345.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:25,003] Trial 4 finished with value: 0.7804036570639985 and parameters: {'n_estimators': 149, 'max_depth': 5, 'learning_rate': 0.1669842907652712, 'subsample': 0.6669018713720295, 'colsample_bytree': 0.9568980566887695, 'gamma': 2.4559246647968083, 'min_child_weight': 8}. Best is trial 3 with value: 0.8090104076821345.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:25,390] Trial 5 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 275, 'max_depth': 4, 'learning_rate': 0.159303011101352, 'subsample': 0.9127527423602573, 'colsample_bytree': 0.6514026306091819, 'gamma': 2.432663427236233, 'min_child_weight': 2}. Best is trial 3 with value: 0.8090104076821345.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:25,715] Trial 6 finished with value: 0.8000402507043874 and parameters: {'n_estimators': 220, 'max_depth': 5, 'learning_rate': 0.05607626769328446, 'subsample': 0.658747127210271, 'colsample_bytree': 0.9718030184654396, 'gamma': 4.930684986597039, 'min_child_weight': 4}. Best is trial 3 with value: 0.8090104076821345.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:26,028] Trial 7 finished with value: 0.7750752304832002 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.03570032925336934, 'subsample': 0.6703392654455017, 'colsample_bytree': 0.6383360423288886, 'gamma': 1.6207222520609403, 'min_child_weight': 10}. Best is trial 3 with value: 0.8090104076821345.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:26,373] Trial 8 finished with value: 0.7929484599313822 and parameters: {'n_estimators': 208, 'max_depth': 6, 'learning_rate': 0.15065281137861286, 'subsample': 0.979564123873613, 'colsample_bytree': 0.7449421490838559, 'gamma': 0.5996896423904841, 'min_child_weight': 1}. Best is trial 3 with value: 0.8090104076821345.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:26,618] Trial 9 finished with value: 0.7965039388189293 and parameters: {'n_estimators': 101, 'max_depth': 8, 'learning_rate': 0.03006430200528251, 'subsample': 0.7821517324985211, 'colsample_bytree': 0.9149860454478755, 'gamma': 2.6735047395943825, 'min_child_weight': 3}. Best is trial 3 with value: 0.8090104076821345.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:27,086] Trial 10 finished with value: 0.7947501581277673 and parameters: {'n_estimators': 245, 'max_depth': 3, 'learning_rate': 0.09611314956430894, 'subsample': 0.8055702903638949, 'colsample_bytree': 0.7149636989963147, 'gamma': 0.5321299103721799, 'min_child_weight': 6}. Best is trial 3 with value: 0.8090104076821345.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:27,496] Trial 11 finished with value: 0.8000594177064766 and parameters: {'n_estimators': 284, 'max_depth': 3, 'learning_rate': 0.13998853077550494, 'subsample': 0.9241593115583983, 'colsample_bytree': 0.6075526398567973, 'gamma': 3.524407366738579, 'min_child_weight': 5}. Best is trial 3 with value: 0.8090104076821345.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:27,897] Trial 12 finished with value: 0.8036532305982022 and parameters: {'n_estimators': 253, 'max_depth': 4, 'learning_rate': 0.19627184650594257, 'subsample': 0.8617309839839575, 'colsample_bytree': 0.6764526173413179, 'gamma': 3.3199111828878287, 'min_child_weight': 4}. Best is trial 3 with value: 0.8090104076821345.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:28,746] Trial 13 finished with value: 0.7893354800375674 and parameters: {'n_estimators': 272, 'max_depth': 7, 'learning_rate': 0.08617387816036831, 'subsample': 0.7795994650121312, 'colsample_bytree': 0.6830620241558322, 'gamma': 0.10403612744353907, 'min_child_weight': 1}. Best is trial 3 with value: 0.8090104076821345.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:29,204] Trial 14 finished with value: 0.8072087094857494 and parameters: {'n_estimators': 229, 'max_depth': 6, 'learning_rate': 0.10595052927331222, 'subsample': 0.8631633662824255, 'colsample_bytree': 0.7579213519747917, 'gamma': 1.0120061791261254, 'min_child_weight': 6}. Best is trial 3 with value: 0.8090104076821345.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:29,539] Trial 15 finished with value: 0.8018898664059955 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.19712006494321288, 'subsample': 0.9945983271214444, 'colsample_bytree': 0.6090139974060829, 'gamma': 3.525288784857368, 'min_child_weight': 3}. Best is trial 3 with value: 0.8090104076821345.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:29,894] Trial 16 finished with value: 0.7750464799800664 and parameters: {'n_estimators': 130, 'max_depth': 10, 'learning_rate': 0.013361488534904525, 'subsample': 0.6024519102537379, 'colsample_bytree': 0.6634701453130214, 'gamma': 4.466603897974762, 'min_child_weight': 9}. Best is trial 3 with value: 0.8090104076821345.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:30,593] Trial 17 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 271, 'max_depth': 4, 'learning_rate': 0.07027710033058802, 'subsample': 0.8460537737991578, 'colsample_bytree': 0.8219534237090292, 'gamma': 1.0932923947249584, 'min_child_weight': 5}. Best is trial 17 with value: 0.8107929388764304.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:31,092] Trial 18 finished with value: 0.8000881682096104 and parameters: {'n_estimators': 234, 'max_depth': 6, 'learning_rate': 0.06360663671100525, 'subsample': 0.7364128395402488, 'colsample_bytree': 0.8254956338140254, 'gamma': 1.2700194598260046, 'min_child_weight': 5}. Best is trial 17 with value: 0.8107929388764304.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:31,514] Trial 19 finished with value: 0.7965231058210186 and parameters: {'n_estimators': 197, 'max_depth': 8, 'learning_rate': 0.12373381977607872, 'subsample': 0.8208115806404143, 'colsample_bytree': 0.8624111261166137, 'gamma': 0.942565248358684, 'min_child_weight': 7}. Best is trial 17 with value: 0.8107929388764304.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:32,075] Trial 20 finished with value: 0.7911467617349971 and parameters: {'n_estimators': 263, 'max_depth': 5, 'learning_rate': 0.06578942309617718, 'subsample': 0.7346107421495, 'colsample_bytree': 0.7560409134947712, 'gamma': 0.09541138999189225, 'min_child_weight': 7}. Best is trial 17 with value: 0.8107929388764304.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:32,509] Trial 21 finished with value: 0.8036723976002914 and parameters: {'n_estimators': 299, 'max_depth': 4, 'learning_rate': 0.17444088134195276, 'subsample': 0.9057587889117659, 'colsample_bytree': 0.712222065114744, 'gamma': 2.4371412889447863, 'min_child_weight': 4}. Best is trial 17 with value: 0.8107929388764304.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:32,910] Trial 22 finished with value: 0.800049834205432 and parameters: {'n_estimators': 281, 'max_depth': 3, 'learning_rate': 0.12373547788263448, 'subsample': 0.8545992108394175, 'colsample_bytree': 0.641825409291672, 'gamma': 3.1227126752143475, 'min_child_weight': 2}. Best is trial 17 with value: 0.8107929388764304.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:33,475] Trial 23 finished with value: 0.8018611159028617 and parameters: {'n_estimators': 263, 'max_depth': 4, 'learning_rate': 0.011464023699577986, 'subsample': 0.9261759833608902, 'colsample_bytree': 0.850674262639322, 'gamma': 2.2003673701560906, 'min_child_weight': 5}. Best is trial 17 with value: 0.8107929388764304.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:33,938] Trial 24 finished with value: 0.8090487416863129 and parameters: {'n_estimators': 216, 'max_depth': 4, 'learning_rate': 0.047148313173355785, 'subsample': 0.9001539031693038, 'colsample_bytree': 0.7964202931877945, 'gamma': 1.070362075780356, 'min_child_weight': 3}. Best is trial 17 with value: 0.8107929388764304.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:34,352] Trial 25 finished with value: 0.8108216893795642 and parameters: {'n_estimators': 171, 'max_depth': 5, 'learning_rate': 0.04423947059215622, 'subsample': 0.835937218960147, 'colsample_bytree': 0.7828170299991812, 'gamma': 1.2512314034353447, 'min_child_weight': 3}. Best is trial 25 with value: 0.8108216893795642.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:34,889] Trial 26 finished with value: 0.8090295746842237 and parameters: {'n_estimators': 169, 'max_depth': 5, 'learning_rate': 0.0517194201867469, 'subsample': 0.9597918418689677, 'colsample_bytree': 0.7880750904195488, 'gamma': 0.5877487999038696, 'min_child_weight': 3}. Best is trial 25 with value: 0.8108216893795642.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:35,239] Trial 27 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 137, 'max_depth': 3, 'learning_rate': 0.07842663127935831, 'subsample': 0.8358007639640115, 'colsample_bytree': 0.7825651204660209, 'gamma': 1.445788688918542, 'min_child_weight': 4}. Best is trial 25 with value: 0.8108216893795642.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:35,593] Trial 28 finished with value: 0.816169282962452 and parameters: {'n_estimators': 130, 'max_depth': 3, 'learning_rate': 0.0815588272748633, 'subsample': 0.834493929649805, 'colsample_bytree': 0.8932558945650984, 'gamma': 1.4033179159777518, 'min_child_weight': 4}. Best is trial 28 with value: 0.816169282962452.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:35,863] Trial 29 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 111, 'max_depth': 3, 'learning_rate': 0.1118722810588392, 'subsample': 0.881407607924099, 'colsample_bytree': 0.9057981450885092, 'gamma': 2.085781006119693, 'min_child_weight': 5}. Best is trial 28 with value: 0.816169282962452.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:36,151] Trial 30 finished with value: 0.805416594790409 and parameters: {'n_estimators': 106, 'max_depth': 3, 'learning_rate': 0.10943083509433263, 'subsample': 0.7443975200312823, 'colsample_bytree': 0.9076101392686732, 'gamma': 1.9529995964766187, 'min_child_weight': 4}. Best is trial 28 with value: 0.816169282962452.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:36,442] Trial 31 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 118, 'max_depth': 3, 'learning_rate': 0.0771953920433882, 'subsample': 0.8864022625384533, 'colsample_bytree': 0.8911510019618707, 'gamma': 1.8426498826649802, 'min_child_weight': 5}. Best is trial 28 with value: 0.816169282962452.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:36,795] Trial 32 finished with value: 0.8054549287945872 and parameters: {'n_estimators': 158, 'max_depth': 4, 'learning_rate': 0.12013151711280905, 'subsample': 0.8403169512089523, 'colsample_bytree': 0.9952931664171195, 'gamma': 0.7634982045333565, 'min_child_weight': 6}. Best is trial 28 with value: 0.816169282962452.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:37,073] Trial 33 finished with value: 0.8018802829049508 and parameters: {'n_estimators': 118, 'max_depth': 3, 'learning_rate': 0.08872042696156061, 'subsample': 0.8712484795582409, 'colsample_bytree': 0.8805526202179641, 'gamma': 1.458959106746963, 'min_child_weight': 5}. Best is trial 28 with value: 0.816169282962452.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:37,375] Trial 34 finished with value: 0.810802522377475 and parameters: {'n_estimators': 139, 'max_depth': 4, 'learning_rate': 0.07327533987780308, 'subsample': 0.8140338232871464, 'colsample_bytree': 0.9443403808441304, 'gamma': 2.839427824820392, 'min_child_weight': 2}. Best is trial 28 with value: 0.816169282962452.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:37,652] Trial 35 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 139, 'max_depth': 5, 'learning_rate': 0.2563052797072688, 'subsample': 0.8123320888592224, 'colsample_bytree': 0.9419988748878941, 'gamma': 2.8737319058300734, 'min_child_weight': 2}. Best is trial 28 with value: 0.816169282962452.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:38,017] Trial 36 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 169, 'max_depth': 3, 'learning_rate': 0.042808463815097696, 'subsample': 0.9433242160408571, 'colsample_bytree': 0.929104713832775, 'gamma': 2.141393641466518, 'min_child_weight': 2}. Best is trial 28 with value: 0.816169282962452.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:38,333] Trial 37 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.09939576805430149, 'subsample': 0.7679820475874646, 'colsample_bytree': 0.9667711079536201, 'gamma': 2.821539705434143, 'min_child_weight': 3}. Best is trial 28 with value: 0.816169282962452.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:38,700] Trial 38 finished with value: 0.8108121058785196 and parameters: {'n_estimators': 156, 'max_depth': 7, 'learning_rate': 0.10085715312305307, 'subsample': 0.7605273771626676, 'colsample_bytree': 0.9871377852566471, 'gamma': 1.7275559041928457, 'min_child_weight': 3}. Best is trial 28 with value: 0.816169282962452.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:38,989] Trial 39 finished with value: 0.8018323653997279 and parameters: {'n_estimators': 122, 'max_depth': 6, 'learning_rate': 0.1278067372984472, 'subsample': 0.8847020031187156, 'colsample_bytree': 0.9603998290492244, 'gamma': 3.861495164614155, 'min_child_weight': 4}. Best is trial 28 with value: 0.816169282962452.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:39,459] Trial 40 finished with value: 0.8071895424836603 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.14302083987147077, 'subsample': 0.7096983590951568, 'colsample_bytree': 0.8384282877788936, 'gamma': 2.2350853956092593, 'min_child_weight': 1}. Best is trial 28 with value: 0.816169282962452.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:39,818] Trial 41 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 153, 'max_depth': 7, 'learning_rate': 0.09326467926038838, 'subsample': 0.7601070408524702, 'colsample_bytree': 0.9887088508632969, 'gamma': 1.612488791639901, 'min_child_weight': 3}. Best is trial 28 with value: 0.816169282962452.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:40,175] Trial 42 finished with value: 0.8179326471546585 and parameters: {'n_estimators': 147, 'max_depth': 8, 'learning_rate': 0.10945106053826101, 'subsample': 0.7883890522010809, 'colsample_bytree': 0.9732629330547538, 'gamma': 1.364852204425236, 'min_child_weight': 3}. Best is trial 42 with value: 0.8179326471546585.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:40,516] Trial 43 finished with value: 0.807218292986794 and parameters: {'n_estimators': 146, 'max_depth': 8, 'learning_rate': 0.11140476515561486, 'subsample': 0.7914672127414877, 'colsample_bytree': 0.9754917847835105, 'gamma': 1.5597302522636438, 'min_child_weight': 4}. Best is trial 42 with value: 0.8179326471546585.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:40,812] Trial 44 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 110, 'max_depth': 9, 'learning_rate': 0.09373521335950269, 'subsample': 0.7646449255955239, 'colsample_bytree': 0.9638845219329579, 'gamma': 1.9299552029686573, 'min_child_weight': 3}. Best is trial 42 with value: 0.8179326471546585.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:41,121] Trial 45 finished with value: 0.8000594177064766 and parameters: {'n_estimators': 130, 'max_depth': 8, 'learning_rate': 0.1403744180086678, 'subsample': 0.7104377709445058, 'colsample_bytree': 0.9313543003763918, 'gamma': 2.287620153753265, 'min_child_weight': 2}. Best is trial 42 with value: 0.8179326471546585.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:41,450] Trial 46 finished with value: 0.8125563030686371 and parameters: {'n_estimators': 149, 'max_depth': 7, 'learning_rate': 0.0886509935157398, 'subsample': 0.7666805877543631, 'colsample_bytree': 0.9022041418665365, 'gamma': 2.597755107932713, 'min_child_weight': 4}. Best is trial 42 with value: 0.8179326471546585.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:41,740] Trial 47 finished with value: 0.8143963352692006 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.15553572404663335, 'subsample': 0.798731955482742, 'colsample_bytree': 0.9883761956527621, 'gamma': 1.7438984340497656, 'min_child_weight': 3}. Best is trial 42 with value: 0.8179326471546585.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:42,055] Trial 48 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 126, 'max_depth': 7, 'learning_rate': 0.18582887472433468, 'subsample': 0.7900780841076208, 'colsample_bytree': 0.9981044636336313, 'gamma': 1.679983098496757, 'min_child_weight': 1}. Best is trial 42 with value: 0.8179326471546585.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:42,451] Trial 49 finished with value: 0.8018323653997279 and parameters: {'n_estimators': 145, 'max_depth': 8, 'learning_rate': 0.16067783638517905, 'subsample': 0.7514600576787733, 'colsample_bytree': 0.9781757395496771, 'gamma': 0.8186199154836534, 'min_child_weight': 3}. Best is trial 42 with value: 0.8179326471546585.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:42,801] Trial 50 finished with value: 0.805416594790409 and parameters: {'n_estimators': 155, 'max_depth': 7, 'learning_rate': 0.2235105000901924, 'subsample': 0.7253003045928734, 'colsample_bytree': 0.9489448419450767, 'gamma': 1.3696516049769425, 'min_child_weight': 2}. Best is trial 42 with value: 0.8179326471546585.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:43,085] Trial 51 finished with value: 0.8090295746842237 and parameters: {'n_estimators': 101, 'max_depth': 8, 'learning_rate': 0.15130943399934393, 'subsample': 0.7992667153421174, 'colsample_bytree': 0.923796020023739, 'gamma': 2.0175146731206812, 'min_child_weight': 3}. Best is trial 42 with value: 0.8179326471546585.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:43,396] Trial 52 finished with value: 0.8197151783489546 and parameters: {'n_estimators': 109, 'max_depth': 7, 'learning_rate': 0.13682203154927167, 'subsample': 0.7756896367856362, 'colsample_bytree': 0.9741392615128561, 'gamma': 1.738255363005544, 'min_child_weight': 4}. Best is trial 52 with value: 0.8197151783489546.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:43,696] Trial 53 finished with value: 0.8268644701282272 and parameters: {'n_estimators': 113, 'max_depth': 7, 'learning_rate': 0.13356255959701807, 'subsample': 0.8227892929620261, 'colsample_bytree': 0.9818719052158643, 'gamma': 1.721433068201912, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:44,011] Trial 54 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 111, 'max_depth': 10, 'learning_rate': 0.1739404323967569, 'subsample': 0.7799834587347668, 'colsample_bytree': 0.9678110764011612, 'gamma': 1.8193409931132176, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:44,366] Trial 55 finished with value: 0.8054453452935427 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.12921887659061784, 'subsample': 0.8233895053294564, 'colsample_bytree': 0.9561242974866389, 'gamma': 0.3864508046685988, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:44,702] Trial 56 finished with value: 0.8018802829049508 and parameters: {'n_estimators': 133, 'max_depth': 6, 'learning_rate': 0.13506638684093936, 'subsample': 0.7969423965651007, 'colsample_bytree': 0.9806707353978764, 'gamma': 1.3021030091506811, 'min_child_weight': 6}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:45,011] Trial 57 finished with value: 0.8036436470971576 and parameters: {'n_estimators': 118, 'max_depth': 9, 'learning_rate': 0.16119881757967386, 'subsample': 0.7765296805043388, 'colsample_bytree': 0.999084546684475, 'gamma': 2.916915736509404, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:45,354] Trial 58 finished with value: 0.8054549287945872 and parameters: {'n_estimators': 125, 'max_depth': 7, 'learning_rate': 0.1454446750490747, 'subsample': 0.8222266240302716, 'colsample_bytree': 0.9381661368047349, 'gamma': 2.3952413500586607, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:45,683] Trial 59 finished with value: 0.7947022406225442 and parameters: {'n_estimators': 107, 'max_depth': 6, 'learning_rate': 0.11666594752419168, 'subsample': 0.8029964376156776, 'colsample_bytree': 0.8846244989432935, 'gamma': 1.1760579983281114, 'min_child_weight': 8}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:45,989] Trial 60 finished with value: 0.8179134801525693 and parameters: {'n_estimators': 116, 'max_depth': 7, 'learning_rate': 0.20520718001585536, 'subsample': 0.6556107676555755, 'colsample_bytree': 0.9562026821815954, 'gamma': 2.621190275323468, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:46,270] Trial 61 finished with value: 0.8143388342629329 and parameters: {'n_estimators': 115, 'max_depth': 7, 'learning_rate': 0.2198075529921673, 'subsample': 0.6256141408440251, 'colsample_bytree': 0.9667037087337873, 'gamma': 3.192955870227985, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:46,576] Trial 62 finished with value: 0.8000402507043874 and parameters: {'n_estimators': 124, 'max_depth': 8, 'learning_rate': 0.25821988024914855, 'subsample': 0.6569182127948223, 'colsample_bytree': 0.9497249683573886, 'gamma': 2.4754968893520846, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:46,854] Trial 63 finished with value: 0.8000210837022982 and parameters: {'n_estimators': 106, 'max_depth': 7, 'learning_rate': 0.2872805752581426, 'subsample': 0.6421411906445966, 'colsample_bytree': 0.9164782980409706, 'gamma': 2.6859975081915755, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:47,127] Trial 64 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 132, 'max_depth': 6, 'learning_rate': 0.1945809186400949, 'subsample': 0.6860536039531122, 'colsample_bytree': 0.9788052567287, 'gamma': 3.661265283948515, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:47,449] Trial 65 finished with value: 0.7911180112318633 and parameters: {'n_estimators': 141, 'max_depth': 8, 'learning_rate': 0.22023527190123715, 'subsample': 0.60350345913162, 'colsample_bytree': 0.9563568497977964, 'gamma': 1.5407044585969791, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:47,757] Trial 66 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 163, 'max_depth': 7, 'learning_rate': 0.1048817621035199, 'subsample': 0.8267478781429164, 'colsample_bytree': 0.9711589373868177, 'gamma': 2.681499678228967, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:48,015] Trial 67 finished with value: 0.8036532305982022 and parameters: {'n_estimators': 116, 'max_depth': 6, 'learning_rate': 0.13265443933901802, 'subsample': 0.8525236617860055, 'colsample_bytree': 0.9868542014655265, 'gamma': 3.0321353735063052, 'min_child_weight': 5}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:48,372] Trial 68 finished with value: 0.8054261782914535 and parameters: {'n_estimators': 126, 'max_depth': 7, 'learning_rate': 0.17795603495614573, 'subsample': 0.7316829279715101, 'colsample_bytree': 0.8737423528237757, 'gamma': 0.8543663995234873, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:48,785] Trial 69 finished with value: 0.8108216893795642 and parameters: {'n_estimators': 203, 'max_depth': 8, 'learning_rate': 0.0605505167521157, 'subsample': 0.8675048542769447, 'colsample_bytree': 0.9332738608564536, 'gamma': 1.8123412278905298, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:49,138] Trial 70 finished with value: 0.7750368964790217 and parameters: {'n_estimators': 104, 'max_depth': 6, 'learning_rate': 0.21041043624305278, 'subsample': 0.7136561902968201, 'colsample_bytree': 0.9172037442714955, 'gamma': 3.365206864034744, 'min_child_weight': 10}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:49,557] Trial 71 finished with value: 0.810802522377475 and parameters: {'n_estimators': 176, 'max_depth': 7, 'learning_rate': 0.09813895905156837, 'subsample': 0.7721180319162152, 'colsample_bytree': 0.9901783542539057, 'gamma': 1.601630056696002, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:49,961] Trial 72 finished with value: 0.8089816571790007 and parameters: {'n_estimators': 114, 'max_depth': 7, 'learning_rate': 0.11965067866095055, 'subsample': 0.7535416552475094, 'colsample_bytree': 0.9876125799690446, 'gamma': 1.0816835279228352, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:50,474] Trial 73 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 135, 'max_depth': 7, 'learning_rate': 0.08132301212094421, 'subsample': 0.8091667340012514, 'colsample_bytree': 0.9572554832939786, 'gamma': 1.4081793857648208, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:50,960] Trial 74 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 136, 'max_depth': 8, 'learning_rate': 0.08031257842955959, 'subsample': 0.8088629757655075, 'colsample_bytree': 0.9498062908467307, 'gamma': 1.3504222948679414, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:51,331] Trial 75 finished with value: 0.8108121058785196 and parameters: {'n_estimators': 123, 'max_depth': 7, 'learning_rate': 0.08304661874563365, 'subsample': 0.8322723372583183, 'colsample_bytree': 0.9609928304156119, 'gamma': 2.053185355880423, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:51,679] Trial 76 finished with value: 0.816169282962452 and parameters: {'n_estimators': 130, 'max_depth': 6, 'learning_rate': 0.10146491863278459, 'subsample': 0.7903910309785359, 'colsample_bytree': 0.9396224060000988, 'gamma': 2.3445070434444264, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:52,051] Trial 77 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 119, 'max_depth': 6, 'learning_rate': 0.06750965904778153, 'subsample': 0.8423537208335914, 'colsample_bytree': 0.9446662573153213, 'gamma': 1.917853488694486, 'min_child_weight': 5}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:52,408] Trial 78 finished with value: 0.8161021984551396 and parameters: {'n_estimators': 130, 'max_depth': 9, 'learning_rate': 0.23623939476885644, 'subsample': 0.7852049475565559, 'colsample_bytree': 0.9026166831136399, 'gamma': 1.455221299861024, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:52,774] Trial 79 finished with value: 0.7982864700132253 and parameters: {'n_estimators': 143, 'max_depth': 9, 'learning_rate': 0.24579079281459545, 'subsample': 0.7877004175278493, 'colsample_bytree': 0.9029326165031416, 'gamma': 1.1862061422995425, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:53,110] Trial 80 finished with value: 0.8036819811013359 and parameters: {'n_estimators': 129, 'max_depth': 10, 'learning_rate': 0.27363001755188854, 'subsample': 0.8137020514558075, 'colsample_bytree': 0.8981018665871606, 'gamma': 2.2982536126834727, 'min_child_weight': 5}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:53,421] Trial 81 finished with value: 0.7946830736204551 and parameters: {'n_estimators': 110, 'max_depth': 9, 'learning_rate': 0.23948740296424526, 'subsample': 0.8029038622152028, 'colsample_bytree': 0.923572701539416, 'gamma': 1.4653681245775543, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:53,750] Trial 82 finished with value: 0.8178943131504801 and parameters: {'n_estimators': 135, 'max_depth': 8, 'learning_rate': 0.2370002442481981, 'subsample': 0.7835701500860981, 'colsample_bytree': 0.8693212069006299, 'gamma': 1.7433322780599623, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:54,098] Trial 83 finished with value: 0.7875816993464052 and parameters: {'n_estimators': 136, 'max_depth': 8, 'learning_rate': 0.23397653213488495, 'subsample': 0.8510558291659158, 'colsample_bytree': 0.8715124035379785, 'gamma': 0.9642642447507672, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:54,440] Trial 84 finished with value: 0.8000785847085657 and parameters: {'n_estimators': 161, 'max_depth': 8, 'learning_rate': 0.2669746857627281, 'subsample': 0.7799482309013726, 'colsample_bytree': 0.9359910753577194, 'gamma': 1.4370449388448, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:54,756] Trial 85 finished with value: 0.7982577195100915 and parameters: {'n_estimators': 130, 'max_depth': 9, 'learning_rate': 0.20671393942510952, 'subsample': 0.7453246906929334, 'colsample_bytree': 0.8444593534879473, 'gamma': 1.6712889033678704, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:55,050] Trial 86 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 120, 'max_depth': 9, 'learning_rate': 0.11472682775448685, 'subsample': 0.7881047274560966, 'colsample_bytree': 0.8616821494716573, 'gamma': 2.152699698478478, 'min_child_weight': 5}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:55,384] Trial 87 finished with value: 0.8107737718743412 and parameters: {'n_estimators': 148, 'max_depth': 8, 'learning_rate': 0.23381055167055914, 'subsample': 0.8145002623882651, 'colsample_bytree': 0.8884483751228566, 'gamma': 1.2637203993776325, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:55,823] Trial 88 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 141, 'max_depth': 10, 'learning_rate': 0.05624334898805979, 'subsample': 0.8400334615568664, 'colsample_bytree': 0.9086832916740691, 'gamma': 1.9552378388489116, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:56,184] Trial 89 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 134, 'max_depth': 7, 'learning_rate': 0.12608069527240895, 'subsample': 0.8260063971566718, 'colsample_bytree': 0.9260003238339278, 'gamma': 1.5044010864000097, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:56,593] Trial 90 finished with value: 0.82330899124068 and parameters: {'n_estimators': 193, 'max_depth': 8, 'learning_rate': 0.10588000038454881, 'subsample': 0.7554454272188512, 'colsample_bytree': 0.953723174381672, 'gamma': 1.732730832862135, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:56,922] Trial 91 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 129, 'max_depth': 8, 'learning_rate': 0.10685913859351685, 'subsample': 0.7711414348044707, 'colsample_bytree': 0.8126525912582152, 'gamma': 1.7332679413633951, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:57,349] Trial 92 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 199, 'max_depth': 8, 'learning_rate': 0.07366114188017561, 'subsample': 0.697734784154129, 'colsample_bytree': 0.9527335295201601, 'gamma': 1.8245427291403897, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:57,694] Trial 93 finished with value: 0.8089912406800454 and parameters: {'n_estimators': 114, 'max_depth': 8, 'learning_rate': 0.09054238424263451, 'subsample': 0.7566196822897601, 'colsample_bytree': 0.9740686346478653, 'gamma': 1.3615205455149915, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:58,022] Trial 94 finished with value: 0.8018419489007725 and parameters: {'n_estimators': 191, 'max_depth': 9, 'learning_rate': 0.10287431249156162, 'subsample': 0.7940016115159828, 'colsample_bytree': 0.9396987589536119, 'gamma': 4.837354478565075, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:58,481] Trial 95 finished with value: 0.8126042205738601 and parameters: {'n_estimators': 290, 'max_depth': 7, 'learning_rate': 0.08462644141481523, 'subsample': 0.8098748542414353, 'colsample_bytree': 0.9592042334753215, 'gamma': 2.373122976425578, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:58,856] Trial 96 finished with value: 0.7946734901194104 and parameters: {'n_estimators': 210, 'max_depth': 7, 'learning_rate': 0.22849186750732725, 'subsample': 0.7841972315089548, 'colsample_bytree': 0.9140143119882537, 'gamma': 1.5570078099143725, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:59,366] Trial 97 finished with value: 0.8071895424836603 and parameters: {'n_estimators': 226, 'max_depth': 8, 'learning_rate': 0.13802257133568285, 'subsample': 0.7471692530050019, 'colsample_bytree': 0.8974729694195895, 'gamma': 2.565375737191612, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:47:59,805] Trial 98 finished with value: 0.7947022406225442 and parameters: {'n_estimators': 246, 'max_depth': 9, 'learning_rate': 0.24849692699095724, 'subsample': 0.8309941551147295, 'colsample_bytree': 0.8765627974311887, 'gamma': 1.0595217793419351, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:47:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:00,231] Trial 99 finished with value: 0.805416594790409 and parameters: {'n_estimators': 151, 'max_depth': 7, 'learning_rate': 0.14601669317372026, 'subsample': 0.8182055200443983, 'colsample_bytree': 0.9723203898599355, 'gamma': 0.6795911104291565, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:00,580] Trial 100 finished with value: 0.8054261782914535 and parameters: {'n_estimators': 127, 'max_depth': 10, 'learning_rate': 0.0965675466163557, 'subsample': 0.8770989296277445, 'colsample_bytree': 0.943449950713229, 'gamma': 1.1702010361193478, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:00,869] Trial 101 finished with value: 0.8054549287945872 and parameters: {'n_estimators': 104, 'max_depth': 7, 'learning_rate': 0.1653453515806521, 'subsample': 0.7953958077009968, 'colsample_bytree': 0.979245657245102, 'gamma': 1.926667708829347, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:01,198] Trial 102 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 121, 'max_depth': 7, 'learning_rate': 0.10998249748669332, 'subsample': 0.8033567163723659, 'colsample_bytree': 0.995579571724236, 'gamma': 1.7344782346820822, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:01,493] Trial 103 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 109, 'max_depth': 7, 'learning_rate': 0.15265021410144036, 'subsample': 0.7766907315508036, 'colsample_bytree': 0.985870971445234, 'gamma': 1.6829800976643852, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:01,783] Trial 104 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 115, 'max_depth': 6, 'learning_rate': 0.18780690096296193, 'subsample': 0.8606942351076928, 'colsample_bytree': 0.9622564925254392, 'gamma': 2.1648702849889494, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:02,099] Trial 105 finished with value: 0.810802522377475 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.12142844027332261, 'subsample': 0.7402222718087041, 'colsample_bytree': 0.9683759670674215, 'gamma': 1.3642144834399361, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:02,422] Trial 106 finished with value: 0.8054453452935427 and parameters: {'n_estimators': 139, 'max_depth': 7, 'learning_rate': 0.2547676903489758, 'subsample': 0.7226641592352196, 'colsample_bytree': 0.9315786981839016, 'gamma': 2.04014929667325, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:02,713] Trial 107 finished with value: 0.8036436470971576 and parameters: {'n_estimators': 112, 'max_depth': 7, 'learning_rate': 0.13306030999999344, 'subsample': 0.762631222375265, 'colsample_bytree': 0.9533109226117479, 'gamma': 1.5674921742046677, 'min_child_weight': 5}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:03,027] Trial 108 finished with value: 0.7982864700132253 and parameters: {'n_estimators': 122, 'max_depth': 6, 'learning_rate': 0.20757044005389097, 'subsample': 0.797828128251655, 'colsample_bytree': 0.8551969574598143, 'gamma': 1.2449034193302684, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:03,336] Trial 109 finished with value: 0.7929005424261591 and parameters: {'n_estimators': 134, 'max_depth': 5, 'learning_rate': 0.21397425480103882, 'subsample': 0.7830986876363076, 'colsample_bytree': 0.9829343866267917, 'gamma': 1.7912461932690535, 'min_child_weight': 9}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:03,682] Trial 110 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 145, 'max_depth': 8, 'learning_rate': 0.11475094344199133, 'subsample': 0.7707837236092404, 'colsample_bytree': 0.7113388678323507, 'gamma': 1.4421157951446215, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:03,992] Trial 111 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.10058230269327476, 'subsample': 0.7668478760170853, 'colsample_bytree': 0.9651670035677781, 'gamma': 2.7535696148557878, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:04,349] Trial 112 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 152, 'max_depth': 4, 'learning_rate': 0.09112647031638214, 'subsample': 0.8080962946705824, 'colsample_bytree': 0.9729446891690365, 'gamma': 1.6290658455756029, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:04,721] Trial 113 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 159, 'max_depth': 6, 'learning_rate': 0.07566540318746376, 'subsample': 0.6631934928310758, 'colsample_bytree': 0.9928293446273636, 'gamma': 2.538067516427857, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:05,018] Trial 114 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 125, 'max_depth': 7, 'learning_rate': 0.1289275014710756, 'subsample': 0.7912793691725056, 'colsample_bytree': 0.9479241454018069, 'gamma': 2.7834352442922663, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:05,370] Trial 115 finished with value: 0.8108216893795642 and parameters: {'n_estimators': 168, 'max_depth': 6, 'learning_rate': 0.08676315419385787, 'subsample': 0.820355435500137, 'colsample_bytree': 0.9987689063156162, 'gamma': 1.8751788303004968, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:05,762] Trial 116 finished with value: 0.803634063596113 and parameters: {'n_estimators': 138, 'max_depth': 7, 'learning_rate': 0.2013586007522296, 'subsample': 0.7559979515142822, 'colsample_bytree': 0.918296085301804, 'gamma': 2.26734071276556, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:06,113] Trial 117 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 132, 'max_depth': 5, 'learning_rate': 0.0973312322818201, 'subsample': 0.774907683713363, 'colsample_bytree': 0.956973068232087, 'gamma': 2.9341716523633266, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:06,449] Trial 118 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 132, 'max_depth': 6, 'learning_rate': 0.10772002640748284, 'subsample': 0.778751990079736, 'colsample_bytree': 0.9379189235778836, 'gamma': 2.9236681870574275, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:06,762] Trial 119 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 131, 'max_depth': 6, 'learning_rate': 0.10531079606188117, 'subsample': 0.7765591210133502, 'colsample_bytree': 0.8332018127885978, 'gamma': 3.0403088848379443, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:07,080] Trial 120 finished with value: 0.8215072930442949 and parameters: {'n_estimators': 133, 'max_depth': 6, 'learning_rate': 0.10436838329385659, 'subsample': 0.7729308954438807, 'colsample_bytree': 0.8310276402878278, 'gamma': 2.998381846959156, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:07,401] Trial 121 finished with value: 0.8179326471546585 and parameters: {'n_estimators': 133, 'max_depth': 6, 'learning_rate': 0.10499906222902715, 'subsample': 0.770034998528347, 'colsample_bytree': 0.8227999808301054, 'gamma': 2.976855218666273, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:07,701] Trial 122 finished with value: 0.819724761849999 and parameters: {'n_estimators': 142, 'max_depth': 6, 'learning_rate': 0.1178115314456076, 'subsample': 0.7620759653277396, 'colsample_bytree': 0.823541866741354, 'gamma': 3.0593768945588815, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:07,995] Trial 123 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 145, 'max_depth': 6, 'learning_rate': 0.11955040685744772, 'subsample': 0.7327178147195812, 'colsample_bytree': 0.8232322149015677, 'gamma': 3.0465165654325324, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:08,297] Trial 124 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 141, 'max_depth': 6, 'learning_rate': 0.11329971530662317, 'subsample': 0.7469001796858017, 'colsample_bytree': 0.834382072774865, 'gamma': 3.3930477206815994, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:08,588] Trial 125 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 142, 'max_depth': 6, 'learning_rate': 0.11317557076971305, 'subsample': 0.751333198008407, 'colsample_bytree': 0.8047882431573334, 'gamma': 3.395364616545568, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:08,888] Trial 126 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 140, 'max_depth': 6, 'learning_rate': 0.1236971800284897, 'subsample': 0.7239311222682973, 'colsample_bytree': 0.8092990645319686, 'gamma': 3.2878349409215026, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:09,204] Trial 127 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 156, 'max_depth': 6, 'learning_rate': 0.11511357216563128, 'subsample': 0.7496458686328915, 'colsample_bytree': 0.797413116777007, 'gamma': 3.4844751912532694, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:09,510] Trial 128 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 147, 'max_depth': 6, 'learning_rate': 0.14255190716371227, 'subsample': 0.7620083336199021, 'colsample_bytree': 0.8335431059980095, 'gamma': 3.75131619569693, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:09,827] Trial 129 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 142, 'max_depth': 6, 'learning_rate': 0.1106833271773131, 'subsample': 0.7406092217272174, 'colsample_bytree': 0.7671242011886151, 'gamma': 3.151969739461731, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:10,143] Trial 130 finished with value: 0.803634063596113 and parameters: {'n_estimators': 144, 'max_depth': 6, 'learning_rate': 0.1326506774495142, 'subsample': 0.7419743998530655, 'colsample_bytree': 0.7722141088498341, 'gamma': 3.279481249326107, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:10,447] Trial 131 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 138, 'max_depth': 6, 'learning_rate': 0.11056659723741995, 'subsample': 0.7012865321781836, 'colsample_bytree': 0.8172953244015801, 'gamma': 3.163332656937551, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:10,786] Trial 132 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 142, 'max_depth': 5, 'learning_rate': 0.1268750539876932, 'subsample': 0.7532943466908526, 'colsample_bytree': 0.791140052823086, 'gamma': 3.391866790360756, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:11,282] Trial 133 finished with value: 0.8036436470971576 and parameters: {'n_estimators': 135, 'max_depth': 6, 'learning_rate': 0.11582221588147548, 'subsample': 0.6477902061963425, 'colsample_bytree': 0.8053727435188299, 'gamma': 3.9887403392098237, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:11,636] Trial 134 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 152, 'max_depth': 6, 'learning_rate': 0.09386293311362856, 'subsample': 0.6818028454262152, 'colsample_bytree': 0.7680394729252593, 'gamma': 3.546859168763135, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:11,946] Trial 135 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 126, 'max_depth': 6, 'learning_rate': 0.0809361174716032, 'subsample': 0.7615099543330657, 'colsample_bytree': 0.8466997611327446, 'gamma': 3.2120251822420367, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:12,251] Trial 136 finished with value: 0.810802522377475 and parameters: {'n_estimators': 124, 'max_depth': 6, 'learning_rate': 0.12170136533497529, 'subsample': 0.7355945050818506, 'colsample_bytree': 0.7429362720577409, 'gamma': 3.1330622961411216, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:12,543] Trial 137 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 120, 'max_depth': 6, 'learning_rate': 0.10401820683326495, 'subsample': 0.7616313004956848, 'colsample_bytree': 0.8507429950016414, 'gamma': 3.579101493833843, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:12,844] Trial 138 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 148, 'max_depth': 6, 'learning_rate': 0.13559558821712123, 'subsample': 0.74456736817748, 'colsample_bytree': 0.8285841717520889, 'gamma': 3.378214499098642, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:13,211] Trial 139 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 236, 'max_depth': 6, 'learning_rate': 0.10885500138421483, 'subsample': 0.727527469606547, 'colsample_bytree': 0.8442679477181757, 'gamma': 3.2040901494736485, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:13,521] Trial 140 finished with value: 0.807218292986794 and parameters: {'n_estimators': 127, 'max_depth': 6, 'learning_rate': 0.06621023133468197, 'subsample': 0.6175065807498095, 'colsample_bytree': 0.8023143387178543, 'gamma': 3.06852770790795, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:13,848] Trial 141 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 137, 'max_depth': 7, 'learning_rate': 0.07822583184442554, 'subsample': 0.7664369142620776, 'colsample_bytree': 0.8671865794129924, 'gamma': 2.9491343083192216, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:14,176] Trial 142 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 141, 'max_depth': 5, 'learning_rate': 0.08723578474122676, 'subsample': 0.7158293218317939, 'colsample_bytree': 0.8158932679922053, 'gamma': 3.44166889820294, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:14,469] Trial 143 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 117, 'max_depth': 8, 'learning_rate': 0.09718289451324674, 'subsample': 0.7570039803810825, 'colsample_bytree': 0.8268505581761626, 'gamma': 3.2472889372126987, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:14,782] Trial 144 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 136, 'max_depth': 7, 'learning_rate': 0.08256931196675459, 'subsample': 0.7704004012972662, 'colsample_bytree': 0.8427380823013261, 'gamma': 3.6711677506851754, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:15,090] Trial 145 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 128, 'max_depth': 6, 'learning_rate': 0.11251912651661966, 'subsample': 0.7489271534547501, 'colsample_bytree': 0.8373685702857384, 'gamma': 2.8502302868569958, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:15,429] Trial 146 finished with value: 0.8179518141567478 and parameters: {'n_estimators': 165, 'max_depth': 6, 'learning_rate': 0.11362715340315681, 'subsample': 0.7381082537512919, 'colsample_bytree': 0.7359413337916867, 'gamma': 2.687949368336199, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:15,781] Trial 147 finished with value: 0.8107737718743412 and parameters: {'n_estimators': 182, 'max_depth': 6, 'learning_rate': 0.11291241201121549, 'subsample': 0.7481611257459109, 'colsample_bytree': 0.7785052917314292, 'gamma': 2.695620641518494, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:16,191] Trial 148 finished with value: 0.8054549287945872 and parameters: {'n_estimators': 176, 'max_depth': 6, 'learning_rate': 0.12093631951302546, 'subsample': 0.73891062124959, 'colsample_bytree': 0.7271319380674611, 'gamma': 2.637170632266891, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:16,607] Trial 149 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 217, 'max_depth': 6, 'learning_rate': 0.12591276400700424, 'subsample': 0.7517089003478706, 'colsample_bytree': 0.7250849797192018, 'gamma': 2.872665340396261, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:16,954] Trial 150 finished with value: 0.8072374599888832 and parameters: {'n_estimators': 154, 'max_depth': 6, 'learning_rate': 0.10179533479250127, 'subsample': 0.717000746433311, 'colsample_bytree': 0.7506928020301262, 'gamma': 2.983029875931753, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:17,281] Trial 151 finished with value: 0.8036628140992468 and parameters: {'n_estimators': 143, 'max_depth': 6, 'learning_rate': 0.11624670366035285, 'subsample': 0.7354113476901158, 'colsample_bytree': 0.8190996537043046, 'gamma': 2.7749920699601924, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:17,592] Trial 152 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 128, 'max_depth': 6, 'learning_rate': 0.1109041389603869, 'subsample': 0.76333823044789, 'colsample_bytree': 0.848771363016959, 'gamma': 3.0972625334390176, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:17,919] Trial 153 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 164, 'max_depth': 6, 'learning_rate': 0.10926890444168899, 'subsample': 0.7592042056619076, 'colsample_bytree': 0.8519480913587415, 'gamma': 2.861449344883767, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:18,260] Trial 154 finished with value: 0.8018515324018171 and parameters: {'n_estimators': 192, 'max_depth': 6, 'learning_rate': 0.13004378256056187, 'subsample': 0.7671522748803569, 'colsample_bytree': 0.8386074910380189, 'gamma': 3.114400724036909, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:18,561] Trial 155 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 126, 'max_depth': 6, 'learning_rate': 0.13941451430806207, 'subsample': 0.7453480532859049, 'colsample_bytree': 0.6897308620405508, 'gamma': 2.486243580576131, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:18,850] Trial 156 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 117, 'max_depth': 6, 'learning_rate': 0.09400068820666338, 'subsample': 0.7560515251440831, 'colsample_bytree': 0.8315331395831608, 'gamma': 3.14974221888983, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:19,181] Trial 157 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 128, 'max_depth': 6, 'learning_rate': 0.1177963494451875, 'subsample': 0.7318635446909707, 'colsample_bytree': 0.7917871843910971, 'gamma': 3.306114469055354, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:19,474] Trial 158 finished with value: 0.8071991259847048 and parameters: {'n_estimators': 111, 'max_depth': 6, 'learning_rate': 0.148766185996239, 'subsample': 0.7748242096185074, 'colsample_bytree': 0.8059513052749118, 'gamma': 3.000140455939968, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:19,808] Trial 159 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 123, 'max_depth': 7, 'learning_rate': 0.10578551378629458, 'subsample': 0.762794967759805, 'colsample_bytree': 0.7604457923357489, 'gamma': 2.8072630981385807, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:20,129] Trial 160 finished with value: 0.8197055948479098 and parameters: {'n_estimators': 133, 'max_depth': 6, 'learning_rate': 0.11216092593239115, 'subsample': 0.7849711946892404, 'colsample_bytree': 0.8388750060959189, 'gamma': 2.6555290041491393, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:20,448] Trial 161 finished with value: 0.8143484177639776 and parameters: {'n_estimators': 134, 'max_depth': 6, 'learning_rate': 0.11118012131107673, 'subsample': 0.7795045625047907, 'colsample_bytree': 0.8429717732686355, 'gamma': 2.6560849715700767, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:20,778] Trial 162 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 149, 'max_depth': 6, 'learning_rate': 0.10022388928307278, 'subsample': 0.7867656577603321, 'colsample_bytree': 0.8228243809422938, 'gamma': 3.2286640849181665, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:21,143] Trial 163 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 140, 'max_depth': 6, 'learning_rate': 0.12311493280831008, 'subsample': 0.7495653765719146, 'colsample_bytree': 0.8612808998602777, 'gamma': 2.560510373291958, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:21,662] Trial 164 finished with value: 0.8107641883732967 and parameters: {'n_estimators': 140, 'max_depth': 6, 'learning_rate': 0.12316518194423971, 'subsample': 0.7427528064430642, 'colsample_bytree': 0.8364110788580018, 'gamma': 3.074406412449817, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:22,027] Trial 165 finished with value: 0.8143388342629331 and parameters: {'n_estimators': 144, 'max_depth': 6, 'learning_rate': 0.11349671565263197, 'subsample': 0.7517479515174983, 'colsample_bytree': 0.859414885309611, 'gamma': 2.5479981462296624, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:22,651] Trial 166 finished with value: 0.8107546048722519 and parameters: {'n_estimators': 133, 'max_depth': 6, 'learning_rate': 0.12783877638567534, 'subsample': 0.7672701197941737, 'colsample_bytree': 0.8626081761880842, 'gamma': 2.9352632207734746, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:22,969] Trial 167 finished with value: 0.8054261782914535 and parameters: {'n_estimators': 137, 'max_depth': 6, 'learning_rate': 0.1194014571773126, 'subsample': 0.7240667690700627, 'colsample_bytree': 0.6186469562425866, 'gamma': 2.725746316270338, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:23,252] Trial 168 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 128, 'max_depth': 5, 'learning_rate': 0.1060622271505017, 'subsample': 0.7394136005492262, 'colsample_bytree': 0.8115523508296787, 'gamma': 3.3736338236541354, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:23,564] Trial 169 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 146, 'max_depth': 6, 'learning_rate': 0.13278016195992445, 'subsample': 0.7581143156164423, 'colsample_bytree': 0.8493866632820078, 'gamma': 2.4283506929320544, 'min_child_weight': 6}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:23,874] Trial 170 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 141, 'max_depth': 6, 'learning_rate': 0.09237122394842859, 'subsample': 0.748319199453619, 'colsample_bytree': 0.8261066744345724, 'gamma': 2.841476268439114, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:24,164] Trial 171 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 122, 'max_depth': 6, 'learning_rate': 0.11290331517033404, 'subsample': 0.7711269494171926, 'colsample_bytree': 0.835991561568245, 'gamma': 3.008079964005375, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:24,518] Trial 172 finished with value: 0.8054261782914535 and parameters: {'n_estimators': 203, 'max_depth': 6, 'learning_rate': 0.12338732580101837, 'subsample': 0.79884792696898, 'colsample_bytree': 0.8486859893299175, 'gamma': 3.200123545843368, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:24,823] Trial 173 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 131, 'max_depth': 7, 'learning_rate': 0.10392982199271975, 'subsample': 0.7837672055678507, 'colsample_bytree': 0.7416588727070581, 'gamma': 2.643714330431767, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:25,137] Trial 174 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 119, 'max_depth': 6, 'learning_rate': 0.11856349393949805, 'subsample': 0.7054051774441552, 'colsample_bytree': 0.8170707251644298, 'gamma': 2.518137642999278, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:25,436] Trial 175 finished with value: 0.8054549287945872 and parameters: {'n_estimators': 113, 'max_depth': 7, 'learning_rate': 0.10993623193809675, 'subsample': 0.7932486781745498, 'colsample_bytree': 0.8322682478759543, 'gamma': 2.7805587758678487, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:25,744] Trial 176 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 138, 'max_depth': 6, 'learning_rate': 0.13528376186461397, 'subsample': 0.7622289927396231, 'colsample_bytree': 0.7823309347310529, 'gamma': 3.4738863519146808, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:26,043] Trial 177 finished with value: 0.8036148965940239 and parameters: {'n_estimators': 133, 'max_depth': 6, 'learning_rate': 0.0986509702426547, 'subsample': 0.7749968288593634, 'colsample_bytree': 0.855668002082303, 'gamma': 3.1129598964317795, 'min_child_weight': 7}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:26,451] Trial 178 finished with value: 0.8179230636536139 and parameters: {'n_estimators': 149, 'max_depth': 7, 'learning_rate': 0.11587766283706274, 'subsample': 0.8075036809922637, 'colsample_bytree': 0.841482271048843, 'gamma': 3.331304878783756, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:26,809] Trial 179 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 148, 'max_depth': 6, 'learning_rate': 0.11595239979754195, 'subsample': 0.8108496941810827, 'colsample_bytree': 0.8404544730988743, 'gamma': 3.3268100830277385, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:27,145] Trial 180 finished with value: 0.803634063596113 and parameters: {'n_estimators': 151, 'max_depth': 7, 'learning_rate': 0.1271091234939018, 'subsample': 0.8022063073611565, 'colsample_bytree': 0.8269886866860958, 'gamma': 3.6559507158823283, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:27,483] Trial 181 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 157, 'max_depth': 7, 'learning_rate': 0.10747186619844332, 'subsample': 0.7539011383809041, 'colsample_bytree': 0.8446743921745553, 'gamma': 3.2412699067491313, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:27,808] Trial 182 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 142, 'max_depth': 7, 'learning_rate': 0.12240159501703685, 'subsample': 0.7868215735344661, 'colsample_bytree': 0.8193711677550436, 'gamma': 2.8954343496501544, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:28,128] Trial 183 finished with value: 0.816140532459318 and parameters: {'n_estimators': 127, 'max_depth': 7, 'learning_rate': 0.1025710377055656, 'subsample': 0.7721154125022387, 'colsample_bytree': 0.9774324263812395, 'gamma': 2.600426878687808, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:28,456] Trial 184 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 107, 'max_depth': 6, 'learning_rate': 0.11196879368813835, 'subsample': 0.7644669535910505, 'colsample_bytree': 0.8022326026931677, 'gamma': 3.033223126674956, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:28,749] Trial 185 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 138, 'max_depth': 6, 'learning_rate': 0.11759469648754248, 'subsample': 0.8184302314950562, 'colsample_bytree': 0.8618725377537232, 'gamma': 3.3781999551111417, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:29,081] Trial 186 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 134, 'max_depth': 7, 'learning_rate': 0.09749292911964554, 'subsample': 0.8064024796747273, 'colsample_bytree': 0.8364766541969709, 'gamma': 2.7231353966387406, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:29,381] Trial 187 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 146, 'max_depth': 6, 'learning_rate': 0.14332073480466315, 'subsample': 0.7399798856357024, 'colsample_bytree': 0.7328913533369912, 'gamma': 3.1666109632570913, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:29,698] Trial 188 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 154, 'max_depth': 6, 'learning_rate': 0.14512018527903678, 'subsample': 0.7335890107139348, 'colsample_bytree': 0.8107927167871127, 'gamma': 3.172546217464161, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:30,053] Trial 189 finished with value: 0.8036244800950684 and parameters: {'n_estimators': 145, 'max_depth': 6, 'learning_rate': 0.036005466005741144, 'subsample': 0.7422914339533042, 'colsample_bytree': 0.7228540525640917, 'gamma': 3.5044585761195517, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:30,404] Trial 190 finished with value: 0.8000594177064766 and parameters: {'n_estimators': 150, 'max_depth': 6, 'learning_rate': 0.1377452670352886, 'subsample': 0.9935133304812518, 'colsample_bytree': 0.7603689661660649, 'gamma': 3.27780959881158, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:30,717] Trial 191 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 142, 'max_depth': 6, 'learning_rate': 0.12932880438354655, 'subsample': 0.7506087776270278, 'colsample_bytree': 0.7297877044635446, 'gamma': 3.115969048911318, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:31,039] Trial 192 finished with value: 0.8125563030686371 and parameters: {'n_estimators': 141, 'max_depth': 6, 'learning_rate': 0.15414636813306745, 'subsample': 0.7508545680118051, 'colsample_bytree': 0.7314460096853571, 'gamma': 3.09052307063573, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:31,388] Trial 193 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 145, 'max_depth': 6, 'learning_rate': 0.13013493998468384, 'subsample': 0.7310461915442046, 'colsample_bytree': 0.7154037062864645, 'gamma': 2.9855016315049623, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:31,742] Trial 194 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 138, 'max_depth': 6, 'learning_rate': 0.13951808977611524, 'subsample': 0.7425197848658788, 'colsample_bytree': 0.7369070473514792, 'gamma': 3.1840741027545656, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:32,085] Trial 195 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 136, 'max_depth': 6, 'learning_rate': 0.13260159408199784, 'subsample': 0.7410790168845175, 'colsample_bytree': 0.7377700983804159, 'gamma': 3.1203236173240807, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:32,400] Trial 196 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 137, 'max_depth': 6, 'learning_rate': 0.1410499720757505, 'subsample': 0.7232191759405098, 'colsample_bytree': 0.7030498589567433, 'gamma': 3.1782652605759325, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:32,699] Trial 197 finished with value: 0.816169282962452 and parameters: {'n_estimators': 130, 'max_depth': 5, 'learning_rate': 0.14197567367911187, 'subsample': 0.73928331054596, 'colsample_bytree': 0.7363182549426706, 'gamma': 3.1420793563917906, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:33,000] Trial 198 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 141, 'max_depth': 6, 'learning_rate': 0.13295889380734796, 'subsample': 0.7531130778748616, 'colsample_bytree': 0.7194116176576453, 'gamma': 3.427813410105734, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:33,311] Trial 199 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 141, 'max_depth': 6, 'learning_rate': 0.13536348515282698, 'subsample': 0.7474925735537452, 'colsample_bytree': 0.7503085915195411, 'gamma': 3.2489030949224476, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:33,596] Trial 200 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 136, 'max_depth': 6, 'learning_rate': 0.14895184449850202, 'subsample': 0.7555994581723704, 'colsample_bytree': 0.7156780206814359, 'gamma': 3.622542188422482, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:33,897] Trial 201 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 136, 'max_depth': 6, 'learning_rate': 0.15073377380393166, 'subsample': 0.7561751018298708, 'colsample_bytree': 0.7011884907403525, 'gamma': 3.442717659687081, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:34,207] Trial 202 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 136, 'max_depth': 6, 'learning_rate': 0.15759888724403054, 'subsample': 0.758073340926045, 'colsample_bytree': 0.7040525558417364, 'gamma': 3.5901959917818114, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:34,500] Trial 203 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 132, 'max_depth': 6, 'learning_rate': 0.1497591329702581, 'subsample': 0.7391103562241343, 'colsample_bytree': 0.6921314228782336, 'gamma': 3.4472114244512997, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:34,817] Trial 204 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 136, 'max_depth': 6, 'learning_rate': 0.16545545777760523, 'subsample': 0.7469846135437843, 'colsample_bytree': 0.717988354548182, 'gamma': 3.693875626255958, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:35,123] Trial 205 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 137, 'max_depth': 6, 'learning_rate': 0.15599103292454022, 'subsample': 0.7308629600550202, 'colsample_bytree': 0.717154014456246, 'gamma': 3.781971751232165, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:35,401] Trial 206 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 138, 'max_depth': 6, 'learning_rate': 0.17264922674871025, 'subsample': 0.758638365379219, 'colsample_bytree': 0.7013045423078648, 'gamma': 3.6158574060357354, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:35,700] Trial 207 finished with value: 0.814386751768156 and parameters: {'n_estimators': 135, 'max_depth': 6, 'learning_rate': 0.17452124942871922, 'subsample': 0.7585418234218312, 'colsample_bytree': 0.7016853551426696, 'gamma': 4.126974397332524, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:36,006] Trial 208 finished with value: 0.8179518141567478 and parameters: {'n_estimators': 139, 'max_depth': 6, 'learning_rate': 0.16905535387191728, 'subsample': 0.7428206779277795, 'colsample_bytree': 0.7086991109927172, 'gamma': 3.855555048519017, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:36,309] Trial 209 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 139, 'max_depth': 6, 'learning_rate': 0.16731596853926353, 'subsample': 0.7429927664146878, 'colsample_bytree': 0.6740791633391949, 'gamma': 3.660540489862973, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:36,766] Trial 210 finished with value: 0.8126042205738601 and parameters: {'n_estimators': 145, 'max_depth': 6, 'learning_rate': 0.17035579383543628, 'subsample': 0.7359356235540981, 'colsample_bytree': 0.718972164874986, 'gamma': 3.8823437771680367, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:37,095] Trial 211 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 133, 'max_depth': 6, 'learning_rate': 0.16556759849115532, 'subsample': 0.7574844253114491, 'colsample_bytree': 0.7095106342925277, 'gamma': 3.6815383049850823, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:37,425] Trial 212 finished with value: 0.816169282962452 and parameters: {'n_estimators': 139, 'max_depth': 6, 'learning_rate': 0.18120853840263074, 'subsample': 0.7590299695836098, 'colsample_bytree': 0.7362812482153578, 'gamma': 3.9421016631961825, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:37,738] Trial 213 finished with value: 0.810802522377475 and parameters: {'n_estimators': 131, 'max_depth': 6, 'learning_rate': 0.14680094311819433, 'subsample': 0.7441626771575867, 'colsample_bytree': 0.7053104803258063, 'gamma': 3.8529681325916236, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:38,048] Trial 214 finished with value: 0.8179518141567478 and parameters: {'n_estimators': 125, 'max_depth': 6, 'learning_rate': 0.16861397813334872, 'subsample': 0.7634835291020848, 'colsample_bytree': 0.6935260304810946, 'gamma': 3.738571637021198, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:38,336] Trial 215 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 126, 'max_depth': 6, 'learning_rate': 0.16524010414234105, 'subsample': 0.7656520587852715, 'colsample_bytree': 0.6900381343980999, 'gamma': 3.7746406805638375, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:38,607] Trial 216 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 123, 'max_depth': 6, 'learning_rate': 0.1641125673608275, 'subsample': 0.7535371152092735, 'colsample_bytree': 0.7135587957780182, 'gamma': 4.033394407441413, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:38,897] Trial 217 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 131, 'max_depth': 6, 'learning_rate': 0.151765020477304, 'subsample': 0.7187653664027749, 'colsample_bytree': 0.7081875623559369, 'gamma': 3.7655875929173446, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:39,199] Trial 218 finished with value: 0.8126138040749047 and parameters: {'n_estimators': 131, 'max_depth': 6, 'learning_rate': 0.159531997478198, 'subsample': 0.7284338184821428, 'colsample_bytree': 0.7123056120941161, 'gamma': 3.8075924590203902, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:39,520] Trial 219 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 174, 'max_depth': 6, 'learning_rate': 0.151953948396129, 'subsample': 0.7231321757374585, 'colsample_bytree': 0.6810078325539176, 'gamma': 3.6787490546461643, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:39,808] Trial 220 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 134, 'max_depth': 6, 'learning_rate': 0.15935064747386532, 'subsample': 0.7155148767747653, 'colsample_bytree': 0.7225480833343892, 'gamma': 3.7632096997363105, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:40,099] Trial 221 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 128, 'max_depth': 6, 'learning_rate': 0.1453210215499463, 'subsample': 0.7464437781098794, 'colsample_bytree': 0.6930679258685916, 'gamma': 3.502248546183, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:40,390] Trial 222 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 134, 'max_depth': 6, 'learning_rate': 0.15201553697816994, 'subsample': 0.7380615532887544, 'colsample_bytree': 0.7090619294263181, 'gamma': 4.0589431342198985, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:40,691] Trial 223 finished with value: 0.814386751768156 and parameters: {'n_estimators': 128, 'max_depth': 6, 'learning_rate': 0.1805773104043728, 'subsample': 0.764701667392964, 'colsample_bytree': 0.732316018006132, 'gamma': 3.595499948285346, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:40,981] Trial 224 finished with value: 0.816169282962452 and parameters: {'n_estimators': 124, 'max_depth': 6, 'learning_rate': 0.16835758075306942, 'subsample': 0.7525958807322158, 'colsample_bytree': 0.6987817515545771, 'gamma': 3.6977870519543536, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:41,276] Trial 225 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 143, 'max_depth': 6, 'learning_rate': 0.13697621811951996, 'subsample': 0.7445737663188036, 'colsample_bytree': 0.74340606399258, 'gamma': 3.9508619100856506, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:41,633] Trial 226 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 131, 'max_depth': 6, 'learning_rate': 0.1595728203640297, 'subsample': 0.768222674574795, 'colsample_bytree': 0.7206793016010733, 'gamma': 3.488221592689013, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:41,993] Trial 227 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 137, 'max_depth': 6, 'learning_rate': 0.1419708245432259, 'subsample': 0.7571020930141421, 'colsample_bytree': 0.7524557281464475, 'gamma': 3.5963898600049475, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:42,323] Trial 228 finished with value: 0.8107737718743412 and parameters: {'n_estimators': 139, 'max_depth': 6, 'learning_rate': 0.14946402269710185, 'subsample': 0.7776216366186629, 'colsample_bytree': 0.7103026209694954, 'gamma': 3.8579726478844827, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:42,634] Trial 229 finished with value: 0.814386751768156 and parameters: {'n_estimators': 134, 'max_depth': 6, 'learning_rate': 0.16408210211500532, 'subsample': 0.735914927150498, 'colsample_bytree': 0.7374435266121028, 'gamma': 3.373360411214719, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:43,060] Trial 230 finished with value: 0.803634063596113 and parameters: {'n_estimators': 263, 'max_depth': 6, 'learning_rate': 0.14159968264204673, 'subsample': 0.7497916805968964, 'colsample_bytree': 0.6746935685581462, 'gamma': 3.540469916943262, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:43,377] Trial 231 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 139, 'max_depth': 6, 'learning_rate': 0.1769810475730316, 'subsample': 0.7604684706718992, 'colsample_bytree': 0.695170045917125, 'gamma': 3.7028516148547967, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:43,684] Trial 232 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 146, 'max_depth': 6, 'learning_rate': 0.18996641251319757, 'subsample': 0.7571155325338417, 'colsample_bytree': 0.6972761559873145, 'gamma': 3.6070533637846722, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:43,969] Trial 233 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 136, 'max_depth': 6, 'learning_rate': 0.15352001946563718, 'subsample': 0.7658090043851, 'colsample_bytree': 0.7064474569802861, 'gamma': 4.196055136358346, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:44,271] Trial 234 finished with value: 0.8143484177639776 and parameters: {'n_estimators': 141, 'max_depth': 6, 'learning_rate': 0.17310343740344336, 'subsample': 0.7441538524656734, 'colsample_bytree': 0.7281003101247016, 'gamma': 3.423779737756126, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:44,548] Trial 235 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 131, 'max_depth': 6, 'learning_rate': 0.1705355166414035, 'subsample': 0.7731481178596442, 'colsample_bytree': 0.7160593114250023, 'gamma': 3.7545591986258513, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:44,844] Trial 236 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 144, 'max_depth': 6, 'learning_rate': 0.16189929452561974, 'subsample': 0.7542670192262003, 'colsample_bytree': 0.723886779225983, 'gamma': 3.87898060559316, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:45,146] Trial 237 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 136, 'max_depth': 6, 'learning_rate': 0.13306664185873668, 'subsample': 0.7292194852228898, 'colsample_bytree': 0.6813133811194164, 'gamma': 3.289648904634534, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:45,423] Trial 238 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 126, 'max_depth': 6, 'learning_rate': 0.18191277833119934, 'subsample': 0.7614634111598297, 'colsample_bytree': 0.7147180789187308, 'gamma': 3.5900182368638047, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:45,715] Trial 239 finished with value: 0.8126042205738601 and parameters: {'n_estimators': 140, 'max_depth': 6, 'learning_rate': 0.17212352914504137, 'subsample': 0.741872259480329, 'colsample_bytree': 0.7022780441949428, 'gamma': 3.7182519118160826, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:46,156] Trial 240 finished with value: 0.7786115423686581 and parameters: {'n_estimators': 120, 'max_depth': 6, 'learning_rate': 0.12505733809801597, 'subsample': 0.749153552557967, 'colsample_bytree': 0.6877879119621104, 'gamma': 0.26521151317435177, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:46,469] Trial 241 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 134, 'max_depth': 6, 'learning_rate': 0.14446497472095057, 'subsample': 0.7714247032281323, 'colsample_bytree': 0.7456961029129955, 'gamma': 3.511627561119274, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:46,843] Trial 242 finished with value: 0.816169282962452 and parameters: {'n_estimators': 130, 'max_depth': 6, 'learning_rate': 0.1377124796646123, 'subsample': 0.7561107571699662, 'colsample_bytree': 0.7064726745259482, 'gamma': 3.253021040641999, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:47,181] Trial 243 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 135, 'max_depth': 6, 'learning_rate': 0.15783674196640127, 'subsample': 0.7401546921389989, 'colsample_bytree': 0.723631322982011, 'gamma': 3.425729471682956, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:47,499] Trial 244 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 138, 'max_depth': 6, 'learning_rate': 0.1539126146045628, 'subsample': 0.7339192220519369, 'colsample_bytree': 0.7289554737159465, 'gamma': 3.4186458655424565, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:47,806] Trial 245 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 142, 'max_depth': 6, 'learning_rate': 0.16612603445010313, 'subsample': 0.7440845866006907, 'colsample_bytree': 0.7208369288195896, 'gamma': 3.2006035211824027, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:48,109] Trial 246 finished with value: 0.817923063653614 and parameters: {'n_estimators': 133, 'max_depth': 6, 'learning_rate': 0.15909679777568328, 'subsample': 0.7366830792384321, 'colsample_bytree': 0.7374783679865847, 'gamma': 3.31261140954694, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:48,409] Trial 247 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 129, 'max_depth': 6, 'learning_rate': 0.1468517190781633, 'subsample': 0.7192582355637667, 'colsample_bytree': 0.7098444313053787, 'gamma': 3.5232651850540475, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:48,721] Trial 248 finished with value: 0.8126042205738601 and parameters: {'n_estimators': 147, 'max_depth': 6, 'learning_rate': 0.13106826278371433, 'subsample': 0.7642286012969548, 'colsample_bytree': 0.6984201525251628, 'gamma': 3.0612739116058565, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:49,025] Trial 249 finished with value: 0.8107737718743412 and parameters: {'n_estimators': 137, 'max_depth': 6, 'learning_rate': 0.15781079040773557, 'subsample': 0.7495854074425291, 'colsample_bytree': 0.6615841711178618, 'gamma': 3.609976753628778, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:49,327] Trial 250 finished with value: 0.8054740957966765 and parameters: {'n_estimators': 142, 'max_depth': 6, 'learning_rate': 0.17656404227371061, 'subsample': 0.7560170877598533, 'colsample_bytree': 0.7170343831890517, 'gamma': 3.4138194769047288, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:49,831] Trial 251 finished with value: 0.8054261782914535 and parameters: {'n_estimators': 134, 'max_depth': 6, 'learning_rate': 0.1488679796561471, 'subsample': 0.7282813252216809, 'colsample_bytree': 0.7257103808668243, 'gamma': 3.7930433144804194, 'min_child_weight': 5}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:50,445] Trial 252 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 182, 'max_depth': 6, 'learning_rate': 0.13873315135344522, 'subsample': 0.7781987206942601, 'colsample_bytree': 0.7364010129552852, 'gamma': 3.3152535144265065, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:50,801] Trial 253 finished with value: 0.8125563030686371 and parameters: {'n_estimators': 125, 'max_depth': 6, 'learning_rate': 0.16883525550490674, 'subsample': 0.7080159816646525, 'colsample_bytree': 0.70785033867523, 'gamma': 3.146130166741429, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:51,183] Trial 254 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 139, 'max_depth': 6, 'learning_rate': 0.12799182446964044, 'subsample': 0.7403278689877391, 'colsample_bytree': 0.7295636735300037, 'gamma': 3.6541669998154886, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:52,707] Trial 255 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 130, 'max_depth': 5, 'learning_rate': 0.12506500125942735, 'subsample': 0.7408442831441368, 'colsample_bytree': 0.7306413961417119, 'gamma': 3.9114148147558536, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:53,207] Trial 256 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 166, 'max_depth': 5, 'learning_rate': 0.12671257069152495, 'subsample': 0.7383605764246757, 'colsample_bytree': 0.7457578918191221, 'gamma': 3.8451040593802666, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:53,678] Trial 257 finished with value: 0.8107737718743412 and parameters: {'n_estimators': 130, 'max_depth': 5, 'learning_rate': 0.12389717163174345, 'subsample': 0.7315770833174146, 'colsample_bytree': 0.7314687078155797, 'gamma': 3.8867896762236493, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:54,105] Trial 258 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 144, 'max_depth': 6, 'learning_rate': 0.1314843659864647, 'subsample': 0.7441385802586037, 'colsample_bytree': 0.7243986305750227, 'gamma': 3.706254327490858, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:54,514] Trial 259 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.12059216864815539, 'subsample': 0.724143008607416, 'colsample_bytree': 0.73192082375523, 'gamma': 4.292203307465855, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:54,982] Trial 260 finished with value: 0.8072087094857494 and parameters: {'n_estimators': 135, 'max_depth': 4, 'learning_rate': 0.13485314689249456, 'subsample': 0.7392534248441011, 'colsample_bytree': 0.7614883953219, 'gamma': 3.9297039373725515, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:55,785] Trial 261 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 208, 'max_depth': 5, 'learning_rate': 0.11890056225221939, 'subsample': 0.7486761538778156, 'colsample_bytree': 0.7415397422288322, 'gamma': 3.7729594037148626, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:56,162] Trial 262 finished with value: 0.8054261782914535 and parameters: {'n_estimators': 148, 'max_depth': 6, 'learning_rate': 0.2996597533080084, 'subsample': 0.7332997735136304, 'colsample_bytree': 0.7173310656788958, 'gamma': 2.449803917901244, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:56,529] Trial 263 finished with value: 0.800049834205432 and parameters: {'n_estimators': 194, 'max_depth': 6, 'learning_rate': 0.14153157821717677, 'subsample': 0.7490010694820707, 'colsample_bytree': 0.7525767031255024, 'gamma': 4.043537198870881, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:56,977] Trial 264 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 139, 'max_depth': 6, 'learning_rate': 0.12395914674513715, 'subsample': 0.7383647928174133, 'colsample_bytree': 0.725032348586993, 'gamma': 3.661963684344753, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:57,558] Trial 265 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 132, 'max_depth': 6, 'learning_rate': 0.13054984921416418, 'subsample': 0.7172862523646995, 'colsample_bytree': 0.7312441242067188, 'gamma': 1.6833841830715688, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:57,966] Trial 266 finished with value: 0.8054070112893643 and parameters: {'n_estimators': 109, 'max_depth': 6, 'learning_rate': 0.14968295302423582, 'subsample': 0.7518547136676177, 'colsample_bytree': 0.7719216146518119, 'gamma': 3.4723772210431383, 'min_child_weight': 6}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:58,606] Trial 267 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 224, 'max_depth': 6, 'learning_rate': 0.11217888086676274, 'subsample': 0.7278383986070774, 'colsample_bytree': 0.7164806754897087, 'gamma': 1.8211208146655875, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:58,920] Trial 268 finished with value: 0.8072470434899278 and parameters: {'n_estimators': 140, 'max_depth': 6, 'learning_rate': 0.13487647076318834, 'subsample': 0.6947337113580209, 'colsample_bytree': 0.7370341392511763, 'gamma': 2.975119533413729, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:59,203] Trial 269 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 122, 'max_depth': 6, 'learning_rate': 0.11828810586287627, 'subsample': 0.7433213764335584, 'colsample_bytree': 0.7118549659835001, 'gamma': 3.525816614126021, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:59,482] Trial 270 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 114, 'max_depth': 6, 'learning_rate': 0.11876707132584365, 'subsample': 0.7457894083839461, 'colsample_bytree': 0.7195188060995606, 'gamma': 3.5345500692980814, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:48:59,760] Trial 271 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 121, 'max_depth': 6, 'learning_rate': 0.10791457989830641, 'subsample': 0.7402377802923695, 'colsample_bytree': 0.7096945835699058, 'gamma': 3.3803825753144268, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:48:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:00,067] Trial 272 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 136, 'max_depth': 6, 'learning_rate': 0.12728227036796375, 'subsample': 0.7324469908928943, 'colsample_bytree': 0.725568459491025, 'gamma': 2.364957658463054, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:00,365] Trial 273 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 130, 'max_depth': 5, 'learning_rate': 0.12177875830234806, 'subsample': 0.7529882526107105, 'colsample_bytree': 0.7130334489844586, 'gamma': 3.0425674832209744, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:00,886] Trial 274 finished with value: 0.8072087094857494 and parameters: {'n_estimators': 103, 'max_depth': 6, 'learning_rate': 0.11374501376291345, 'subsample': 0.7414070620518535, 'colsample_bytree': 0.7413209124416327, 'gamma': 3.5853965048136716, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:01,196] Trial 275 finished with value: 0.8036532305982022 and parameters: {'n_estimators': 143, 'max_depth': 6, 'learning_rate': 0.1399625277126049, 'subsample': 0.9446552367161243, 'colsample_bytree': 0.7309616014342213, 'gamma': 3.439952055133231, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:01,587] Trial 276 finished with value: 0.8000594177064766 and parameters: {'n_estimators': 151, 'max_depth': 6, 'learning_rate': 0.018373810688256775, 'subsample': 0.7239703067425683, 'colsample_bytree': 0.7491678100017208, 'gamma': 3.3503581388879327, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:01,900] Trial 277 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 134, 'max_depth': 6, 'learning_rate': 0.12898350283237217, 'subsample': 0.7432522337384023, 'colsample_bytree': 0.7217018123953524, 'gamma': 3.235057040512118, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:02,276] Trial 278 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 139, 'max_depth': 6, 'learning_rate': 0.10518789114291309, 'subsample': 0.7695362521076995, 'colsample_bytree': 0.706534255899278, 'gamma': 2.891537057435039, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:02,731] Trial 279 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 146, 'max_depth': 6, 'learning_rate': 0.117614080157686, 'subsample': 0.7547350779934118, 'colsample_bytree': 0.71628774227845, 'gamma': 3.1101676089734163, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:03,169] Trial 280 finished with value: 0.8072087094857494 and parameters: {'n_estimators': 127, 'max_depth': 6, 'learning_rate': 0.15422319019402614, 'subsample': 0.7357385223628975, 'colsample_bytree': 0.9818064140489995, 'gamma': 3.5302979592459325, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:03,485] Trial 281 finished with value: 0.8143292507618884 and parameters: {'n_estimators': 131, 'max_depth': 4, 'learning_rate': 0.14382732276735827, 'subsample': 0.748501904542158, 'colsample_bytree': 0.7312586140647042, 'gamma': 2.580955681868207, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:03,780] Trial 282 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 118, 'max_depth': 6, 'learning_rate': 0.13677689280629104, 'subsample': 0.7613914394533666, 'colsample_bytree': 0.7008589061420788, 'gamma': 1.9799698056292834, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:04,092] Trial 283 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 136, 'max_depth': 6, 'learning_rate': 0.12361237646054665, 'subsample': 0.779027633570564, 'colsample_bytree': 0.7418707761745412, 'gamma': 3.7050792362778475, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:04,455] Trial 284 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 234, 'max_depth': 6, 'learning_rate': 0.11169670889945539, 'subsample': 0.7441876505842793, 'colsample_bytree': 0.8314151020814871, 'gamma': 3.9517624600458165, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:04,767] Trial 285 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 142, 'max_depth': 6, 'learning_rate': 0.1474559408443839, 'subsample': 0.731793965777466, 'colsample_bytree': 0.7572779292226809, 'gamma': 3.194294517751608, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:05,074] Trial 286 finished with value: 0.796465604814751 and parameters: {'n_estimators': 133, 'max_depth': 6, 'learning_rate': 0.12947968478776378, 'subsample': 0.7556712726376233, 'colsample_bytree': 0.725025768906119, 'gamma': 1.5977849910835353, 'min_child_weight': 10}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:05,385] Trial 287 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 172, 'max_depth': 6, 'learning_rate': 0.11693847520548074, 'subsample': 0.7702955448264518, 'colsample_bytree': 0.7102019859736551, 'gamma': 3.307397350743745, 'min_child_weight': 5}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:05,681] Trial 288 finished with value: 0.810802522377475 and parameters: {'n_estimators': 123, 'max_depth': 6, 'learning_rate': 0.10798151721808912, 'subsample': 0.7160543525722239, 'colsample_bytree': 0.7367047999341217, 'gamma': 3.639076080757894, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:06,133] Trial 289 finished with value: 0.789345063538612 and parameters: {'n_estimators': 139, 'max_depth': 6, 'learning_rate': 0.10065394950028124, 'subsample': 0.7260496122480907, 'colsample_bytree': 0.7210314516112506, 'gamma': 3.8157100593493425, 'min_child_weight': 9}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:06,420] Trial 290 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 128, 'max_depth': 5, 'learning_rate': 0.1550104551654852, 'subsample': 0.749561134653411, 'colsample_bytree': 0.7123025233853518, 'gamma': 3.4657702707117055, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:06,712] Trial 291 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 126, 'max_depth': 6, 'learning_rate': 0.15369625101745585, 'subsample': 0.7622508432033829, 'colsample_bytree': 0.8493535457412484, 'gamma': 3.4899312693230247, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:07,114] Trial 292 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 129, 'max_depth': 5, 'learning_rate': 0.15980173354268232, 'subsample': 0.7518773036924257, 'colsample_bytree': 0.7304905203233502, 'gamma': 3.3196351253241114, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:07,461] Trial 293 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 118, 'max_depth': 5, 'learning_rate': 0.14430219813911094, 'subsample': 0.7852756716650496, 'colsample_bytree': 0.9922376138679794, 'gamma': 3.42142396072881, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:07,830] Trial 294 finished with value: 0.821507293044295 and parameters: {'n_estimators': 121, 'max_depth': 5, 'learning_rate': 0.13675838989642, 'subsample': 0.7580360413860636, 'colsample_bytree': 0.7445245429827771, 'gamma': 3.0479434403971797, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:08,130] Trial 295 finished with value: 0.8054261782914535 and parameters: {'n_estimators': 111, 'max_depth': 5, 'learning_rate': 0.1387405889799696, 'subsample': 0.7686352917511838, 'colsample_bytree': 0.7485274886852822, 'gamma': 3.0840744619476683, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:08,428] Trial 296 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 122, 'max_depth': 5, 'learning_rate': 0.13378617756877612, 'subsample': 0.7587093989352347, 'colsample_bytree': 0.7183425331225883, 'gamma': 3.0005812223297483, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:08,722] Trial 297 finished with value: 0.8054261782914535 and parameters: {'n_estimators': 122, 'max_depth': 5, 'learning_rate': 0.14858192055465572, 'subsample': 0.7764332257848197, 'colsample_bytree': 0.7665158156051414, 'gamma': 3.1778261746649505, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:09,026] Trial 298 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 127, 'max_depth': 5, 'learning_rate': 0.1410615911501252, 'subsample': 0.7629239696582114, 'colsample_bytree': 0.697588922344855, 'gamma': 3.4537516419908907, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:09,298] Trial 299 finished with value: 0.8143484177639776 and parameters: {'n_estimators': 118, 'max_depth': 5, 'learning_rate': 0.1269267503807219, 'subsample': 0.7513634154216168, 'colsample_bytree': 0.7125605438765282, 'gamma': 3.2481066942100716, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:09,582] Trial 300 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.1335393232297162, 'subsample': 0.7477985727885148, 'colsample_bytree': 0.725995076369108, 'gamma': 2.9221602493149472, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:09,854] Trial 301 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.15322881358646287, 'subsample': 0.7673042729965557, 'colsample_bytree': 0.8544199436301356, 'gamma': 3.5436191091312716, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:10,136] Trial 302 finished with value: 0.8179518141567478 and parameters: {'n_estimators': 132, 'max_depth': 5, 'learning_rate': 0.14571399632648285, 'subsample': 0.7576031550241812, 'colsample_bytree': 0.7452487442107636, 'gamma': 3.104915737622684, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:10,449] Trial 303 finished with value: 0.7965039388189293 and parameters: {'n_estimators': 128, 'max_depth': 5, 'learning_rate': 0.12226364816952283, 'subsample': 0.7362363563351615, 'colsample_bytree': 0.8267187574518854, 'gamma': 1.753888037455729, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:10,745] Trial 304 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 135, 'max_depth': 5, 'learning_rate': 0.13682271316627684, 'subsample': 0.7465197749441529, 'colsample_bytree': 0.8853671724520864, 'gamma': 3.364407638138302, 'min_child_weight': 5}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:11,026] Trial 305 finished with value: 0.8018515324018171 and parameters: {'n_estimators': 125, 'max_depth': 4, 'learning_rate': 0.15999077690998886, 'subsample': 0.7754162929235605, 'colsample_bytree': 0.8407680317802243, 'gamma': 3.588586801203954, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:11,498] Trial 306 finished with value: 0.807218292986794 and parameters: {'n_estimators': 274, 'max_depth': 7, 'learning_rate': 0.13020312100321943, 'subsample': 0.7552600696684806, 'colsample_bytree': 0.7376167472216664, 'gamma': 3.040122699098114, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:11,905] Trial 307 finished with value: 0.8143388342629329 and parameters: {'n_estimators': 131, 'max_depth': 5, 'learning_rate': 0.15013578737274, 'subsample': 0.7663025778016466, 'colsample_bytree': 0.7181303471027112, 'gamma': 3.2891282038629734, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:12,499] Trial 308 finished with value: 0.8054261782914535 and parameters: {'n_estimators': 246, 'max_depth': 6, 'learning_rate': 0.12453194952407615, 'subsample': 0.739007632675165, 'colsample_bytree': 0.728578240343435, 'gamma': 3.4398738378907656, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:13,024] Trial 309 finished with value: 0.8072374599888832 and parameters: {'n_estimators': 144, 'max_depth': 6, 'learning_rate': 0.14211756006077272, 'subsample': 0.7816586761470408, 'colsample_bytree': 0.709757202070924, 'gamma': 3.627072809824385, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:13,867] Trial 310 finished with value: 0.8197151783489546 and parameters: {'n_estimators': 136, 'max_depth': 6, 'learning_rate': 0.15659742513318786, 'subsample': 0.7544880896494405, 'colsample_bytree': 0.779751686918175, 'gamma': 3.139488778531477, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:14,308] Trial 311 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 137, 'max_depth': 6, 'learning_rate': 0.15598855064430536, 'subsample': 0.7527746393153426, 'colsample_bytree': 0.7035298699378911, 'gamma': 3.1386367654014187, 'min_child_weight': 7}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:14,615] Trial 312 finished with value: 0.810754604872252 and parameters: {'n_estimators': 113, 'max_depth': 6, 'learning_rate': 0.16171874666943167, 'subsample': 0.7458081988189618, 'colsample_bytree': 0.7960924345911184, 'gamma': 3.2183319157095887, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:14,949] Trial 313 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 142, 'max_depth': 7, 'learning_rate': 0.16360636281578564, 'subsample': 0.7308501901142055, 'colsample_bytree': 0.7897214514273856, 'gamma': 2.973086276147179, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:15,292] Trial 314 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 122, 'max_depth': 6, 'learning_rate': 0.15519897896180035, 'subsample': 0.7585373942804453, 'colsample_bytree': 0.7698527294457145, 'gamma': 1.8650712588984444, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:16,136] Trial 315 finished with value: 0.8107737718743412 and parameters: {'n_estimators': 146, 'max_depth': 5, 'learning_rate': 0.1477980460711179, 'subsample': 0.7434479053299378, 'colsample_bytree': 0.7586681963821018, 'gamma': 2.1564686912544078, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:16,472] Trial 316 finished with value: 0.8107737718743412 and parameters: {'n_estimators': 137, 'max_depth': 6, 'learning_rate': 0.13905632182407493, 'subsample': 0.7514956605941231, 'colsample_bytree': 0.7518394316092749, 'gamma': 3.354908392160885, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:16,808] Trial 317 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 130, 'max_depth': 6, 'learning_rate': 0.133141441809177, 'subsample': 0.7384912800984775, 'colsample_bytree': 0.7820558650065155, 'gamma': 3.150691335023506, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:17,190] Trial 318 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 134, 'max_depth': 6, 'learning_rate': 0.1513692814858974, 'subsample': 0.7600886686269802, 'colsample_bytree': 0.7735448587214668, 'gamma': 3.685162428307784, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:17,561] Trial 319 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 105, 'max_depth': 6, 'learning_rate': 0.14619909735366035, 'subsample': 0.7626318442636607, 'colsample_bytree': 0.7425826778479152, 'gamma': 3.730335506352571, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:18,076] Trial 320 finished with value: 0.8018419489007725 and parameters: {'n_estimators': 128, 'max_depth': 6, 'learning_rate': 0.13765212325512938, 'subsample': 0.845859669358159, 'colsample_bytree': 0.9679997861423146, 'gamma': 3.5819319018764504, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:18,446] Trial 321 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 141, 'max_depth': 7, 'learning_rate': 0.12790585815015085, 'subsample': 0.7476886119508251, 'colsample_bytree': 0.9840474937214084, 'gamma': 3.6792192389306346, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:18,782] Trial 322 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 133, 'max_depth': 8, 'learning_rate': 0.1506546574759762, 'subsample': 0.7249580568558827, 'colsample_bytree': 0.6873051237909094, 'gamma': 3.5098199222688593, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:19,131] Trial 323 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 117, 'max_depth': 6, 'learning_rate': 0.11853053426229257, 'subsample': 0.7092594886107579, 'colsample_bytree': 0.7230922287679069, 'gamma': 3.6501555059554107, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:19,433] Trial 324 finished with value: 0.8233185747417248 and parameters: {'n_estimators': 123, 'max_depth': 5, 'learning_rate': 0.14283200899415913, 'subsample': 0.7620986553091845, 'colsample_bytree': 0.7346997551131462, 'gamma': 3.4472302995753137, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:19,865] Trial 325 finished with value: 0.816169282962452 and parameters: {'n_estimators': 259, 'max_depth': 5, 'learning_rate': 0.1438047690787723, 'subsample': 0.7605269809627719, 'colsample_bytree': 0.737834189778764, 'gamma': 3.7699840590659255, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:20,238] Trial 326 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 125, 'max_depth': 5, 'learning_rate': 0.15344235680273127, 'subsample': 0.7337182241074047, 'colsample_bytree': 0.7325986809941581, 'gamma': 4.720257178783675, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:20,581] Trial 327 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 124, 'max_depth': 5, 'learning_rate': 0.14323270770014013, 'subsample': 0.742767143261266, 'colsample_bytree': 0.762036452336403, 'gamma': 3.4301055579096684, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:20,985] Trial 328 finished with value: 0.7911467617349971 and parameters: {'n_estimators': 148, 'max_depth': 5, 'learning_rate': 0.1629220346852667, 'subsample': 0.9154264918436202, 'colsample_bytree': 0.7460901180628317, 'gamma': 3.4977916218963045, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:21,348] Trial 329 finished with value: 0.8126042205738601 and parameters: {'n_estimators': 130, 'max_depth': 5, 'learning_rate': 0.13233891462596284, 'subsample': 0.7673657425756057, 'colsample_bytree': 0.7155195157840918, 'gamma': 3.3615048710787874, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:21,850] Trial 330 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 293, 'max_depth': 5, 'learning_rate': 0.10373753545384137, 'subsample': 0.7524759252284428, 'colsample_bytree': 0.7248255223231228, 'gamma': 3.559878953349394, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:22,177] Trial 331 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 120, 'max_depth': 6, 'learning_rate': 0.12233090183210817, 'subsample': 0.7603153842044424, 'colsample_bytree': 0.7321334118600731, 'gamma': 3.2621806419313426, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:22,572] Trial 332 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 119, 'max_depth': 3, 'learning_rate': 0.12730332686358342, 'subsample': 0.7473865489137106, 'colsample_bytree': 0.7326535279921622, 'gamma': 3.2589799797350136, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:22,938] Trial 333 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 120, 'max_depth': 4, 'learning_rate': 0.12344633106441139, 'subsample': 0.7383826503189238, 'colsample_bytree': 0.7341711308926954, 'gamma': 3.3162217488379406, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:23,275] Trial 334 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 119, 'max_depth': 9, 'learning_rate': 0.12786785567816722, 'subsample': 0.7460550183545038, 'colsample_bytree': 0.7306617232700069, 'gamma': 3.237969195556197, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:23,604] Trial 335 finished with value: 0.8197151783489546 and parameters: {'n_estimators': 117, 'max_depth': 10, 'learning_rate': 0.1275759009861152, 'subsample': 0.7488785943062756, 'colsample_bytree': 0.739809491383264, 'gamma': 3.1890343027449566, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:23,932] Trial 336 finished with value: 0.8054453452935427 and parameters: {'n_estimators': 120, 'max_depth': 9, 'learning_rate': 0.11970259886858635, 'subsample': 0.8348433566429828, 'colsample_bytree': 0.7314372728979112, 'gamma': 3.2109248159294723, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:24,275] Trial 337 finished with value: 0.8107737718743412 and parameters: {'n_estimators': 120, 'max_depth': 3, 'learning_rate': 0.13197499435890445, 'subsample': 0.7467034946595426, 'colsample_bytree': 0.7518695595299443, 'gamma': 3.2751813393588614, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:24,572] Trial 338 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 115, 'max_depth': 9, 'learning_rate': 0.12495703369092975, 'subsample': 0.7304899482884253, 'colsample_bytree': 0.7426085482746179, 'gamma': 3.307975550995154, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:24,893] Trial 339 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 121, 'max_depth': 9, 'learning_rate': 0.13628361047328477, 'subsample': 0.7546404774897518, 'colsample_bytree': 0.7317611033941958, 'gamma': 3.2571433443995184, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:25,200] Trial 340 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 113, 'max_depth': 9, 'learning_rate': 0.12964052409938537, 'subsample': 0.7201485106163876, 'colsample_bytree': 0.7320208375435632, 'gamma': 3.067922099383998, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:25,501] Trial 341 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 123, 'max_depth': 4, 'learning_rate': 0.1388217155082939, 'subsample': 0.7535718184005171, 'colsample_bytree': 0.723486434496253, 'gamma': 3.243679621797299, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:25,796] Trial 342 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 118, 'max_depth': 3, 'learning_rate': 0.13461779402356133, 'subsample': 0.7441656996185686, 'colsample_bytree': 0.7361582397126532, 'gamma': 3.364358418514159, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:26,098] Trial 343 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 121, 'max_depth': 9, 'learning_rate': 0.11711212776899513, 'subsample': 0.7354920859885434, 'colsample_bytree': 0.7456267976718379, 'gamma': 3.2425009823433233, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:26,407] Trial 344 finished with value: 0.810802522377475 and parameters: {'n_estimators': 116, 'max_depth': 9, 'learning_rate': 0.13499498736899976, 'subsample': 0.7687779931423944, 'colsample_bytree': 0.8721875665899465, 'gamma': 3.0379768735322137, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:26,783] Trial 345 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 213, 'max_depth': 9, 'learning_rate': 0.12293844036930333, 'subsample': 0.7550318622704207, 'colsample_bytree': 0.7268089573571316, 'gamma': 3.1266001295390575, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:27,096] Trial 346 finished with value: 0.8197439288520884 and parameters: {'n_estimators': 124, 'max_depth': 10, 'learning_rate': 0.11229242294710225, 'subsample': 0.7463242277684764, 'colsample_bytree': 0.719386382200524, 'gamma': 3.254243053950661, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:27,470] Trial 347 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 123, 'max_depth': 10, 'learning_rate': 0.10951161437945825, 'subsample': 0.7267912366291079, 'colsample_bytree': 0.733584358235413, 'gamma': 3.222407962606002, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:28,212] Trial 348 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 111, 'max_depth': 10, 'learning_rate': 0.11688914834433645, 'subsample': 0.7418246145963233, 'colsample_bytree': 0.7146258827477475, 'gamma': 3.084339040228388, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:28,601] Trial 349 finished with value: 0.8000402507043874 and parameters: {'n_estimators': 124, 'max_depth': 10, 'learning_rate': 0.10851605625122682, 'subsample': 0.7483670000962465, 'colsample_bytree': 0.7408361185319595, 'gamma': 2.9001888440820363, 'min_child_weight': 8}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:29,139] Trial 350 finished with value: 0.8089912406800454 and parameters: {'n_estimators': 119, 'max_depth': 10, 'learning_rate': 0.09738575388073639, 'subsample': 0.7307915554892952, 'colsample_bytree': 0.726742332047862, 'gamma': 3.306421003913807, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:29,570] Trial 351 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 126, 'max_depth': 10, 'learning_rate': 0.11410369062138842, 'subsample': 0.6761445146146629, 'colsample_bytree': 0.7509738249451444, 'gamma': 3.149205695458474, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:30,077] Trial 352 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 113, 'max_depth': 8, 'learning_rate': 0.12237453107404873, 'subsample': 0.7365192595962982, 'colsample_bytree': 0.7213056896029278, 'gamma': 2.990181951828554, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:30,819] Trial 353 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 120, 'max_depth': 9, 'learning_rate': 0.10488208136106968, 'subsample': 0.7622004072976167, 'colsample_bytree': 0.7101109754565849, 'gamma': 3.251985243276398, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:31,554] Trial 354 finished with value: 0.8214977095432504 and parameters: {'n_estimators': 126, 'max_depth': 8, 'learning_rate': 0.127099030438717, 'subsample': 0.7453105078268462, 'colsample_bytree': 0.735672094799387, 'gamma': 3.4043396300463433, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:32,291] Trial 355 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 126, 'max_depth': 8, 'learning_rate': 0.12766019499342635, 'subsample': 0.7560615971356934, 'colsample_bytree': 0.7305054439273628, 'gamma': 3.3928920625288077, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:33,562] Trial 356 finished with value: 0.8179518141567478 and parameters: {'n_estimators': 279, 'max_depth': 9, 'learning_rate': 0.11393116587079491, 'subsample': 0.7438323086290772, 'colsample_bytree': 0.718308737973282, 'gamma': 3.520921909943416, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:34,367] Trial 357 finished with value: 0.814386751768156 and parameters: {'n_estimators': 116, 'max_depth': 8, 'learning_rate': 0.12104137802007162, 'subsample': 0.6902804411996406, 'colsample_bytree': 0.75658311576002, 'gamma': 3.345193085754446, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:34,729] Trial 358 finished with value: 0.8161309489582735 and parameters: {'n_estimators': 122, 'max_depth': 4, 'learning_rate': 0.1261499634135719, 'subsample': 0.7479771398265848, 'colsample_bytree': 0.742856069862049, 'gamma': 3.4893708156680656, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:35,280] Trial 359 finished with value: 0.805416594790409 and parameters: {'n_estimators': 128, 'max_depth': 8, 'learning_rate': 0.11623545757197815, 'subsample': 0.7697435658767496, 'colsample_bytree': 0.7277165097437714, 'gamma': 3.959509639273706, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:35,618] Trial 360 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 124, 'max_depth': 3, 'learning_rate': 0.11020708873595775, 'subsample': 0.7603265253961383, 'colsample_bytree': 0.7141542530631014, 'gamma': 3.414470203449603, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:35,963] Trial 361 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 119, 'max_depth': 9, 'learning_rate': 0.12081066855381813, 'subsample': 0.7371192864771606, 'colsample_bytree': 0.7351219328486658, 'gamma': 3.820993468869531, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:36,309] Trial 362 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 127, 'max_depth': 8, 'learning_rate': 0.1038554630893853, 'subsample': 0.7203593845005417, 'colsample_bytree': 0.7043292404821545, 'gamma': 3.5796279712587977, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:36,647] Trial 363 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 115, 'max_depth': 10, 'learning_rate': 0.1285228059032036, 'subsample': 0.7497387239422018, 'colsample_bytree': 0.7202719026443565, 'gamma': 4.168689075956003, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:37,002] Trial 364 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 122, 'max_depth': 9, 'learning_rate': 0.09440150418736559, 'subsample': 0.7623607536506924, 'colsample_bytree': 0.7472153942365695, 'gamma': 3.288977115073822, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:37,324] Trial 365 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 110, 'max_depth': 8, 'learning_rate': 0.13127982953811668, 'subsample': 0.7131787873756809, 'colsample_bytree': 0.7383162136538564, 'gamma': 2.839051452020555, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:37,738] Trial 366 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 111, 'max_depth': 8, 'learning_rate': 0.1335990449226669, 'subsample': 0.7035099110621209, 'colsample_bytree': 0.7363142285091479, 'gamma': 2.790370009762153, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:38,124] Trial 367 finished with value: 0.807218292986794 and parameters: {'n_estimators': 108, 'max_depth': 8, 'learning_rate': 0.12737651864819222, 'subsample': 0.7096360904906723, 'colsample_bytree': 0.8926523397776438, 'gamma': 2.9883631928178316, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:38,657] Trial 368 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 113, 'max_depth': 8, 'learning_rate': 0.13759835056860253, 'subsample': 0.7222876176265174, 'colsample_bytree': 0.6276109690713554, 'gamma': 2.8716764654841733, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:39,009] Trial 369 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 107, 'max_depth': 8, 'learning_rate': 0.13056008986396794, 'subsample': 0.7123959700744592, 'colsample_bytree': 0.7287584674377903, 'gamma': 2.295675325860687, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:39,371] Trial 370 finished with value: 0.814386751768156 and parameters: {'n_estimators': 117, 'max_depth': 8, 'learning_rate': 0.12362344693353647, 'subsample': 0.7726105151348742, 'colsample_bytree': 0.7117309707575937, 'gamma': 2.9002808122758967, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:39,698] Trial 371 finished with value: 0.814386751768156 and parameters: {'n_estimators': 127, 'max_depth': 8, 'learning_rate': 0.14084240504355347, 'subsample': 0.7544207581674249, 'colsample_bytree': 0.6026264441630337, 'gamma': 3.7132384346659317, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:40,032] Trial 372 finished with value: 0.8072566269909723 and parameters: {'n_estimators': 122, 'max_depth': 8, 'learning_rate': 0.1336429877444509, 'subsample': 0.6968104909347237, 'colsample_bytree': 0.6473926202868091, 'gamma': 3.06127382036853, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:40,332] Trial 373 finished with value: 0.8072374599888832 and parameters: {'n_estimators': 116, 'max_depth': 4, 'learning_rate': 0.12024354683975427, 'subsample': 0.8904802475711946, 'colsample_bytree': 0.7223754827372357, 'gamma': 2.8153880040198973, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:40,668] Trial 374 finished with value: 0.8089912406800454 and parameters: {'n_estimators': 129, 'max_depth': 3, 'learning_rate': 0.12903960535897738, 'subsample': 0.7296066837248248, 'colsample_bytree': 0.7398804639045743, 'gamma': 3.527146391902316, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:40,997] Trial 375 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 124, 'max_depth': 9, 'learning_rate': 0.13794103183071085, 'subsample': 0.7647942693370464, 'colsample_bytree': 0.7049102515418086, 'gamma': 3.6364063289547737, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:41,350] Trial 376 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 120, 'max_depth': 8, 'learning_rate': 0.12448755450329095, 'subsample': 0.7134216024679287, 'colsample_bytree': 0.7320395714028877, 'gamma': 3.848766690964699, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:41,698] Trial 377 finished with value: 0.8089816571790007 and parameters: {'n_estimators': 129, 'max_depth': 10, 'learning_rate': 0.14371282384736372, 'subsample': 0.748553932946559, 'colsample_bytree': 0.7165796962903405, 'gamma': 3.376087533680624, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:42,030] Trial 378 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 125, 'max_depth': 5, 'learning_rate': 0.1166371261557048, 'subsample': 0.7563722032614135, 'colsample_bytree': 0.8595084179311079, 'gamma': 3.2563279005357377, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:42,353] Trial 379 finished with value: 0.8107737718743412 and parameters: {'n_estimators': 114, 'max_depth': 8, 'learning_rate': 0.1353532523374878, 'subsample': 0.7384709393281277, 'colsample_bytree': 0.7262726119953159, 'gamma': 3.465007913985148, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:42,750] Trial 380 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 102, 'max_depth': 7, 'learning_rate': 0.1285046293540853, 'subsample': 0.7485904089534193, 'colsample_bytree': 0.7466089093948988, 'gamma': 2.9643487711998278, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:43,225] Trial 381 finished with value: 0.8143484177639776 and parameters: {'n_estimators': 131, 'max_depth': 9, 'learning_rate': 0.11328086817371333, 'subsample': 0.7734325894578477, 'colsample_bytree': 0.6977338032903492, 'gamma': 3.13099082187601, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:43,608] Trial 382 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 119, 'max_depth': 7, 'learning_rate': 0.12191384200611713, 'subsample': 0.7306218587614162, 'colsample_bytree': 0.7402004934443768, 'gamma': 4.0335439445767065, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:44,146] Trial 383 finished with value: 0.8233089912406801 and parameters: {'n_estimators': 126, 'max_depth': 9, 'learning_rate': 0.14492863137937878, 'subsample': 0.758927484000205, 'colsample_bytree': 0.7119627790853806, 'gamma': 3.1836955429683025, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:44,489] Trial 384 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 125, 'max_depth': 9, 'learning_rate': 0.14504533101380984, 'subsample': 0.7653548374581197, 'colsample_bytree': 0.7136664403924081, 'gamma': 3.073984207748318, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:44,878] Trial 385 finished with value: 0.7929580434324267 and parameters: {'n_estimators': 110, 'max_depth': 9, 'learning_rate': 0.14124167783438996, 'subsample': 0.8558542123889231, 'colsample_bytree': 0.6937329495037975, 'gamma': 0.9293003292830415, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:45,328] Trial 386 finished with value: 0.7875816993464052 and parameters: {'n_estimators': 121, 'max_depth': 9, 'learning_rate': 0.14771519935432817, 'subsample': 0.822934310538039, 'colsample_bytree': 0.7080935757472491, 'gamma': 0.5105938041064935, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:45,654] Trial 387 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 128, 'max_depth': 9, 'learning_rate': 0.13678327123891493, 'subsample': 0.7591385041829424, 'colsample_bytree': 0.7243142702504595, 'gamma': 3.185673639856179, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:45,980] Trial 388 finished with value: 0.816169282962452 and parameters: {'n_estimators': 118, 'max_depth': 9, 'learning_rate': 0.1322745158926345, 'subsample': 0.7722821970789032, 'colsample_bytree': 0.8799927302115809, 'gamma': 2.9842283013034745, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:46,312] Trial 389 finished with value: 0.8233089912406801 and parameters: {'n_estimators': 124, 'max_depth': 10, 'learning_rate': 0.14066110000787982, 'subsample': 0.7551548851928946, 'colsample_bytree': 0.7184673948136827, 'gamma': 3.1967375576910024, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:46,672] Trial 390 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 128, 'max_depth': 10, 'learning_rate': 0.144109390299148, 'subsample': 0.7649967893926973, 'colsample_bytree': 0.7034279994069548, 'gamma': 3.0835585387773565, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:47,192] Trial 391 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 124, 'max_depth': 10, 'learning_rate': 0.14913830052600716, 'subsample': 0.757575491059038, 'colsample_bytree': 0.7172728519960463, 'gamma': 2.737866710518233, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:47,541] Trial 392 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 132, 'max_depth': 10, 'learning_rate': 0.13973807224691157, 'subsample': 0.7545678684490729, 'colsample_bytree': 0.7103120907810048, 'gamma': 3.7387322575682402, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:47,916] Trial 393 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 130, 'max_depth': 10, 'learning_rate': 0.1436490279238828, 'subsample': 0.7790245303710492, 'colsample_bytree': 0.721666741111715, 'gamma': 3.1261525393900933, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:48,321] Trial 394 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 124, 'max_depth': 10, 'learning_rate': 0.1343197950260907, 'subsample': 0.7666631905549034, 'colsample_bytree': 0.7009924871496473, 'gamma': 3.330398108003154, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:48,776] Trial 395 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 127, 'max_depth': 10, 'learning_rate': 0.14851674118914307, 'subsample': 0.7535348315012945, 'colsample_bytree': 0.9997878825004163, 'gamma': 2.95836001787465, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:49,783] Trial 396 finished with value: 0.8161405324593182 and parameters: {'n_estimators': 131, 'max_depth': 10, 'learning_rate': 0.15617309326918227, 'subsample': 0.7431865033811396, 'colsample_bytree': 0.7176408482989854, 'gamma': 3.910093354353832, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:50,288] Trial 397 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 122, 'max_depth': 5, 'learning_rate': 0.1384233790561632, 'subsample': 0.7616571831249913, 'colsample_bytree': 0.709675064151873, 'gamma': 3.189190971506637, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:51,041] Trial 398 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 114, 'max_depth': 10, 'learning_rate': 0.1654892949808767, 'subsample': 0.7047288186207951, 'colsample_bytree': 0.7284913675467336, 'gamma': 3.6322371032891763, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:51,580] Trial 399 finished with value: 0.8036436470971576 and parameters: {'n_estimators': 126, 'max_depth': 5, 'learning_rate': 0.13133584180332408, 'subsample': 0.7357960659893759, 'colsample_bytree': 0.7377748892030206, 'gamma': 0.05773030637440657, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:52,118] Trial 400 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 132, 'max_depth': 4, 'learning_rate': 0.14179583922056782, 'subsample': 0.7723235023664982, 'colsample_bytree': 0.7229656918578111, 'gamma': 3.266004722262456, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:52,890] Trial 401 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 179, 'max_depth': 8, 'learning_rate': 0.1501541416447685, 'subsample': 0.7224337268965247, 'colsample_bytree': 0.7533062834909665, 'gamma': 3.7822770975966757, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:53,643] Trial 402 finished with value: 0.8143484177639776 and parameters: {'n_estimators': 121, 'max_depth': 7, 'learning_rate': 0.136148469875516, 'subsample': 0.7511949212228218, 'colsample_bytree': 0.6929034150557718, 'gamma': 3.048172223992503, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:54,408] Trial 403 finished with value: 0.8018706994039063 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.10067087313261061, 'subsample': 0.9752797222047487, 'colsample_bytree': 0.7147612625777834, 'gamma': 2.846777667057147, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:54,788] Trial 404 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 109, 'max_depth': 8, 'learning_rate': 0.1267345296456266, 'subsample': 0.7591341878738238, 'colsample_bytree': 0.7337412777779916, 'gamma': 3.550937650127425, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:55,129] Trial 405 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.15977808611082703, 'subsample': 0.7397595052783117, 'colsample_bytree': 0.8653582734329588, 'gamma': 3.4276356105301486, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:55,524] Trial 406 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 128, 'max_depth': 10, 'learning_rate': 0.14516287371598718, 'subsample': 0.7461417058979272, 'colsample_bytree': 0.7060391667316215, 'gamma': 3.323446938934496, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:55,897] Trial 407 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 132, 'max_depth': 10, 'learning_rate': 0.14693794456912215, 'subsample': 0.766372715403766, 'colsample_bytree': 0.702237490768248, 'gamma': 3.1715595697215617, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:56,476] Trial 408 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 129, 'max_depth': 10, 'learning_rate': 0.15508906949150023, 'subsample': 0.751575472944798, 'colsample_bytree': 0.9258583301558382, 'gamma': 3.312970266006041, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:56,857] Trial 409 finished with value: 0.8215072930442949 and parameters: {'n_estimators': 127, 'max_depth': 10, 'learning_rate': 0.14253347403698813, 'subsample': 0.7804322590250773, 'colsample_bytree': 0.6852313497250214, 'gamma': 2.0400332972585926, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:57,402] Trial 410 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 125, 'max_depth': 10, 'learning_rate': 0.14474355548221401, 'subsample': 0.7927652801252774, 'colsample_bytree': 0.694704943900647, 'gamma': 1.8017163812485537, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:58,006] Trial 411 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 126, 'max_depth': 10, 'learning_rate': 0.1412812407015007, 'subsample': 0.7824959508485196, 'colsample_bytree': 0.6702339459885515, 'gamma': 1.7309200863796215, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:49:58,881] Trial 412 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 134, 'max_depth': 10, 'learning_rate': 0.14978543729818694, 'subsample': 0.7719067445394548, 'colsample_bytree': 0.6805738944677713, 'gamma': 1.560412262406546, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:49:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:00,120] Trial 413 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 128, 'max_depth': 10, 'learning_rate': 0.15362408267689914, 'subsample': 0.7813702825479758, 'colsample_bytree': 0.6679403427835743, 'gamma': 1.8601569859796099, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:00,941] Trial 414 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 119, 'max_depth': 10, 'learning_rate': 0.1418080279406043, 'subsample': 0.7745882575917357, 'colsample_bytree': 0.9078329591689771, 'gamma': 3.2062757248265528, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:01,281] Trial 415 finished with value: 0.8108121058785196 and parameters: {'n_estimators': 105, 'max_depth': 10, 'learning_rate': 0.1468540499607182, 'subsample': 0.7635792768981283, 'colsample_bytree': 0.6852605985206042, 'gamma': 3.0358453627985256, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:01,816] Trial 416 finished with value: 0.7965039388189293 and parameters: {'n_estimators': 205, 'max_depth': 10, 'learning_rate': 0.13884539096301884, 'subsample': 0.7912345810517758, 'colsample_bytree': 0.6880805008365435, 'gamma': 2.0471310464183055, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:02,203] Trial 417 finished with value: 0.8072087094857494 and parameters: {'n_estimators': 123, 'max_depth': 10, 'learning_rate': 0.16294021767776476, 'subsample': 0.7784088500863758, 'colsample_bytree': 0.6601108627960799, 'gamma': 1.9231070253079319, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:02,637] Trial 418 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 133, 'max_depth': 10, 'learning_rate': 0.15305831585065682, 'subsample': 0.7585167465652227, 'colsample_bytree': 0.7071052283657235, 'gamma': 1.6519776634717238, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:03,092] Trial 419 finished with value: 0.8089816571790007 and parameters: {'n_estimators': 112, 'max_depth': 10, 'learning_rate': 0.13575922847990793, 'subsample': 0.766738512299157, 'colsample_bytree': 0.6777445909640532, 'gamma': 2.3804580295145317, 'min_child_weight': 6}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:03,544] Trial 420 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 128, 'max_depth': 10, 'learning_rate': 0.14401797562713728, 'subsample': 0.7591836510301668, 'colsample_bytree': 0.7196454711382246, 'gamma': 3.3525265621407305, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:04,207] Trial 421 finished with value: 0.8072470434899278 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.143587222918121, 'subsample': 0.7736349321628856, 'colsample_bytree': 0.7237362335088636, 'gamma': 2.157242990293321, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:04,989] Trial 422 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 219, 'max_depth': 10, 'learning_rate': 0.13594804076429617, 'subsample': 0.7580258207792014, 'colsample_bytree': 0.7463863336039356, 'gamma': 3.2716600694439713, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:05,349] Trial 423 finished with value: 0.810802522377475 and parameters: {'n_estimators': 116, 'max_depth': 10, 'learning_rate': 0.13135009070447604, 'subsample': 0.7851999768391006, 'colsample_bytree': 0.7366588799091833, 'gamma': 3.35688337076722, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:05,892] Trial 424 finished with value: 0.8054261782914535 and parameters: {'n_estimators': 125, 'max_depth': 10, 'learning_rate': 0.2796857052841133, 'subsample': 0.7661338527458574, 'colsample_bytree': 0.7274488853408182, 'gamma': 3.1295183069240444, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:06,605] Trial 425 finished with value: 0.8018611159028617 and parameters: {'n_estimators': 121, 'max_depth': 10, 'learning_rate': 0.14301281345968422, 'subsample': 0.752828919462203, 'colsample_bytree': 0.7238628128288623, 'gamma': 1.4974502313316351, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:07,357] Trial 426 finished with value: 0.807218292986794 and parameters: {'n_estimators': 128, 'max_depth': 10, 'learning_rate': 0.137585665619022, 'subsample': 0.7610450498788405, 'colsample_bytree': 0.7148186598628478, 'gamma': 2.2462575839399928, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:07,873] Trial 427 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 135, 'max_depth': 10, 'learning_rate': 0.1328397485967969, 'subsample': 0.7710872295871475, 'colsample_bytree': 0.7387683597933998, 'gamma': 3.3695936697062026, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:09,256] Trial 428 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 119, 'max_depth': 10, 'learning_rate': 0.1479090691323016, 'subsample': 0.7507502270310801, 'colsample_bytree': 0.718109654757158, 'gamma': 3.2224357481011516, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:10,356] Trial 429 finished with value: 0.8072374599888832 and parameters: {'n_estimators': 186, 'max_depth': 10, 'learning_rate': 0.14264952140160778, 'subsample': 0.7588489464748595, 'colsample_bytree': 0.7457297841924088, 'gamma': 2.9202542590014557, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:10,755] Trial 430 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 125, 'max_depth': 10, 'learning_rate': 0.08987835096354697, 'subsample': 0.7471090157325784, 'colsample_bytree': 0.6562110905544366, 'gamma': 3.4162454799638655, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:11,181] Trial 431 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 122, 'max_depth': 10, 'learning_rate': 0.06004989336153628, 'subsample': 0.7452276909456923, 'colsample_bytree': 0.656510752041882, 'gamma': 3.413478868334276, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:11,633] Trial 432 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 116, 'max_depth': 10, 'learning_rate': 0.13090246508888023, 'subsample': 0.748209762428959, 'colsample_bytree': 0.6666343921335024, 'gamma': 3.340773061685726, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:12,130] Trial 433 finished with value: 0.7982768865121807 and parameters: {'n_estimators': 125, 'max_depth': 10, 'learning_rate': 0.08852618144831013, 'subsample': 0.8294134638138424, 'colsample_bytree': 0.6387197673426401, 'gamma': 3.242655069540699, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:12,522] Trial 434 finished with value: 0.8090295746842237 and parameters: {'n_estimators': 111, 'max_depth': 10, 'learning_rate': 0.09093118226336859, 'subsample': 0.7988677647063495, 'colsample_bytree': 0.7324759093256427, 'gamma': 3.451148512334105, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:12,886] Trial 435 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 128, 'max_depth': 10, 'learning_rate': 0.08181561111615525, 'subsample': 0.7443952446457331, 'colsample_bytree': 0.7523618917814607, 'gamma': 3.1208514847384654, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:13,231] Trial 436 finished with value: 0.810802522377475 and parameters: {'n_estimators': 123, 'max_depth': 10, 'learning_rate': 0.09986811458999569, 'subsample': 0.7555414441793618, 'colsample_bytree': 0.7401261322676261, 'gamma': 3.3035216069936086, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:13,613] Trial 437 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 118, 'max_depth': 10, 'learning_rate': 0.1388508779590127, 'subsample': 0.7354286921657252, 'colsample_bytree': 0.7312947417552216, 'gamma': 3.1850574892242514, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:14,122] Trial 438 finished with value: 0.803634063596113 and parameters: {'n_estimators': 230, 'max_depth': 3, 'learning_rate': 0.09195474598960497, 'subsample': 0.6706768187811522, 'colsample_bytree': 0.6393241195537556, 'gamma': 3.43672349983276, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:14,548] Trial 439 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 129, 'max_depth': 8, 'learning_rate': 0.13171173142022974, 'subsample': 0.7668698367036219, 'colsample_bytree': 0.7192880222669541, 'gamma': 3.008738347455409, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:15,140] Trial 440 finished with value: 0.8018323653997279 and parameters: {'n_estimators': 122, 'max_depth': 4, 'learning_rate': 0.10794643260243002, 'subsample': 0.7498839513143752, 'colsample_bytree': 0.72800558149205, 'gamma': 2.0765124688029077, 'min_child_weight': 8}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:15,906] Trial 441 finished with value: 0.8072087094857494 and parameters: {'n_estimators': 196, 'max_depth': 10, 'learning_rate': 0.14713214899882623, 'subsample': 0.7818853359141367, 'colsample_bytree': 0.756757125361974, 'gamma': 3.304019178302153, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:16,475] Trial 442 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 125, 'max_depth': 8, 'learning_rate': 0.06824989507385391, 'subsample': 0.7618989128876655, 'colsample_bytree': 0.7386411501452358, 'gamma': 3.096842448227307, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:16,849] Trial 443 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 114, 'max_depth': 7, 'learning_rate': 0.12433827923001665, 'subsample': 0.7402449602673005, 'colsample_bytree': 0.6533065699956973, 'gamma': 3.1824958270235024, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:17,220] Trial 444 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 132, 'max_depth': 10, 'learning_rate': 0.13421548855363513, 'subsample': 0.7760114000669069, 'colsample_bytree': 0.7192654066857709, 'gamma': 3.3612371133698504, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:17,785] Trial 445 finished with value: 0.8089912406800454 and parameters: {'n_estimators': 119, 'max_depth': 10, 'learning_rate': 0.13911680113330924, 'subsample': 0.7523832012994677, 'colsample_bytree': 0.6988677454742764, 'gamma': 2.7550974200930973, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:18,195] Trial 446 finished with value: 0.8000594177064766 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.12709129126078086, 'subsample': 0.7464162106830204, 'colsample_bytree': 0.9441688431401453, 'gamma': 2.8746089896902873, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:18,534] Trial 447 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 127, 'max_depth': 10, 'learning_rate': 0.14599604405103628, 'subsample': 0.7682795439650301, 'colsample_bytree': 0.6450704983145087, 'gamma': 3.478120173997802, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:19,216] Trial 448 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 108, 'max_depth': 8, 'learning_rate': 0.13902789629442375, 'subsample': 0.7330325793363843, 'colsample_bytree': 0.7447525284595331, 'gamma': 3.0332020808135267, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:19,779] Trial 449 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 106, 'max_depth': 8, 'learning_rate': 0.1392610062851854, 'subsample': 0.7288282600605795, 'colsample_bytree': 0.7482246718908802, 'gamma': 2.978685300546835, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:20,137] Trial 450 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 108, 'max_depth': 8, 'learning_rate': 0.1334612605726081, 'subsample': 0.7342579043110294, 'colsample_bytree': 0.7589879765716455, 'gamma': 3.0371794098032896, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:20,468] Trial 451 finished with value: 0.8054453452935427 and parameters: {'n_estimators': 112, 'max_depth': 8, 'learning_rate': 0.14062616094468416, 'subsample': 0.7390916847032082, 'colsample_bytree': 0.6150896242516591, 'gamma': 3.0894761037124034, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:20,987] Trial 452 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 115, 'max_depth': 8, 'learning_rate': 0.12314780648730428, 'subsample': 0.7285215972846095, 'colsample_bytree': 0.6298828855993002, 'gamma': 2.5145234520479653, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:21,491] Trial 453 finished with value: 0.810802522377475 and parameters: {'n_estimators': 104, 'max_depth': 8, 'learning_rate': 0.13154768228706828, 'subsample': 0.7592985805087966, 'colsample_bytree': 0.7501656544931182, 'gamma': 2.8113442399348614, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:21,970] Trial 454 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 161, 'max_depth': 8, 'learning_rate': 0.15005864005018943, 'subsample': 0.7534489129825543, 'colsample_bytree': 0.743556540843872, 'gamma': 3.242235385828007, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:22,301] Trial 455 finished with value: 0.817970981158837 and parameters: {'n_estimators': 111, 'max_depth': 8, 'learning_rate': 0.1369094516941035, 'subsample': 0.7419135466870622, 'colsample_bytree': 0.7358594506752014, 'gamma': 3.177726591641131, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:22,646] Trial 456 finished with value: 0.803634063596113 and parameters: {'n_estimators': 117, 'max_depth': 8, 'learning_rate': 0.09620301468742895, 'subsample': 0.7355853718576907, 'colsample_bytree': 0.9594906916162701, 'gamma': 2.9448666291451673, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:22,975] Trial 457 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 106, 'max_depth': 10, 'learning_rate': 0.11968005415666798, 'subsample': 0.7643678611611143, 'colsample_bytree': 0.8766032957117618, 'gamma': 3.064908357164162, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:23,350] Trial 458 finished with value: 0.8054261782914535 and parameters: {'n_estimators': 122, 'max_depth': 8, 'learning_rate': 0.14479530241072547, 'subsample': 0.7491243909601378, 'colsample_bytree': 0.7456031108602528, 'gamma': 1.6345822309439701, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:23,912] Trial 459 finished with value: 0.8036436470971576 and parameters: {'n_estimators': 243, 'max_depth': 9, 'learning_rate': 0.14191033743051215, 'subsample': 0.7745129454987649, 'colsample_bytree': 0.7648018141251656, 'gamma': 3.2985215940270107, 'min_child_weight': 5}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:25,105] Trial 460 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 119, 'max_depth': 10, 'learning_rate': 0.07482444648373053, 'subsample': 0.7577864601820394, 'colsample_bytree': 0.731713705695288, 'gamma': 3.1288782487637863, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:25,668] Trial 461 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 125, 'max_depth': 7, 'learning_rate': 0.1271585077561399, 'subsample': 0.7449399903454329, 'colsample_bytree': 0.7274261693640982, 'gamma': 2.9287304216506107, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:26,270] Trial 462 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 108, 'max_depth': 10, 'learning_rate': 0.1357965427643424, 'subsample': 0.7247926962958966, 'colsample_bytree': 0.735727258713553, 'gamma': 2.677416087006383, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:26,833] Trial 463 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 128, 'max_depth': 8, 'learning_rate': 0.10793973696456281, 'subsample': 0.8396658509652547, 'colsample_bytree': 0.742087578478702, 'gamma': 3.246195358029872, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:27,896] Trial 464 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 253, 'max_depth': 10, 'learning_rate': 0.11625485051085384, 'subsample': 0.7526344389710583, 'colsample_bytree': 0.7236478656189922, 'gamma': 3.417079249654646, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:28,506] Trial 465 finished with value: 0.8179518141567478 and parameters: {'n_estimators': 115, 'max_depth': 9, 'learning_rate': 0.12934153961556893, 'subsample': 0.7329337610548922, 'colsample_bytree': 0.755307374816024, 'gamma': 3.3138893631451682, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:29,303] Trial 466 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 269, 'max_depth': 8, 'learning_rate': 0.14699370679755358, 'subsample': 0.7874258981420276, 'colsample_bytree': 0.7308746908870563, 'gamma': 3.0232321987402067, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:29,884] Trial 467 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 121, 'max_depth': 3, 'learning_rate': 0.1530727404588341, 'subsample': 0.7663511701180805, 'colsample_bytree': 0.8548191554223948, 'gamma': 3.118237889365993, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:30,299] Trial 468 finished with value: 0.8161596994614073 and parameters: {'n_estimators': 131, 'max_depth': 10, 'learning_rate': 0.12207171402877366, 'subsample': 0.7412726322742912, 'colsample_bytree': 0.6749071395946084, 'gamma': 3.1875603710227107, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:30,816] Trial 469 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 124, 'max_depth': 4, 'learning_rate': 0.1364634412447777, 'subsample': 0.7580349918315773, 'colsample_bytree': 0.9770352203009712, 'gamma': 2.8398174916304866, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:31,163] Trial 470 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 112, 'max_depth': 10, 'learning_rate': 0.12969287474300872, 'subsample': 0.7473442872329494, 'colsample_bytree': 0.916850976089423, 'gamma': 3.362943457602588, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:31,512] Trial 471 finished with value: 0.8018802829049508 and parameters: {'n_estimators': 118, 'max_depth': 7, 'learning_rate': 0.08490977809318193, 'subsample': 0.8170900403318572, 'colsample_bytree': 0.743812319629095, 'gamma': 3.2231897007139705, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:31,865] Trial 472 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 129, 'max_depth': 10, 'learning_rate': 0.10476812407837396, 'subsample': 0.7717951512575615, 'colsample_bytree': 0.7230362167416128, 'gamma': 3.5071753220555784, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:32,245] Trial 473 finished with value: 0.8125563030686371 and parameters: {'n_estimators': 123, 'max_depth': 8, 'learning_rate': 0.14145825863002204, 'subsample': 0.7567271771988595, 'colsample_bytree': 0.9336879454225555, 'gamma': 3.001208133738978, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:32,610] Trial 474 finished with value: 0.8072087094857494 and parameters: {'n_estimators': 134, 'max_depth': 9, 'learning_rate': 0.11371852206646711, 'subsample': 0.734276844007763, 'colsample_bytree': 0.6868419321137705, 'gamma': 1.9904834996735452, 'min_child_weight': 6}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:32,964] Trial 475 finished with value: 0.7964847718168402 and parameters: {'n_estimators': 126, 'max_depth': 10, 'learning_rate': 0.14737977753146608, 'subsample': 0.7630288628793547, 'colsample_bytree': 0.8670650799193155, 'gamma': 3.3886710457562166, 'min_child_weight': 10}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:33,385] Trial 476 finished with value: 0.8018898664059955 and parameters: {'n_estimators': 130, 'max_depth': 8, 'learning_rate': 0.12553941960630996, 'subsample': 0.866182922444293, 'colsample_bytree': 0.711651051489626, 'gamma': 1.277863542781753, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:34,067] Trial 477 finished with value: 0.810802522377475 and parameters: {'n_estimators': 286, 'max_depth': 7, 'learning_rate': 0.1336812698175274, 'subsample': 0.7189719793926077, 'colsample_bytree': 0.9907984526816619, 'gamma': 3.1372023037651537, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:34,448] Trial 478 finished with value: 0.8179518141567478 and parameters: {'n_estimators': 109, 'max_depth': 9, 'learning_rate': 0.14085264592701938, 'subsample': 0.7433207596319642, 'colsample_bytree': 0.7322908131532465, 'gamma': 3.2788538115887658, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:34,812] Trial 479 finished with value: 0.800049834205432 and parameters: {'n_estimators': 102, 'max_depth': 10, 'learning_rate': 0.15511443389260002, 'subsample': 0.7515437626358933, 'colsample_bytree': 0.8978533431330047, 'gamma': 1.7498583542258088, 'min_child_weight': 7}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:35,263] Trial 480 finished with value: 0.8036628140992468 and parameters: {'n_estimators': 119, 'max_depth': 8, 'learning_rate': 0.1224203613191104, 'subsample': 0.777227445270467, 'colsample_bytree': 0.7030406206759805, 'gamma': 3.493770503432571, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:35,595] Trial 481 finished with value: 0.8071895424836603 and parameters: {'n_estimators': 115, 'max_depth': 10, 'learning_rate': 0.1359634890882146, 'subsample': 0.7671768924682854, 'colsample_bytree': 0.7501778806883493, 'gamma': 2.580128195363959, 'min_child_weight': 9}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:35,982] Trial 482 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 136, 'max_depth': 10, 'learning_rate': 0.1112026556513404, 'subsample': 0.7400748470226696, 'colsample_bytree': 0.7397640709236538, 'gamma': 3.050573578352238, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:36,336] Trial 483 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 122, 'max_depth': 7, 'learning_rate': 0.1505990889986197, 'subsample': 0.7495843481931278, 'colsample_bytree': 0.7193371871792612, 'gamma': 3.324586744462606, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:36,675] Trial 484 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 121, 'max_depth': 7, 'learning_rate': 0.1297201913794244, 'subsample': 0.7298156707859661, 'colsample_bytree': 0.7278378886530955, 'gamma': 3.29957185306072, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:37,032] Trial 485 finished with value: 0.8107737718743412 and parameters: {'n_estimators': 124, 'max_depth': 7, 'learning_rate': 0.09971834047985519, 'subsample': 0.682508639853606, 'colsample_bytree': 0.7365671895258088, 'gamma': 3.2167720358755036, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:37,489] Trial 486 finished with value: 0.8125563030686371 and parameters: {'n_estimators': 113, 'max_depth': 7, 'learning_rate': 0.1441292490225678, 'subsample': 0.7461946478542495, 'colsample_bytree': 0.7190537990821718, 'gamma': 3.3849647433585246, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:37,837] Trial 487 finished with value: 0.805416594790409 and parameters: {'n_estimators': 117, 'max_depth': 7, 'learning_rate': 0.15181507401092806, 'subsample': 0.7518983895564798, 'colsample_bytree': 0.9504858126939577, 'gamma': 3.1598002951950006, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:38,203] Trial 488 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 121, 'max_depth': 7, 'learning_rate': 0.11819295314272053, 'subsample': 0.7384418104878259, 'colsample_bytree': 0.728087895807053, 'gamma': 2.9061080579722764, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:38,578] Trial 489 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 126, 'max_depth': 8, 'learning_rate': 0.13833080788735788, 'subsample': 0.7259434448122953, 'colsample_bytree': 0.7555245150201955, 'gamma': 3.279839415028764, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:38,996] Trial 490 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 120, 'max_depth': 7, 'learning_rate': 0.12768818996338277, 'subsample': 0.7950167397913482, 'colsample_bytree': 0.8151655410827714, 'gamma': 1.4487822619661213, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:39,447] Trial 491 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 128, 'max_depth': 4, 'learning_rate': 0.14411304208385528, 'subsample': 0.7596879285321607, 'colsample_bytree': 0.7111383543100693, 'gamma': 3.1098081683588323, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:39,838] Trial 492 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 114, 'max_depth': 8, 'learning_rate': 0.1346361981659735, 'subsample': 0.748978228393607, 'colsample_bytree': 0.7359004668901467, 'gamma': 2.4205360553062865, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:40,212] Trial 493 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 124, 'max_depth': 10, 'learning_rate': 0.12317791168316472, 'subsample': 0.735626991924409, 'colsample_bytree': 0.7265291902892049, 'gamma': 3.380940085303794, 'min_child_weight': 1}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:40,547] Trial 494 finished with value: 0.8197439288520884 and parameters: {'n_estimators': 110, 'max_depth': 9, 'learning_rate': 0.14965269022809313, 'subsample': 0.7611215914835364, 'colsample_bytree': 0.8486030374548099, 'gamma': 3.2105254895770035, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:40,867] Trial 495 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 110, 'max_depth': 9, 'learning_rate': 0.1516959378600619, 'subsample': 0.7697973086930762, 'colsample_bytree': 0.8598711869316193, 'gamma': 3.306169817611933, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:41,184] Trial 496 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 106, 'max_depth': 9, 'learning_rate': 0.1586398433931844, 'subsample': 0.7798553228881945, 'colsample_bytree': 0.8504814762588723, 'gamma': 3.4667505787302777, 'min_child_weight': 3}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:41,504] Trial 497 finished with value: 0.8179518141567478 and parameters: {'n_estimators': 103, 'max_depth': 9, 'learning_rate': 0.15617334624815532, 'subsample': 0.7622667306144736, 'colsample_bytree': 0.8483747265017861, 'gamma': 3.2267768338756926, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:41,814] Trial 498 finished with value: 0.7982960535142699 and parameters: {'n_estimators': 109, 'max_depth': 9, 'learning_rate': 0.14927815323169466, 'subsample': 0.6113108032109669, 'colsample_bytree': 0.8321742491678554, 'gamma': 3.3410953000815278, 'min_child_weight': 4}. Best is trial 53 with value: 0.8268644701282272.\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:50:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-07 22:50:42,134] Trial 499 finished with value: 0.803634063596113 and parameters: {'n_estimators': 112, 'max_depth': 9, 'learning_rate': 0.14401282251164152, 'subsample': 0.773169929731113, 'colsample_bytree': 0.8503182039675491, 'gamma': 3.1810800026663606, 'min_child_weight': 2}. Best is trial 53 with value: 0.8268644701282272.\n",
      "07-05-2025 22:50:42 Best XGBoost params: {'n_estimators': 113, 'max_depth': 7, 'learning_rate': 0.13356255959701807, 'subsample': 0.8227892929620261, 'colsample_bytree': 0.9818719052158643, 'gamma': 1.721433068201912, 'min_child_weight': 4}\n",
      "[I 2025-05-07 22:50:42,141] A new study created in memory with name: no-name-f585a768-aacc-4292-bb20-09daa33a8e3c\n",
      "[I 2025-05-07 22:50:42,591] Trial 0 finished with value: 0.8018323653997279 and parameters: {'n_estimators': 85, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.8018323653997279.\n",
      "[I 2025-05-07 22:50:43,540] Trial 1 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 199, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8107833553753858.\n",
      "[I 2025-05-07 22:50:43,941] Trial 2 finished with value: 0.8036628140992468 and parameters: {'n_estimators': 80, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8107833553753858.\n",
      "[I 2025-05-07 22:50:44,487] Trial 3 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 106, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:44,965] Trial 4 finished with value: 0.7910892607287293 and parameters: {'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:45,425] Trial 5 finished with value: 0.8090295746842237 and parameters: {'n_estimators': 92, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:46,603] Trial 6 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 189, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:47,835] Trial 7 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 189, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:48,816] Trial 8 finished with value: 0.7875146148390929 and parameters: {'n_estimators': 155, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:49,836] Trial 9 finished with value: 0.8036915646023806 and parameters: {'n_estimators': 150, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:50,447] Trial 10 finished with value: 0.8089720736779561 and parameters: {'n_estimators': 57, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:51,291] Trial 11 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 129, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:51,920] Trial 12 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 118, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:52,590] Trial 13 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 115, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:53,250] Trial 14 finished with value: 0.805416594790409 and parameters: {'n_estimators': 132, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:53,583] Trial 15 finished with value: 0.8018323653997279 and parameters: {'n_estimators': 59, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:54,093] Trial 16 finished with value: 0.7750177294769326 and parameters: {'n_estimators': 111, 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:54,843] Trial 17 finished with value: 0.807218292986794 and parameters: {'n_estimators': 149, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:55,645] Trial 18 finished with value: 0.8036244800950684 and parameters: {'n_estimators': 167, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:56,023] Trial 19 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 71, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:56,560] Trial 20 finished with value: 0.7982481360090469 and parameters: {'n_estimators': 111, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:57,434] Trial 21 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 177, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:58,087] Trial 22 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 133, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:58,744] Trial 23 finished with value: 0.8071895424836603 and parameters: {'n_estimators': 140, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8143675847660669.\n",
      "[I 2025-05-07 22:50:59,354] Trial 24 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 124, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8161501159603627.\n",
      "[I 2025-05-07 22:50:59,861] Trial 25 finished with value: 0.8054070112893643 and parameters: {'n_estimators': 99, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 24 with value: 0.8161501159603627.\n",
      "[I 2025-05-07 22:51:00,531] Trial 26 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 137, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8161501159603627.\n",
      "[I 2025-05-07 22:51:01,133] Trial 27 finished with value: 0.7946830736204551 and parameters: {'n_estimators': 122, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 24 with value: 0.8161501159603627.\n",
      "[I 2025-05-07 22:51:01,634] Trial 28 finished with value: 0.8071799589826156 and parameters: {'n_estimators': 104, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8161501159603627.\n",
      "[I 2025-05-07 22:51:02,068] Trial 29 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 83, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 24 with value: 0.8161501159603627.\n",
      "[I 2025-05-07 22:51:02,788] Trial 30 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 144, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8161501159603627.\n",
      "[I 2025-05-07 22:51:03,563] Trial 31 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 124, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8161501159603627.\n",
      "[I 2025-05-07 22:51:04,193] Trial 32 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 126, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:04,835] Trial 33 finished with value: 0.8089816571790007 and parameters: {'n_estimators': 123, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:05,300] Trial 34 finished with value: 0.8018706994039063 and parameters: {'n_estimators': 92, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:06,050] Trial 35 finished with value: 0.796465604814751 and parameters: {'n_estimators': 161, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:06,588] Trial 36 finished with value: 0.7964847718168402 and parameters: {'n_estimators': 104, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:06,986] Trial 37 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 75, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:07,587] Trial 38 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:08,290] Trial 39 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 127, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:08,822] Trial 40 finished with value: 0.8018419489007725 and parameters: {'n_estimators': 106, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:09,486] Trial 41 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 134, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:10,077] Trial 42 finished with value: 0.8125850535717709 and parameters: {'n_estimators': 118, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:10,767] Trial 43 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 144, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:11,400] Trial 44 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 129, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:12,067] Trial 45 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 125, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:12,619] Trial 46 finished with value: 0.8089720736779561 and parameters: {'n_estimators': 112, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:13,399] Trial 47 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 154, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:13,914] Trial 48 finished with value: 0.8089912406800454 and parameters: {'n_estimators': 96, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:14,474] Trial 49 finished with value: 0.796465604814751 and parameters: {'n_estimators': 119, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:15,088] Trial 50 finished with value: 0.7893067295344336 and parameters: {'n_estimators': 129, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:15,774] Trial 51 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 133, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:16,490] Trial 52 finished with value: 0.8125754700707263 and parameters: {'n_estimators': 145, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:17,195] Trial 53 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 138, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:17,790] Trial 54 finished with value: 0.8071895424836603 and parameters: {'n_estimators': 115, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:18,326] Trial 55 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 108, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:18,986] Trial 56 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 130, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:19,630] Trial 57 finished with value: 0.8036244800950684 and parameters: {'n_estimators': 124, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:20,240] Trial 58 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 116, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:20,890] Trial 59 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 129, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:21,575] Trial 60 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 131, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:22,248] Trial 61 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 139, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:22,863] Trial 62 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 121, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:23,615] Trial 63 finished with value: 0.807218292986794 and parameters: {'n_estimators': 149, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:24,164] Trial 64 finished with value: 0.8071895424836603 and parameters: {'n_estimators': 111, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:24,805] Trial 65 finished with value: 0.8036244800950684 and parameters: {'n_estimators': 128, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:25,542] Trial 66 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 143, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:26,224] Trial 67 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 136, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:26,739] Trial 68 finished with value: 0.8089816571790007 and parameters: {'n_estimators': 101, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:27,513] Trial 69 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 157, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:28,405] Trial 70 finished with value: 0.7732543652847257 and parameters: {'n_estimators': 198, 'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.8179326471546586.\n",
      "[I 2025-05-07 22:51:28,688] Trial 71 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 71 with value: 0.8215264600463842.\n",
      "[I 2025-05-07 22:51:29,013] Trial 72 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 71 with value: 0.8215264600463842.\n",
      "[I 2025-05-07 22:51:29,324] Trial 73 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 71 with value: 0.8215264600463842.\n",
      "[I 2025-05-07 22:51:29,730] Trial 74 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 71 with value: 0.8215264600463842.\n",
      "[I 2025-05-07 22:51:30,042] Trial 75 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 51, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:30,346] Trial 76 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:30,642] Trial 77 finished with value: 0.810802522377475 and parameters: {'n_estimators': 51, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:31,280] Trial 78 finished with value: 0.8089720736779561 and parameters: {'n_estimators': 63, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:31,583] Trial 79 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 50, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:31,946] Trial 80 finished with value: 0.8126042205738601 and parameters: {'n_estimators': 65, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:32,287] Trial 81 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:32,604] Trial 82 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:32,911] Trial 83 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:33,263] Trial 84 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:33,588] Trial 85 finished with value: 0.8125467195675924 and parameters: {'n_estimators': 59, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:33,962] Trial 86 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 69, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:34,309] Trial 87 finished with value: 0.8054549287945872 and parameters: {'n_estimators': 56, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:34,656] Trial 88 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:35,087] Trial 89 finished with value: 0.8054357617924981 and parameters: {'n_estimators': 78, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:35,425] Trial 90 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:35,810] Trial 91 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 69, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:36,141] Trial 92 finished with value: 0.8054645122956319 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:36,530] Trial 93 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 68, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:36,830] Trial 94 finished with value: 0.8178943131504801 and parameters: {'n_estimators': 52, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:37,150] Trial 95 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:37,531] Trial 96 finished with value: 0.8071799589826155 and parameters: {'n_estimators': 67, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:37,862] Trial 97 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:38,248] Trial 98 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 72, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:38,594] Trial 99 finished with value: 0.8090295746842237 and parameters: {'n_estimators': 59, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:38,928] Trial 100 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:39,270] Trial 101 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:39,636] Trial 102 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:39,961] Trial 103 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:40,352] Trial 104 finished with value: 0.8161309489582735 and parameters: {'n_estimators': 74, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:40,703] Trial 105 finished with value: 0.8125467195675924 and parameters: {'n_estimators': 58, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:41,050] Trial 106 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 61, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:41,416] Trial 107 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 66, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:41,889] Trial 108 finished with value: 0.807218292986794 and parameters: {'n_estimators': 81, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:42,249] Trial 109 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 67, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:42,570] Trial 110 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 57, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:42,937] Trial 111 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:43,306] Trial 112 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 66, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:43,681] Trial 113 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 67, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:44,227] Trial 114 finished with value: 0.8071799589826156 and parameters: {'n_estimators': 75, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:44,530] Trial 115 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:44,822] Trial 116 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:45,127] Trial 117 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:45,414] Trial 118 finished with value: 0.8143292507618883 and parameters: {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:45,711] Trial 119 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 50, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:46,058] Trial 120 finished with value: 0.8036723976002914 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:46,389] Trial 121 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:46,685] Trial 122 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:46,993] Trial 123 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:47,320] Trial 124 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:47,623] Trial 125 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:47,942] Trial 126 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 51, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:48,269] Trial 127 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:48,590] Trial 128 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 56, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:48,905] Trial 129 finished with value: 0.8161021984551396 and parameters: {'n_estimators': 53, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:49,225] Trial 130 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:49,547] Trial 131 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:49,883] Trial 132 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:50,203] Trial 133 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:50,548] Trial 134 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:51,020] Trial 135 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:51,481] Trial 136 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:51,980] Trial 137 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:52,502] Trial 138 finished with value: 0.816169282962452 and parameters: {'n_estimators': 64, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:52,895] Trial 139 finished with value: 0.8053974277883197 and parameters: {'n_estimators': 71, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:53,255] Trial 140 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:53,636] Trial 141 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:53,993] Trial 142 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:54,368] Trial 143 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:54,733] Trial 144 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:55,117] Trial 145 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:55,492] Trial 146 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:56,379] Trial 147 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 172, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:56,791] Trial 148 finished with value: 0.8143484177639776 and parameters: {'n_estimators': 71, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:57,150] Trial 149 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 61, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:57,532] Trial 150 finished with value: 0.816169282962452 and parameters: {'n_estimators': 64, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:58,009] Trial 151 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:58,350] Trial 152 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:58,708] Trial 153 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:59,080] Trial 154 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:59,412] Trial 155 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:51:59,775] Trial 156 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:00,169] Trial 157 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 65, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:00,644] Trial 158 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 87, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:01,043] Trial 159 finished with value: 0.8071799589826155 and parameters: {'n_estimators': 69, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:01,400] Trial 160 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:01,750] Trial 161 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:02,108] Trial 162 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:02,426] Trial 163 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:02,771] Trial 164 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:03,146] Trial 165 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:03,469] Trial 166 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:03,818] Trial 167 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:04,199] Trial 168 finished with value: 0.8053974277883197 and parameters: {'n_estimators': 66, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:04,530] Trial 169 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:04,911] Trial 170 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:05,285] Trial 171 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:05,628] Trial 172 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:05,957] Trial 173 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:06,329] Trial 174 finished with value: 0.8054645122956319 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:06,728] Trial 175 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 68, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:07,049] Trial 176 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:07,470] Trial 177 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 65, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:07,828] Trial 178 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:08,207] Trial 179 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:08,557] Trial 180 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:08,915] Trial 181 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:09,265] Trial 182 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:09,657] Trial 183 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:10,008] Trial 184 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:10,868] Trial 185 finished with value: 0.7910892607287293 and parameters: {'n_estimators': 185, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:11,210] Trial 186 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:11,604] Trial 187 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 65, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:11,931] Trial 188 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:12,365] Trial 189 finished with value: 0.8143484177639776 and parameters: {'n_estimators': 71, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:12,725] Trial 190 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:13,070] Trial 191 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:13,573] Trial 192 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:13,940] Trial 193 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:14,274] Trial 194 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:14,662] Trial 195 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:14,972] Trial 196 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:15,314] Trial 197 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:15,725] Trial 198 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 67, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:16,089] Trial 199 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:16,431] Trial 200 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:16,806] Trial 201 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:17,147] Trial 202 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:17,472] Trial 203 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:17,847] Trial 204 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:18,189] Trial 205 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:18,526] Trial 206 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:18,864] Trial 207 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:19,202] Trial 208 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:19,581] Trial 209 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:19,930] Trial 210 finished with value: 0.8161117819561842 and parameters: {'n_estimators': 55, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:20,472] Trial 211 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:20,925] Trial 212 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:21,281] Trial 213 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:21,626] Trial 214 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:22,005] Trial 215 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 66, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:22,409] Trial 216 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 52, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:22,771] Trial 217 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:23,129] Trial 218 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:23,466] Trial 219 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:23,783] Trial 220 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 52, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:24,123] Trial 221 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:24,481] Trial 222 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:24,847] Trial 223 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:25,184] Trial 224 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:25,517] Trial 225 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:25,912] Trial 226 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:26,247] Trial 227 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:26,613] Trial 228 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:27,112] Trial 229 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 67, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:27,425] Trial 230 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 52, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:27,779] Trial 231 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:28,112] Trial 232 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:28,448] Trial 233 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:28,803] Trial 234 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:29,142] Trial 235 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:29,495] Trial 236 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:29,828] Trial 237 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:30,186] Trial 238 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:30,528] Trial 239 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:30,862] Trial 240 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:31,212] Trial 241 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:31,557] Trial 242 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:31,941] Trial 243 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:32,283] Trial 244 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 56, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:32,628] Trial 245 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:33,011] Trial 246 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 65, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:33,352] Trial 247 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:33,694] Trial 248 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:34,061] Trial 249 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:34,379] Trial 250 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 52, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:34,725] Trial 251 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:35,042] Trial 252 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:35,478] Trial 253 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:35,893] Trial 254 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:36,261] Trial 255 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 61, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:36,646] Trial 256 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 68, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:36,978] Trial 257 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:37,312] Trial 258 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:37,660] Trial 259 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:38,010] Trial 260 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:38,393] Trial 261 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 65, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:38,725] Trial 262 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:39,027] Trial 263 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 52, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:39,393] Trial 264 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:39,870] Trial 265 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:40,194] Trial 266 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:40,493] Trial 267 finished with value: 0.8143292507618883 and parameters: {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:40,981] Trial 268 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 89, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:41,279] Trial 269 finished with value: 0.7911084277308186 and parameters: {'n_estimators': 56, 'max_depth': 2, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:41,654] Trial 270 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 65, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:42,163] Trial 271 finished with value: 0.8072087094857494 and parameters: {'n_estimators': 97, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:42,501] Trial 272 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:42,834] Trial 273 finished with value: 0.8054453452935427 and parameters: {'n_estimators': 53, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:43,160] Trial 274 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:43,524] Trial 275 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:43,910] Trial 276 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 68, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:44,234] Trial 277 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:44,587] Trial 278 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:44,959] Trial 279 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:45,309] Trial 280 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:45,624] Trial 281 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:45,968] Trial 282 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:46,326] Trial 283 finished with value: 0.8053974277883197 and parameters: {'n_estimators': 66, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:46,678] Trial 284 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:47,008] Trial 285 finished with value: 0.8072374599888832 and parameters: {'n_estimators': 55, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:47,985] Trial 286 finished with value: 0.8107737718743412 and parameters: {'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:48,291] Trial 287 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 52, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:48,650] Trial 288 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:49,019] Trial 289 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:49,450] Trial 290 finished with value: 0.8143484177639776 and parameters: {'n_estimators': 71, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:49,809] Trial 291 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:50,178] Trial 292 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:50,478] Trial 293 finished with value: 0.8179518141567478 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:50,800] Trial 294 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:51,138] Trial 295 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:51,468] Trial 296 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 54, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:51,832] Trial 297 finished with value: 0.8089720736779561 and parameters: {'n_estimators': 62, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:52,216] Trial 298 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 66, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:52,550] Trial 299 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:52,908] Trial 300 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:53,220] Trial 301 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 52, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:53,554] Trial 302 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:53,959] Trial 303 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 69, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:54,329] Trial 304 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:54,688] Trial 305 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:55,491] Trial 306 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 160, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:55,929] Trial 307 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:56,274] Trial 308 finished with value: 0.8125467195675924 and parameters: {'n_estimators': 58, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:56,657] Trial 309 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:56,958] Trial 310 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:57,286] Trial 311 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:57,674] Trial 312 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:58,046] Trial 313 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 65, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:58,374] Trial 314 finished with value: 0.8072470434899278 and parameters: {'n_estimators': 57, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:58,707] Trial 315 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:59,065] Trial 316 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:52:59,851] Trial 317 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 152, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:00,225] Trial 318 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:00,548] Trial 319 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:00,902] Trial 320 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:01,346] Trial 321 finished with value: 0.8108121058785196 and parameters: {'n_estimators': 77, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:01,732] Trial 322 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 68, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:02,090] Trial 323 finished with value: 0.8089720736779561 and parameters: {'n_estimators': 64, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:02,448] Trial 324 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:02,765] Trial 325 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:03,115] Trial 326 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 61, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:03,490] Trial 327 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:03,805] Trial 328 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:04,187] Trial 329 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:04,628] Trial 330 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:05,616] Trial 331 finished with value: 0.8107737718743412 and parameters: {'n_estimators': 178, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:05,948] Trial 332 finished with value: 0.8161117819561842 and parameters: {'n_estimators': 56, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:06,314] Trial 333 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:06,678] Trial 334 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:07,045] Trial 335 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 67, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:07,393] Trial 336 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:07,724] Trial 337 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 52, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:08,064] Trial 338 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 59, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:08,464] Trial 339 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:08,804] Trial 340 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:09,147] Trial 341 finished with value: 0.8054453452935427 and parameters: {'n_estimators': 60, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:09,489] Trial 342 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:10,045] Trial 343 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:10,965] Trial 344 finished with value: 0.814386751768156 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:12,095] Trial 345 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 66, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:13,184] Trial 346 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:13,796] Trial 347 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:14,305] Trial 348 finished with value: 0.8125467195675924 and parameters: {'n_estimators': 59, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:14,741] Trial 349 finished with value: 0.8143484177639776 and parameters: {'n_estimators': 73, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:15,136] Trial 350 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:15,504] Trial 351 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:15,885] Trial 352 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:16,213] Trial 353 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:16,653] Trial 354 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 69, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:16,996] Trial 355 finished with value: 0.8090104076821345 and parameters: {'n_estimators': 58, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:17,450] Trial 356 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 62, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:17,818] Trial 357 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 52, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:18,207] Trial 358 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 65, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:18,574] Trial 359 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:18,975] Trial 360 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:19,319] Trial 361 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:19,697] Trial 362 finished with value: 0.8072470434899278 and parameters: {'n_estimators': 58, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:20,108] Trial 363 finished with value: 0.8089720736779561 and parameters: {'n_estimators': 63, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:20,449] Trial 364 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:20,762] Trial 365 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:21,360] Trial 366 finished with value: 0.796465604814751 and parameters: {'n_estimators': 108, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:21,834] Trial 367 finished with value: 0.8090008241810899 and parameters: {'n_estimators': 83, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:22,195] Trial 368 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:22,601] Trial 369 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 66, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:22,911] Trial 370 finished with value: 0.7893067295344336 and parameters: {'n_estimators': 53, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:23,275] Trial 371 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:23,636] Trial 372 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:24,521] Trial 373 finished with value: 0.8125658865696818 and parameters: {'n_estimators': 168, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:24,888] Trial 374 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:25,285] Trial 375 finished with value: 0.814386751768156 and parameters: {'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:25,653] Trial 376 finished with value: 0.8089624901769114 and parameters: {'n_estimators': 59, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:26,003] Trial 377 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:26,386] Trial 378 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:26,732] Trial 379 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 52, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:27,077] Trial 380 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:27,519] Trial 381 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 70, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:27,919] Trial 382 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 66, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:28,273] Trial 383 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:28,672] Trial 384 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:28,994] Trial 385 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:29,354] Trial 386 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:29,761] Trial 387 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:30,102] Trial 388 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:30,845] Trial 389 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 141, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:31,182] Trial 390 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:31,560] Trial 391 finished with value: 0.8161501159603627 and parameters: {'n_estimators': 61, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:31,883] Trial 392 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:32,285] Trial 393 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 67, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:32,793] Trial 394 finished with value: 0.810754604872252 and parameters: {'n_estimators': 93, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:33,135] Trial 395 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:34,135] Trial 396 finished with value: 0.8072278764878386 and parameters: {'n_estimators': 190, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:34,893] Trial 397 finished with value: 0.807218292986794 and parameters: {'n_estimators': 103, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:35,284] Trial 398 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:35,646] Trial 399 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:35,979] Trial 400 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:36,329] Trial 401 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:36,718] Trial 402 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:37,072] Trial 403 finished with value: 0.8090199911831791 and parameters: {'n_estimators': 56, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:37,432] Trial 404 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:37,784] Trial 405 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:38,092] Trial 406 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:38,466] Trial 407 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:38,810] Trial 408 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:39,192] Trial 409 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 66, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:39,568] Trial 410 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:39,926] Trial 411 finished with value: 0.8161117819561842 and parameters: {'n_estimators': 56, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:40,309] Trial 412 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:40,642] Trial 413 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:41,258] Trial 414 finished with value: 0.8107929388764304 and parameters: {'n_estimators': 114, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:41,630] Trial 415 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:41,979] Trial 416 finished with value: 0.8090295746842237 and parameters: {'n_estimators': 59, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:42,335] Trial 417 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:42,729] Trial 418 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 69, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:43,045] Trial 419 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 52, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:43,418] Trial 420 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:43,800] Trial 421 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 65, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:44,175] Trial 422 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:44,550] Trial 423 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:44,908] Trial 424 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:45,226] Trial 425 finished with value: 0.8071799589826156 and parameters: {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:45,625] Trial 426 finished with value: 0.814386751768156 and parameters: {'n_estimators': 63, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:45,950] Trial 427 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:46,308] Trial 428 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:46,833] Trial 429 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 67, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:47,591] Trial 430 finished with value: 0.8107833553753858 and parameters: {'n_estimators': 147, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:47,941] Trial 431 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:48,332] Trial 432 finished with value: 0.8072374599888832 and parameters: {'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:48,666] Trial 433 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 52, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:49,009] Trial 434 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:49,391] Trial 435 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:49,799] Trial 436 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 65, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:50,295] Trial 437 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:50,812] Trial 438 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:51,249] Trial 439 finished with value: 0.8107546048722519 and parameters: {'n_estimators': 61, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:51,617] Trial 440 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:52,057] Trial 441 finished with value: 0.807218292986794 and parameters: {'n_estimators': 72, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:52,555] Trial 442 finished with value: 0.816169282962452 and parameters: {'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:52,887] Trial 443 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:53,262] Trial 444 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:53,617] Trial 445 finished with value: 0.8054645122956319 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:53,940] Trial 446 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:54,381] Trial 447 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 68, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:54,765] Trial 448 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:55,107] Trial 449 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:55,491] Trial 450 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:55,873] Trial 451 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:56,242] Trial 452 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:56,589] Trial 453 finished with value: 0.8143771682671114 and parameters: {'n_estimators': 53, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:56,942] Trial 454 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:57,587] Trial 455 finished with value: 0.8143675847660669 and parameters: {'n_estimators': 119, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:57,939] Trial 456 finished with value: 0.785760834147931 and parameters: {'n_estimators': 60, 'max_depth': 2, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:58,335] Trial 457 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 66, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:58,664] Trial 458 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:59,026] Trial 459 finished with value: 0.8125467195675924 and parameters: {'n_estimators': 58, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:59,397] Trial 460 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:53:59,736] Trial 461 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 52, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:00,114] Trial 462 finished with value: 0.8054549287945872 and parameters: {'n_estimators': 56, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:00,496] Trial 463 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 65, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:00,863] Trial 464 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 59, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:01,314] Trial 465 finished with value: 0.8143292507618883 and parameters: {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:01,666] Trial 466 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:02,034] Trial 467 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:02,388] Trial 468 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:02,741] Trial 469 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:03,127] Trial 470 finished with value: 0.8125946370728155 and parameters: {'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:03,513] Trial 471 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:03,870] Trial 472 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:04,250] Trial 473 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:04,686] Trial 474 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 68, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:05,047] Trial 475 finished with value: 0.8072470434899278 and parameters: {'n_estimators': 58, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:05,501] Trial 476 finished with value: 0.8161309489582735 and parameters: {'n_estimators': 75, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:05,853] Trial 477 finished with value: 0.8232898242385908 and parameters: {'n_estimators': 52, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:06,552] Trial 478 finished with value: 0.8143580012650222 and parameters: {'n_estimators': 134, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:06,888] Trial 479 finished with value: 0.8161117819561842 and parameters: {'n_estimators': 56, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:07,286] Trial 480 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:07,713] Trial 481 finished with value: 0.8215168765453397 and parameters: {'n_estimators': 60, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:08,037] Trial 482 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:08,413] Trial 483 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:08,795] Trial 484 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:09,112] Trial 485 finished with value: 0.8215264600463842 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:09,562] Trial 486 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 70, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:09,926] Trial 487 finished with value: 0.8232994077396354 and parameters: {'n_estimators': 56, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:10,322] Trial 488 finished with value: 0.8054453452935427 and parameters: {'n_estimators': 66, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:10,679] Trial 489 finished with value: 0.7893067295344336 and parameters: {'n_estimators': 60, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:11,026] Trial 490 finished with value: 0.8179326471546586 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:11,379] Trial 491 finished with value: 0.8071799589826156 and parameters: {'n_estimators': 58, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:11,792] Trial 492 finished with value: 0.8197343453510437 and parameters: {'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:12,150] Trial 493 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:12,495] Trial 494 finished with value: 0.8126042205738601 and parameters: {'n_estimators': 55, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:12,887] Trial 495 finished with value: 0.8232994077396355 and parameters: {'n_estimators': 58, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:13,227] Trial 496 finished with value: 0.8197247618499991 and parameters: {'n_estimators': 53, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:13,592] Trial 497 finished with value: 0.8179422306557033 and parameters: {'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:13,976] Trial 498 finished with value: 0.8072470434899278 and parameters: {'n_estimators': 57, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "[I 2025-05-07 22:54:14,347] Trial 499 finished with value: 0.8214977095432503 and parameters: {'n_estimators': 61, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 75 with value: 0.8232994077396355.\n",
      "07-05-2025 22:54:14 Best RF params: {'n_estimators': 51, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}\n",
      "07-05-2025 22:54:14 Best model accuracy: 0.7685185185185185\n",
      "07-05-2025 22:54:15 Đã lưu mô hình và scaler vào W&B: final_model.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polar-wildflower-198</strong> at: <a href='https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes/runs/d8i6hc0d' target=\"_blank\">https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes/runs/d8i6hc0d</a><br> View project at: <a href='https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes' target=\"_blank\">https://wandb.ai/ngocnhi-p4work-national-economics-university/diabetes</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250507_224717-d8i6hc0d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === RUN PIPELINE ===\n",
    "df, run = load_data()\n",
    "X_train, X_val, y_train, y_val, scaler = prepare_data(df)\n",
    "train_base_models(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Tune models\n",
    "xgb_model = tune_xgboost(X_train, y_train)\n",
    "rf_model = tune_random_forest(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "xgb_auc = accuracy_score(y_val, xgb_model.predict(X_val))\n",
    "rf_auc = accuracy_score(y_val, rf_model.predict(X_val))\n",
    "\n",
    "best_model = xgb_model if xgb_auc >= rf_auc else rf_model\n",
    "logger.info(f\"Best model accuracy: {max(xgb_auc, rf_auc)}\")\n",
    "save_and_log_model(best_model, scaler, run)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3217db65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9818719052158643, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, feature_weights=None,\n",
       "              gamma=1.721433068201912, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.13356255959701807,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=4, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=113, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9818719052158643, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, feature_weights=None,\n",
       "              gamma=1.721433068201912, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.13356255959701807,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=4, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=113, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9818719052158643, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, feature_weights=None,\n",
       "              gamma=1.721433068201912, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.13356255959701807,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "              min_child_weight=4, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=113, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a20c0a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã xóa tệp ../model/final_model.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../model/final_model.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "model_path = \"../model/final_model.pkl\"\n",
    "if os.path.exists(model_path):\n",
    "    os.remove(model_path)\n",
    "    print(f\"Đã xóa tệp {model_path}\")\n",
    "import joblib\n",
    "joblib.dump([best_model, scaler], model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06b0bc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "<class 'sklearn.preprocessing._data.StandardScaler'>\n"
     ]
    }
   ],
   "source": [
    "loaded = joblib.load(\"../model/final_model.pkl\")\n",
    "model = loaded[0]\n",
    "scaler = loaded[1]\n",
    "print(type(model))  # Expect XGBClassifier\n",
    "print(type(scaler))  # Expect StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab3f78aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x80\\x04\\x95d\\x03\\x00\\x00\\x00\\x00\\x00\\x00]\\x94(\\x8c\\x0fxgbo'\n"
     ]
    }
   ],
   "source": [
    "with open(\"../model/final_model.pkl\", \"rb\") as f:\n",
    "    content = f.read(20)\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d429906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version used to train: 1.1.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(\"scikit-learn version used to train:\", sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bed01977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python location: c:\\Users\\x-hp\\OneDrive - National Economics University\\Desktop\\ML Ops\\.venv\\Scripts\\python.exe\n",
      "NumPy version: 1.23.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python location:\", sys.executable)\n",
    "\n",
    "import numpy as np\n",
    "print(\"NumPy version:\", np.__version__)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
